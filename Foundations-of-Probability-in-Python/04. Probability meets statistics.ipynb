{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f368f5",
   "metadata": {},
   "source": [
    "1\\. From sample mean to population mean\n",
    "---------------------------------------\n",
    "\n",
    "00:00 - 00:13\n",
    "\n",
    "Now we're going to study some patterns that we can observe in the sample mean when the sample size becomes larger. These patterns form the basis of the law of large numbers.\n",
    "\n",
    "2\\. Sample mean review\n",
    "----------------------\n",
    "\n",
    "00:13 - 00:27\n",
    "\n",
    "Jakob Bernoulli developed the law of large numbers in his book Ars Conjectandi (1713). The law states that the sample mean tends to the expected value as the sample grows larger.\n",
    "\n",
    "3\\. Sample mean review (Cont.)\n",
    "------------------------------\n",
    "\n",
    "00:27 - 00:33\n",
    "\n",
    "For example, we calculate the sample mean of two values by adding the values and dividing by two.\n",
    "\n",
    "4\\. Sample mean review (Cont.)\n",
    "------------------------------\n",
    "\n",
    "00:33 - 00:39\n",
    "\n",
    "For three values, we add up the values and divide by three.\n",
    "\n",
    "5\\. Sample mean review (Cont.)\n",
    "------------------------------\n",
    "\n",
    "00:39 - 00:45\n",
    "\n",
    "If we have n samples, we add the n values and divide by n.\n",
    "\n",
    "6\\. Sample mean review (Cont.)\n",
    "------------------------------\n",
    "\n",
    "00:45 - 00:54\n",
    "\n",
    "As the sample becomes larger, the sample mean gets nearer to the population mean. Let's code a bit.\n",
    "\n",
    "7\\. Generating the sample\n",
    "-------------------------\n",
    "\n",
    "00:54 - 01:34\n",
    "\n",
    "To generate a sample of coin flips, we will use the binomial distribution. First we import the binom object and the describe method from scipy dot stats, then we generate the sample using binom dot rvs. We specify n as 1 coin flip and p as the probability of success (0.5 for a fair coin), then we specify the sample size as 250 and set random_state so we can reproduce our results. After that, we print the first 100 values from our samples.\n",
    "\n",
    "8\\. Calculating the sample mean\n",
    "-------------------------------\n",
    "\n",
    "01:34 - 01:53\n",
    "\n",
    "To calculate the sample mean we pass the sample to describe dot mean. We specify samples from 0 to 10, and we see that for the first 10 values the sample mean is 0.6. Now let's see what this process looks like with an animation.\n",
    "\n",
    "9\\. Sample mean of coin flips (Cont.)\n",
    "-------------------------------------\n",
    "\n",
    "01:53 - 02:31\n",
    "\n",
    "In this animation you see how we take the sample mean for values from 2 to 250 using the describe method. The red line represents the population mean, in this case 0.5, and the blue line is the sample mean. As you'll notice, due to the randomness of the data, the sample mean fluctuates around the population mean -- but as more data becomes available, the sample mean approaches the population mean. Let's see another example with the normal distribution.\n",
    "\n",
    "10\\. Sample mean of normal distribution\n",
    "---------------------------------------\n",
    "\n",
    "02:31 - 03:19\n",
    "\n",
    "Now we have three animated plots. At the top left we have our sample data from a normal distribution. We use one dot for each sample. At the top right we've plotted a histogram of the sample data, and at the bottom we've plotted the sample mean. In all the plots the population mean is represented with a black line and the sample mean is drawn using a red line. You can see how the red line moves and gets nearer to the population mean as more data becomes available. Enjoy the animations for a bit, and get some perspective. Now let's move on and learn how to plot the sample mean with Python.\n",
    "\n",
    "11\\. Plotting the sample mean\n",
    "-----------------------------\n",
    "\n",
    "03:19 - 03:45\n",
    "\n",
    "First we import the binom object and describe from scipy dot stats, along with matplotlib dot pyplot as plt. Then we initialize the variables, setting coin_flips to 1, p to 0.5, sample_size to 1000, and averages to an empty list.\n",
    "\n",
    "12\\. Plotting the sample mean (Cont.)\n",
    "-------------------------------------\n",
    "\n",
    "03:45 - 04:06\n",
    "\n",
    "Finally, we calculate the sample mean using describe from 0 to the i index that goes from 2 to sample_size plus 1. We store the result in the averages list using append, then we print the first 10 values.\n",
    "\n",
    "13\\. Plotting the sample mean (Cont.)\n",
    "-------------------------------------\n",
    "\n",
    "04:06 - 04:20\n",
    "\n",
    "We add a red line with plt dot axhline at the population mean and plot the averages. Then we add a legend in the upper-right corner and show our plot.\n",
    "\n",
    "14\\. Sample mean plot\n",
    "---------------------\n",
    "\n",
    "04:20 - 04:25\n",
    "\n",
    "The result is this beautiful plot that shows the law of large numbers in action.\n",
    "\n",
    "15\\. Let's practice!\n",
    "--------------------\n",
    "\n",
    "04:25 - 04:32\n",
    "\n",
    "Let's get some hands-on practice with the law of large numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183f373e",
   "metadata": {},
   "source": [
    "Generating a sample\n",
    "===================\n",
    "\n",
    "A hospital's planning department is investigating different treatments for newborns. As a data scientist you are hired to simulate the sex of 250 newborn children, and you are told that on average 50.50% are males.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import the `binom` object from `scipy.stats`.\n",
    "-   Generate a sample of 250 newborns with 50.50% probability of being male.\n",
    "-   Print the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a76f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the binom object\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Generate a sample of 250 newborn children\n",
    "sample = binom.rvs(n=1, p=0.505, size=250, random_state=42)\n",
    "\n",
    "# Show the sample values\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551d4330",
   "metadata": {},
   "source": [
    "Calculating the sample mean\n",
    "===========================\n",
    "\n",
    "Now you can calculate the sample mean for this generated sample by taking some elements from the sample.\n",
    "\n",
    "Using the `sample` variable you just created, you'll calculate the sample means of the first 10, 50, and 250 samples.\n",
    "\n",
    "The `binom` object and `describe()` method from `scipy.stats` have been imported for your convenience.\n",
    "\n",
    "Instructions 1/3\n",
    "----------------\n",
    "\n",
    "Print the sample mean of the first 10 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the sample mean of the first 10 samples\n",
    "print(describe(sample[0:10]).mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801d0790",
   "metadata": {},
   "source": [
    "Instructions 2/3\n",
    "----------------\n",
    "\n",
    "-   Print the sample mean of the first 10 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4836c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the sample mean of the first 50 samples\n",
    "print(describe(sample[0:50]).mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4185b901",
   "metadata": {},
   "source": [
    "Instructions 3/3\n",
    "----------------\n",
    "\n",
    "-   Print the sample mean of the first 50 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b6366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the sample mean of the first 250 samples\n",
    "print(describe(sample[0:250]).mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e184753e",
   "metadata": {},
   "source": [
    "Plotting the sample mean\n",
    "========================\n",
    "\n",
    "Now let's plot the sample mean, so you can see more clearly how it evolves as more data becomes available.\n",
    "\n",
    "For this exercise we'll again use the sample you generated earlier, which is available in the `sample` variable. The `binom` object and `describe()` function have already been imported for you from `scipy.stats`, and `matplotlib.pyplot` is available as `plt`.\n",
    "\n",
    "Instructions 1/3\n",
    "----------------\n",
    "\n",
    "In a `for` statement for `i` in a range that goes from `2` to `251`, do the following:\n",
    "\n",
    "-   Calculate the sample mean for the first `i` values.\n",
    "-   Use `append` to add the value to the `averages` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe4a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sample mean and store it on averages array\n",
    "averages = []\n",
    "for i in range(2, 251):\n",
    "    averages.append(describe(sample[0:i]).mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa8d3a",
   "metadata": {},
   "source": [
    "Instructions 2/3\n",
    "----------------\n",
    "\n",
    "Add a horizontal line at the mean value of the binomial distribution with `n=1` and `p=0.505`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8639b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sample mean and store it on averages array\n",
    "averages = []\n",
    "for i in range(2, 251):\n",
    "    averages.append(describe(sample[0:i]).mean)\n",
    "\n",
    "# Add population mean line and sample mean plot\n",
    "plt.axhline(binom.mean(n=1, p=0.505), color='red')\n",
    "plt.plot(averages, '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b4322b",
   "metadata": {},
   "source": [
    "Instructions 3/3\n",
    "----------------\n",
    "\n",
    "Add a legend with labels `Population mean` and `Sample mean` and show the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e91f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sample mean and store it on averages array\n",
    "averages = []\n",
    "for i in range(2, 251):\n",
    "    averages.append(describe(sample[0:i]).mean)\n",
    "\n",
    "# Add population mean line and sample mean plot\n",
    "plt.axhline(binom.mean(n=1, p=0.505), color='red')\n",
    "plt.plot(averages, '-')\n",
    "\n",
    "# Add legend\n",
    "plt.legend((\"Population mean\",\"Sample mean\"), loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a72fe",
   "metadata": {},
   "source": [
    "1\\. Adding random variables\n",
    "---------------------------\n",
    "\n",
    "00:00 - 00:11\n",
    "\n",
    "The most important result in probability and statistics is the central limit theorem. Let's take a look at what happens when you add random variables.\n",
    "\n",
    "2\\. The central limit theorem (CLT)\n",
    "-----------------------------------\n",
    "\n",
    "00:11 - 00:54\n",
    "\n",
    "The CLT states that the sum of random variables tends to a normal distribution as the number of them grows to infinity. This theorem works under certain conditions: the variables must have the same distribution, and the variables must be independent. You can start adding binomial, geometric, or even Poisson random variables, and as you add more, you get a normal distribution. Recall that random variables are independent when the outcome on one variable does not affect the outcome on the others. Let's see an example.\n",
    "\n",
    "3\\. Poisson sample generation\n",
    "-----------------------------\n",
    "\n",
    "00:54 - 01:22\n",
    "\n",
    "In an example we saw previously about a busy highway with two accidents per day on average, we modeled the number of accidents per day with a Poisson random variable. Now imagine we have the data from 1,000 days. In the following animation you can see on the left the values of our population, and on the right you can see the histogram of the population values. This is our data.\n",
    "\n",
    "4\\. Selection from population\n",
    "-----------------------------\n",
    "\n",
    "01:22 - 01:45\n",
    "\n",
    "Now we are going to take 10 values from our population many times, so we can calculate the sample mean of those values. Notice the red dots. Recall that when calculating the sample mean we are adding the values, and the central limit theorem applies to the sum of random variables that are equally distributed.\n",
    "\n",
    "5\\. Selection from population (Cont.)\n",
    "-------------------------------------\n",
    "\n",
    "01:45 - 01:57\n",
    "\n",
    "Notice the histogram of the population -- it's skewed! Now we are going to repeat this process 350 times and see the outcome.\n",
    "\n",
    "6\\. Poisson sample mean plot\n",
    "----------------------------\n",
    "\n",
    "01:57 - 02:39\n",
    "\n",
    "Take a look at these animations. At the top we have the population. We're highlighting in red the 10 randomly selected values used to calculate the sample means, and plotting those values. At the bottom left we're plotting the sample means, and at the bottom right is a histogram of the sample means. Notice that as we calculate more sample means from our population the histogram is centered at 2, which is the mean of our population, and the histogram takes on a bell shape. That is the magic of the central limit theorem. Now let's code this important result.\n",
    "\n",
    "7\\. Poisson population plot\n",
    "---------------------------\n",
    "\n",
    "02:39 - 03:11\n",
    "\n",
    "First we import poisson and describe from scipy dot stats. Then, from matplotlib we import pyplot as plt, and we import numpy as np. We generate our population with poisson dot rvs with mu equals 2, size equals 1000, and the random_state seed set to reproduce our results. Now we can plot a histogram of our population.\n",
    "\n",
    "8\\. Poisson population plot (Cont.)\n",
    "-----------------------------------\n",
    "\n",
    "03:11 - 03:17\n",
    "\n",
    "This is the plot. It's a Poisson skewed plot of our data. Next, let's plot the sample means.\n",
    "\n",
    "9\\. Sample means plot\n",
    "---------------------\n",
    "\n",
    "03:17 - 03:50\n",
    "\n",
    "We first fix our random seed make the results reproducible. We define an empty list called sample_means to store the sample mean values. Then we write a for statement to loop for and arbitrarily chosen large number of samples like, 350 times. We select 10 values from our population using np dot random dot choice and then we append the sample mean of the 10 values to the sample_means list.\n",
    "\n",
    "10\\. Sample means plot (Cont.)\n",
    "------------------------------\n",
    "\n",
    "03:50 - 04:08\n",
    "\n",
    "Outside the for statement, we add labels and a title to the plot. Finally, we plot and show the histogram. We get a plot centered at 2, which is the mean of the population, with a bell shape as we expected.\n",
    "\n",
    "11\\. Let's add random variables\n",
    "-------------------------------\n",
    "\n",
    "04:08 - 04:29\n",
    "\n",
    "We've finished with the most important results in probability and statistics. After exercising a bit with the central limit theorem, we will work on two applications of probability in data science, linear regression and logistic regression. Let's add random variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae839c03",
   "metadata": {},
   "source": [
    "Sample means\n",
    "============\n",
    "\n",
    "An important result in probability and statistics is that the shape of the distribution of the means of random variables tends to a normal distribution, which happens when you add random variables with **any** distribution with the same expected value and variance.\n",
    "\n",
    "For your convenience, we've loaded `binom` and `describe()` from the `scipy.stats` library and imported `matplotlib.pyplot` as `plt` and `numpy` as `np`. We generated a simulated population with size 1,000 that follows a binomial distribution for 10 fair coin flips and is available in the `population` variable.\n",
    "\n",
    "Instructions 1/4\n",
    "----------------\n",
    "\n",
    "Select 20 random values from the `population` using `np.random.choice()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list for sample means\n",
    "sample_means = []\n",
    "for _ in range(1500):\n",
    "\t# Take 20 values from the population\n",
    "    sample = np.random.choice(population, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779e7ba",
   "metadata": {},
   "source": [
    "Instructions 2/4\n",
    "----------------\n",
    "\n",
    "Calculate the sample mean of `sample` and add the calculated sample mean to the `sample_means` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1761eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list for sample means\n",
    "sample_means = []\n",
    "for _ in range(1500):\n",
    "\t# Take 20 values from the population\n",
    "    sample = np.random.choice(population, 20)\n",
    "    # Calculate the sample mean\n",
    "    sample_means.append(describe(sample).mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4749183",
   "metadata": {},
   "source": [
    "Instructions 3/4\n",
    "----------------\n",
    "\n",
    "Plot a histogram of the `sample_means` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d276ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list for sample means\n",
    "sample_means = []\n",
    "for _ in range(1500):\n",
    "\t# Take 20 values from the population\n",
    "    sample = np.random.choice(population, 20)\n",
    "    # Calculate the sample mean\n",
    "    sample_means.append(describe(sample).mean)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(sample_means)\n",
    "plt.xlabel(\"Sample mean values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6dd191",
   "metadata": {},
   "source": [
    "Instructions 4/4\n",
    "----------------\n",
    "\n",
    "Question\n",
    "--------\n",
    "\n",
    "Inspecting the plot, what is the distribution of the sample mean?\n",
    "\n",
    "### Possible answers\n",
    "\n",
    "Same as the generated sample\n",
    "\n",
    "Binomial\n",
    "\n",
    "[x] Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11a1de0",
   "metadata": {},
   "source": [
    "Sample means follow a normal distribution\n",
    "=========================================\n",
    "\n",
    "In the previous exercise, we generated a population that followed a binomial distribution, chose 20 random samples from the population, and calculated the sample mean. Now we're going to test some other probability distributions to see the shape of the sample means.\n",
    "\n",
    "From the `scipy.stats` library, we've loaded the `poisson` and `geom` objects and the `describe()` function. We've also imported `matplotlib.pyplot` as `plt` and `numpy` as `np`.\n",
    "\n",
    "As you'll see, the shape of the distribution of the means is the same even though the samples are generated from different distributions.\n",
    "\n",
    "Instructions 1/2\n",
    "----------------\n",
    "\n",
    "Select 20 values from the population, add the sample mean to the `sample_means` list, and plot a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the population\n",
    "population = geom.rvs(p=0.5, size=1000)\n",
    "\n",
    "# Create list for sample means\n",
    "sample_means = []\n",
    "for _ in range(3000):\n",
    "\t# Take 20 values from the population\n",
    "    sample = np.random.choice(population, 20)\n",
    "    # Calculate the sample mean\n",
    "    sample_means.append(describe(sample).mean)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(sample_means)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09287b7b",
   "metadata": {},
   "source": [
    "Instructions 2/2\n",
    "----------------\n",
    "\n",
    "-   Select 20 values from the population, add the sample mean to the `sample_means` list, and plot a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a7adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the population\n",
    "population = poisson.rvs(mu=2, size=1000)\n",
    "\n",
    "# Create list for sample means\n",
    "sample_means = []\n",
    "for _ in range(1500):\n",
    "\t# Take 20 values from the population\n",
    "     sample = np.random.choice(population, 20)\n",
    "    # Calculate the sample mean\n",
    "     sample_means.append(describe(sample).mean)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(sample_means)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de75dc7a",
   "metadata": {},
   "source": [
    "Adding dice rolls\n",
    "=================\n",
    "\n",
    "To illustrate the central limit theorem, we are going to work with dice rolls. We'll generate the samples and then add them to plot the outcome.\n",
    "\n",
    "You're provided with a function named `roll_dice()` that will generate the sample dice rolls. `numpy` is already imported as `np` for your convenience: you have to use `np.add(sample1, sample2)` to add samples. Also, `matplotlib.pyplot` is imported as `plt` so you can plot the histograms.\n",
    "\n",
    "Instructions 1/3\n",
    "----------------\n",
    "\n",
    "Generate a sample of `2000` dice rolls using `roll_dice()` and plot a histogram of the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1b8ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure random generator\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate the sample\n",
    "sample1 = roll_dice(num_rolls=2000)\n",
    "\n",
    "# Plot the sample\n",
    "plt.hist(sample1, bins=range(1, 8), width=0.9)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d457b127",
   "metadata": {},
   "source": [
    "Instructions 2/3\n",
    "----------------\n",
    "\n",
    "-   Generate a sample of `2000` dice rolls using `roll_dice()` and plot a histogram of the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure random generator\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate two samples of 2000 dice rolls\n",
    "sample1 = roll_dice(2000)\n",
    "sample2 = roll_dice(2000)\n",
    "\n",
    "# Add the first two samples\n",
    "sum_of_1_and_2 = np.add(sample1, sample2)\n",
    "\n",
    "# Plot the sum\n",
    "plt.hist(sum_of_1_and_2, bins=range(2, 14), width=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a308e732",
   "metadata": {},
   "source": [
    "Instructions 3/3\n",
    "----------------\n",
    "\n",
    "-   Add `sample1` and `sample2` using `np.add()`, store the result in the variable `sum_of_1_and_2`, then plot `sum_of_1_and_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure random generator\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate the samples\n",
    "sample1 = roll_dice(2000)\n",
    "sample2 = roll_dice(2000)\n",
    "sample3 = roll_dice(2000)  # Generate the third sample\n",
    "\n",
    "# Add the first two samples\n",
    "sum_of_1_and_2 = np.add(sample1, sample2)\n",
    "\n",
    "# Add the first two with the third sample\n",
    "sum_of_3_samples = np.add(sum_of_1_and_2, sample3)\n",
    "\n",
    "# Plot the result\n",
    "plt.hist(sum_of_3_samples, bins=range(3, 20), width=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea5e89",
   "metadata": {},
   "source": [
    "1\\. Linear regression\n",
    "---------------------\n",
    "\n",
    "00:00 - 00:12\n",
    "\n",
    "We've already finished our core content for this course, but before closing, we will take a quick look at linear regression and logistic models as applications of probability and statistics in data science.\n",
    "\n",
    "2\\. Linear functions\n",
    "--------------------\n",
    "\n",
    "00:12 - 00:25\n",
    "\n",
    "Let's start with a linear function. A linear function is a constant relationship between an independent variable x and a dependent variable y that is represented by a line.\n",
    "\n",
    "3\\. Linear function parameters\n",
    "------------------------------\n",
    "\n",
    "00:25 - 00:51\n",
    "\n",
    "The relationship is expressed with two parameters, the slope and the intercept value. When x equals 0, if we apply the line formula we get the intercept value. In our example, the slope is 1.5 and the intercept is 10. Now consider what would happen if we were to add a random number to the value of the function.\n",
    "\n",
    "4\\. Linear function with random perturbations\n",
    "---------------------------------------------\n",
    "\n",
    "00:51 - 01:01\n",
    "\n",
    "Our values are not on the line anymore. Some real data has similar behavior. Now let's go backwards.\n",
    "\n",
    "5\\. Start from the data and find a model that fits\n",
    "--------------------------------------------------\n",
    "\n",
    "01:01 - 01:21\n",
    "\n",
    "Imagine we have data that shows the relationship between hours of study and students' scores on a test. You can see in the plot that when the hours of study increase, the scores also increase. The idea is to determine if a linear model fits.\n",
    "\n",
    "6\\. What model will fit the data?\n",
    "---------------------------------\n",
    "\n",
    "01:21 - 01:31\n",
    "\n",
    "We might ask ourselves a few questions, like: What model will fit the data? What criteria can we use to determine which is the best model?\n",
    "\n",
    "7\\. What model will fit the data? (Cont.)\n",
    "-----------------------------------------\n",
    "\n",
    "01:31 - 01:40\n",
    "\n",
    "What are the parameters of such a model? Let's assume that the model is linear and try to answer the other two questions.\n",
    "\n",
    "8\\. Residuals of the model\n",
    "--------------------------\n",
    "\n",
    "01:40 - 02:00\n",
    "\n",
    "In the plot, the data are the blue dots and the green line is a linear model. These represent the difference between the data points and the model's predictions. The red lines are the distance between the data and the model. All the red lines are the residuals of the linear model.\n",
    "\n",
    "9\\. Minimizing residuals\n",
    "------------------------\n",
    "\n",
    "02:00 - 02:20\n",
    "\n",
    "If we calculate the residuals and add them up, we can start looking for the slope and intercept that minimize the residuals. That is the foundation for many models in data science: we look for the model parameters that minimize the distance between the model and the data.\n",
    "\n",
    "10\\. Probability and statistics in action\n",
    "-----------------------------------------\n",
    "\n",
    "02:20 - 02:42\n",
    "\n",
    "An interesting link between probability and the linear model is that to apply this model to data you must study the distribution of the residuals and its variance. The distribution of the residuals should be normal with constant variance. Otherwise, the linear model is not a good fit. Let's code a bit.\n",
    "\n",
    "11\\. Calculating linear model parameters\n",
    "----------------------------------------\n",
    "\n",
    "02:42 - 03:13\n",
    "\n",
    "To get the parameters from a model we will use the LinearRegression class from sklearn dot linear_model. We use the provided data for hours of study and scores. Then we get the slope and intercept in model dot coef_ and model dot intercept_. In our case the slope is 1.5 and the intercept is 52.45. Now let's predict with our model.\n",
    "\n",
    "12\\. Predicting scores based on hours of study\n",
    "----------------------------------------------\n",
    "\n",
    "03:13 - 03:40\n",
    "\n",
    "After fitting the model, we can predict the scores based on hours of study. If we want to predict the score for someone who studies a certain number of hours, we call model dot predict and pass an array with the values we want to evaluate. For 15 hours we get 74.90 as the predicted score. Now let's plot our model.\n",
    "\n",
    "13\\. Plotting the linear model\n",
    "------------------------------\n",
    "\n",
    "03:40 - 04:05\n",
    "\n",
    "We first import matplotlib dot pyplot as plt. We use plt dot scatter to plot the data in hours_of_study and scores, and we use plt dot plot to plot the provided values and model dot predict to generate the predicted scores. Then we show our plot.\n",
    "\n",
    "14\\. Plot the linear model (Cont.)\n",
    "----------------------------------\n",
    "\n",
    "04:05 - 04:13\n",
    "\n",
    "The result is this plot with a linear relation between hours of study and scores, with minimal error.\n",
    "\n",
    "15\\. Let's practice with linear models\n",
    "--------------------------------------\n",
    "\n",
    "04:13 - 04:19\n",
    "\n",
    "Now, let's move on and practice with linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f6d3bb",
   "metadata": {},
   "source": [
    "Fitting a model\n",
    "===============\n",
    "\n",
    "A university has provided you with data that shows a relationship between the hours of study and the scores that the students get on a given test.\n",
    "\n",
    "You have access to the data through the variables `hours_of_study` and `scores`. Use a linear model to learn from the data.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import the `linregress()` function from `scipy.stats`.\n",
    "-   Fit a linear model using the provided data in the `hours_of_study` and `scores` variables.\n",
    "-   Print the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the linregress() function\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Get the model parameters\n",
    "slope, intercept, r_value, p_value, std_err = linregress(hours_of_study, scores)\n",
    "\n",
    "\n",
    "# Print the linear model parameters\n",
    "print('slope:', slope)\n",
    "print('intercept:', intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36662f66",
   "metadata": {},
   "source": [
    "Predicting test scores\n",
    "======================\n",
    "\n",
    "With the relationship between the hours of study and the scores that students got on a given test, you already got the parameters of a linear model, `slope` and `intercept`. With those parameters, let's predict the test score for a student who studies for 10 hours.\n",
    "\n",
    "For this exercise, the `linregress()` function has been imported for you from `scipy.stats`.\n",
    "\n",
    "Instructions 1/3\n",
    "----------------\n",
    "\n",
    "Predict the test score for `10` hours of study using the provided parameters in `slope` and `intercept`, then print the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e5cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted test score for given hours of study\n",
    "score = slope*10 + intercept\n",
    "print('score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdfe5f7",
   "metadata": {},
   "source": [
    "Instructions 2/3\n",
    "----------------\n",
    "\n",
    "-   Predict the test score for `10` hours of study using the provided parameters in `slope` and `intercept`, then print the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf606297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted test score for given hours of study\n",
    "score = slope*9 + intercept\n",
    "print('score:', score)\n",
    "score: 63.70809994642248"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ee73e",
   "metadata": {},
   "source": [
    "Instructions 3/3\n",
    "----------------\n",
    "\n",
    "-   Now predict the score for `9` hours of study using the parameters in `slope` and `intercept`, then print the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99456186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted test score for given hours of study\n",
    "score = slope*12 + intercept\n",
    "print('score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a8827d",
   "metadata": {},
   "source": [
    "Studying residuals\n",
    "==================\n",
    "\n",
    "To implement a linear model you must study the **residuals**, which are the distances between the predicted outcomes and the data.\n",
    "\n",
    "Three conditions must be met:\n",
    "\n",
    "1.  The mean should be 0.\n",
    "2.  The variance must be constant.\n",
    "3.  The distribution must be normal.\n",
    "\n",
    "We will work with data of test scores for two schools, A and B, on the same subject. `model_A` and `model_B` were fitted with `hours_of_study_A` and `test_scores_A` and `hours_of_study_B` and `test_scores_B`, respectively.\n",
    "\n",
    "`matplotlib.pyplot` has been imported as `plt`, `numpy` as `np` and `LinearRegression` from `sklearn.linear_model`.\n",
    "\n",
    "Instructions 1/4\n",
    "----------------\n",
    "\n",
    "Make a scatter of `hours_of_study_A` and `test_scores_A` and plot `hours_of_study_values_A` and the outcomes from `model_A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5095c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of hours of study and test scores\n",
    "plt.scatter(hours_of_study_A, test_scores_A)\n",
    "\n",
    "# Plot of hours_of_study_values_A and predicted values\n",
    "plt.plot(hours_of_study_values_A, model_A.predict(hours_of_study_values_A))\n",
    "plt.title(\"Model A\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd06c81",
   "metadata": {},
   "source": [
    "Instructions 2/4\n",
    "----------------\n",
    "\n",
    "-   Make a scatter of `hours_of_study_A` and `test_scores_A` and plot `hours_of_study_values_A` and the outcomes from `model_A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals\n",
    "residuals_A = model_A.predict(hours_of_study_A) - test_scores_A\n",
    "\n",
    "# Make a scatterplot of residuals of model_A\n",
    "plt.scatter(hours_of_study_A, residuals_A)\n",
    "\n",
    "# Add reference line and title and show plot\n",
    "plt.hlines(0, 0, 30, colors='r', linestyles='--')\n",
    "plt.title(\"Residuals plot of Model A\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a450e",
   "metadata": {},
   "source": [
    "Instructions 3/4\n",
    "----------------\n",
    "\n",
    "-   Subtract the predicted values and `test_scores_A`, then make a scatterplot with `hours_of_study_A` and `residuals_A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ed9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of hours of study and test scores\n",
    "plt.scatter(hours_of_study_B, test_scores_B)\n",
    "\n",
    "# Plot of hours_of_study_values_B and predicted values\n",
    "plt.plot(hours_of_study_values_B, model_B.predict(hours_of_study_values_B))\n",
    "plt.title(\"Model B\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e60a5c",
   "metadata": {},
   "source": [
    "Instructions 4/4\n",
    "----------------\n",
    "\n",
    "-   Make a scatter of `hours_of_study_B` and `test_scores_B` and plot `hours_of_study_values_B` and the outcomes from `model_B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals\n",
    "residuals_B = model_B.predict(hours_of_study_B) - test_scores_B\n",
    "\n",
    "# Make a scatterplot of residuals of model_B\n",
    "plt.scatter(hours_of_study_B, residuals_B)\n",
    "\n",
    "# Add reference line and title and show plot\n",
    "plt.hlines(0, 0, 30, colors='r', linestyles='--')\n",
    "plt.title(\"Residuals plot of Model B\", fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d56048",
   "metadata": {},
   "source": [
    "1\\. Logistic regression\n",
    "-----------------------\n",
    "\n",
    "00:00 - 00:27\n",
    "\n",
    "This is our final lesson of the course -- we're going to work with the logistic regression model. Suppose a university has provided you with data on students' test scores and the hours of study they put in before the test. The logistic model will allow you to classify and predict based on the hours of study how likely it is that a student will pass the test. Let's get started!\n",
    "\n",
    "2\\. Original data\n",
    "-----------------\n",
    "\n",
    "00:27 - 00:45\n",
    "\n",
    "A plot of a sample of the original data looks like this. Now, for this first exercise, let's say that the data provided is not the actual scores but, based on the hours of study, whether a student passed or failed the test.\n",
    "\n",
    "3\\. New data\n",
    "------------\n",
    "\n",
    "00:45 - 00:53\n",
    "\n",
    "So, for each student you have the hours of study and only two possible values, pass or fail.\n",
    "\n",
    "4\\. Where would you draw the line?\n",
    "----------------------------------\n",
    "\n",
    "00:53 - 01:13\n",
    "\n",
    "In this case, where would you draw the line to classify between pass or fail based on the hours of study? You could put it at 10 or 11 or even 12, but depending on where you draw the line you will have some misclassified values.\n",
    "\n",
    "5\\. Solution based on probability\n",
    "---------------------------------\n",
    "\n",
    "01:13 - 01:32\n",
    "\n",
    "To draw the line, we need a function that will provide probabilities based on the hours of study. So, the model will provide the probability, which is a value between 0 and 1 for each value of hours of study. This means we have to change our scale.\n",
    "\n",
    "6\\. The logistic function\n",
    "-------------------------\n",
    "\n",
    "01:32 - 01:54\n",
    "\n",
    "The function we need is the logistic function, also called sigmoid. This function: Will throw values from 0 to 1 Will get values based on a linear model using the slope and intercept So, we pass it a linear model and the logistic function returns probabilities.\n",
    "\n",
    "7\\. Changing the slope\n",
    "----------------------\n",
    "\n",
    "01:54 - 02:15\n",
    "\n",
    "From now on we will call the slope of the linear model beta1 and the intercept beta0. If we study the effect of the parameters we can see that increasing beta1 (the slope) will make the logistic function steeper, or more aggressive to classify at a certain value of x.\n",
    "\n",
    "8\\. Changing the intercept\n",
    "--------------------------\n",
    "\n",
    "02:15 - 02:27\n",
    "\n",
    "On the other hand, adjusting the parameter beta0 (intercept), will translate the function left or right on the x-axis. This is how you draw the line.\n",
    "\n",
    "9\\. From data to probability\n",
    "----------------------------\n",
    "\n",
    "02:27 - 02:36\n",
    "\n",
    "So, for each value we will get the probability of passing the test based on the hours of study applying the logistic model parameters.\n",
    "\n",
    "10\\. Outcomes\n",
    "-------------\n",
    "\n",
    "02:36 - 02:50\n",
    "\n",
    "We can say that if the probability is higher than 0.5 we will consider that the outcome is a pass, and otherwise it's a fail. You can see the predicted outcomes of the model in red.\n",
    "\n",
    "11\\. Misclassifications\n",
    "-----------------------\n",
    "\n",
    "02:50 - 03:19\n",
    "\n",
    "But if we compare the model's predictions with the actual outcomes, we can see that there are some misclassifications between 11 and 12 hours of study. Based on the model, we can say that if a student studies less than 10 hours the probability of them passing the test is very low, and if they study 13 hours or more they have a high probability of passing the test. Now let's code a bit.\n",
    "\n",
    "12\\. Logistic regression\n",
    "------------------------\n",
    "\n",
    "03:19 - 04:03\n",
    "\n",
    "To run a logistic regression model we will use scikit-learn -- in particular, the LogisticRegression class. We create our model with LogisticRegression and pass the C parameter as 1e9. This parameter helps keep the model from overfitting to the data. Then we call model.fit with our data. We create variables to get the parameters from model dot coef_ and model dot intercept_. The parameters from the model are arrays, so we extract the values from the arrays. Finally, we print the values.\n",
    "\n",
    "13\\. Predicting outcomes based on hours of study\n",
    "------------------------------------------------\n",
    "\n",
    "04:03 - 04:25\n",
    "\n",
    "If we want to predict the outcome based on a provided number of hours of study, we pass the hours of study to model dot predict and we get the predicted outcome. Notice that the outcomes are an array, so we can pass many values to test and we'll get an array with the outcome for each value provided.\n",
    "\n",
    "14\\. Probability calculation\n",
    "----------------------------\n",
    "\n",
    "04:25 - 04:47\n",
    "\n",
    "If you instead are curious about the probability of passing with a particular number of hours of study, you can use model dot predict_proba. You pass it an array with the values you want to calculate. For 9 hours, we have approximately 0.05 probability of passing.\n",
    "\n",
    "15\\. Let's practice!\n",
    "--------------------\n",
    "\n",
    "04:47 - 04:53\n",
    "\n",
    "It's been great working with the logistic model -- now let's practice some more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd15cde",
   "metadata": {},
   "source": [
    "Fitting a logistic model\n",
    "========================\n",
    "\n",
    "The university studying the relationship between hours of study and outcomes on a given test has provided you with a dataset containing the number of hours the students studied and whether they failed or passed the test, and asked you to fit a model to predict future performance.\n",
    "\n",
    "The data is provided in the variables `hours_of_study` and `outcomes`. Use this data to fit a `LogisticRegression` model. `numpy` has been imported as `np` for your convenience.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import `LogisticRegression` from `sklearn.linear_model`.\n",
    "-   Create the model using `LogisticRegression(C=1e9)`.\n",
    "-   Pass the data to the `model.fit()` method.\n",
    "-   Create variables for each parameter, assign the values from the model, and print the parameters `beta1` and `beta0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c1727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sklearn logistic model\n",
    "model = LogisticRegression(C=1e9)\n",
    "model.fit(hours_of_study, outcomes)\n",
    "\n",
    "# Get parameters\n",
    "beta1 = model.coef_[0][0]\n",
    "beta0 = model.intercept_[0]\n",
    "\n",
    "# Print parameters\n",
    "print(beta1, beta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e681ce",
   "metadata": {},
   "source": [
    "Predicting if students will pass\n",
    "================================\n",
    "\n",
    "In the previous exercise you calculated the parameters of the logistic regression model that fits the data of hours of study and test outcomes.\n",
    "\n",
    "With those parameters you can predict the performance of students based on their hours of study. Use `model.predict()` to get the outcomes based on the logistic regression.\n",
    "\n",
    "For your convenience, `LogisticRegression` has been imported from `sklearn.linear_model` and `numpy` has been imported as `np`.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Create an array with the values 10, 11, 12, 13, and 14 to predict the outcomes for a test based on those numbers of hours of study.\n",
    "-   Use `model.predict()` to get the outcomes from the model, and print the outcomes.\n",
    "-   Use `model.predict_proba()` to get the probability of passing the test with 11 hours of study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a7b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify values to predict\n",
    "hours_of_study_test = [[10], [11], [12], [13], [14]]\n",
    "\n",
    "# Pass values to predict\n",
    "predicted_outcomes = model.predict(hours_of_study_test)\n",
    "print(predicted_outcomes)\n",
    "\n",
    "# Set value in array\n",
    "value = np.asarray(11).reshape(-1,1)\n",
    "# Probability of passing the test with 11 hours of study\n",
    "print(\"Probability of passing test \", model.predict_proba(value)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8564cb",
   "metadata": {},
   "source": [
    "Passing two tests\n",
    "=================\n",
    "\n",
    "Put yourself in the shoes of one of the university students. You have two tests coming up in different subjects, and you're running out of time to study. You want to know how much time you have to study each subject to maximize the probability of passing both tests. Fortunately, there's data that you can use.\n",
    "\n",
    "For subject A, you already fitted a logistic model in `model_A`, and for subject B you fitted a model in `model_B`. As well as preloading `LogisticRegression` from `sklearn.linear_model` and `numpy` as `np`, `expit()`, the inverse of the logistic function, has been imported for you from `scipy.special`.\n",
    "\n",
    "Instructions 1/4\n",
    "----------------\n",
    "\n",
    "Use `model_A` to predict if you'll pass the test with 6, 7, 8, 9, or 10 hours of study and `model_B` with 3, 4, 5, or 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a338074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify values to predict\n",
    "hours_of_study_test_A = [[6], [7], [8], [9], [10]]\n",
    "\n",
    "# Pass values to predict\n",
    "predicted_outcomes_A = model_A.predict(hours_of_study_test_A)\n",
    "print(predicted_outcomes_A)\n",
    "\n",
    "# Specify values to predict\n",
    "hours_of_study_test_B = [[3], [4], [5], [6]]\n",
    "\n",
    "# Pass values to predict\n",
    "predicted_outcomes_B = model_B.predict(hours_of_study_test_B)\n",
    "print(predicted_outcomes_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60334c7",
   "metadata": {},
   "source": [
    "Instructions 2/4\n",
    "----------------\n",
    "\n",
    "-   Use `model_A` to predict if you'll pass the test with 6, 7, 8, 9, or 10 hours of study and `model_B` with 3, 4, 5, or 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a2e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set value in array\n",
    "value_A = np.asarray([8.6]).reshape(-1,1)\n",
    "# Probability of passing test A with 8.6 hours of study\n",
    "print(\"The probability of passing test A with 8.6 hours of study is \", model_A.predict_proba(value_A)[:,1])\n",
    "\n",
    "\n",
    "# Set value in array\n",
    "value_B = np.asarray([4.7]).reshape(-1,1)\n",
    "# Probability of passing test B with 4.7 hours of study\n",
    "print(\"The probability of passing test B with 4.7 hours of study is \", model_B.predict_proba(value_B)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc89cc",
   "metadata": {},
   "source": [
    "Instructions 3/4\n",
    "----------------\n",
    "\n",
    "-   Get the probability of passing for test A with 8.6 hours of study and test B with 4.7 hours of study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fbcf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the hours required to have 0.5 probability on model_A\n",
    "print(\"Minimum hours of study for test A are \", -model_A.intercept_/model_A.coef_)\n",
    "\n",
    "# Print the hours required to have 0.5 probability on model_B\n",
    "print(\"Minimum hours of study for test B are \", -model_B.intercept_/model_B.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af8e00",
   "metadata": {},
   "source": [
    "Instructions 4/4\n",
    "----------------\n",
    "\n",
    "-   Calculate the hours you need to study to have 0.5 probability of passing the test using the formula `-intercept/slope`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005320ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability calculation for each value of study_hours\n",
    "prob_passing_A = model_A.predict_proba(study_hours_A.reshape(-1,1))[:,1]\n",
    "prob_passing_B = model_B.predict_proba(study_hours_B.reshape(-1,1))[:,1]\n",
    "\n",
    "# Calculate the probability of passing both tests\n",
    "prob_passing_A_and_B = prob_passing_A * prob_passing_B\n",
    "\n",
    "# Maximum probability value\n",
    "max_prob = max(prob_passing_A_and_B)\n",
    "\n",
    "# Position where we get the maximum value\n",
    "max_position = np.where(prob_passing_A_and_B == max_prob)[0][0]\n",
    "\n",
    "# Study hours for each test\n",
    "print(\"Study {:1.0f} hours for the first and {:1.0f} hours for the second test and you will pass both tests with {:01.2f} probability.\".format(study_hours_A[max_position], study_hours_B[max_position], max_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88900a41",
   "metadata": {},
   "source": [
    "1\\. Wrapping up\n",
    "---------------\n",
    "\n",
    "00:00 - 00:07\n",
    "\n",
    "Congratulations, you made it to the end of the course!! We've covered a lot of ground.\n",
    "\n",
    "2\\. Fundamental concepts\n",
    "------------------------\n",
    "\n",
    "00:07 - 00:26\n",
    "\n",
    "We learned to simulate random variables in order to review the fundamental concepts of probability, such as density, distributions, expected values, sample means, variance, joint probability of dependent and independent events, and conditional probability using Bayes' rule.\n",
    "\n",
    "3\\. Important probability distributions\n",
    "---------------------------------------\n",
    "\n",
    "00:26 - 00:35\n",
    "\n",
    "We reviewed some of the most important probability distributions, such as binomial, geometric, Poisson, and normal distributions.\n",
    "\n",
    "4\\. The most important results\n",
    "------------------------------\n",
    "\n",
    "00:35 - 00:44\n",
    "\n",
    "We also studied the most important laws of probability: the law of large numbers and the central limit theorem.\n",
    "\n",
    "5\\. Linear and logistic regression\n",
    "----------------------------------\n",
    "\n",
    "00:44 - 01:05\n",
    "\n",
    "Finally, we applied those concepts in data science and reviewed linear regression and logistic regression, fitting models, and predicting. There's a lot more to study, and other DataCamp courses go into much more depth on many of the topics we've covered.\n",
    "\n",
    "6\\. Keep learning at DataCamp!\n",
    "------------------------------\n",
    "\n",
    "01:05 - 01:40\n",
    "\n",
    "To really understand and get to grips with all the methods you've seen in this course, it's important to apply them with real data. Only with practice will you truly master the content. By relating these methods to real-life situations you can gain a deeper understanding about your context with science. There are many more courses at DataCamp you can work through to deepen your understanding about probability and statistics. Keep going and good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
