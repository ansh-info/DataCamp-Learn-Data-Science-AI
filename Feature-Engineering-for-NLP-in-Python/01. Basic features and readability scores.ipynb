{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Introduction to NLP feature engineering\n",
    "-------------------------------------------\n",
    "\n",
    "00:00 - 00:18\n",
    "\n",
    "Welcome to Feature Engineering for NLP in Python! I am Rounak and I will be your instructor for this course. In this course, you will learn to extract useful features out of text and convert them into formats that are suitable for machine learning algorithms.\n",
    "\n",
    "2\\. Numerical data\n",
    "------------------\n",
    "\n",
    "00:18 - 00:44\n",
    "\n",
    "For any ML algorithm, data fed into it must be in tabular form and all the training features must be numerical. Consider the Iris dataset. Every training instance has exactly four numerical features. The ML algorithm uses these four features to train and predict if an instance belongs to class iris-virginica, iris-setosa or iris-versicolor.\n",
    "\n",
    "```markdown\n",
    "# Iris dataset\n",
    "\n",
    "| sepal length | sepal width | petal length | petal width | class           |\n",
    "|--------------|-------------|--------------|-------------|-----------------|\n",
    "| 6.3          | 2.9         | 5.6          | 1.8         | Iris-virginica  |\n",
    "| 4.9          | 3.0         | 1.4          | 0.2         | Iris-setosa     |\n",
    "| 5.6          | 2.9         | 3.6          | 1.3         | Iris-versicolor |\n",
    "| 6.0          | 2.7         | 5.1          | 1.6         | Iris-versicolor |\n",
    "| 7.2          | 3.6         | 6.1          | 2.5         | Iris-virginica  |\n",
    "```\n",
    "\n",
    "3\\. One-hot encoding\n",
    "--------------------\n",
    "\n",
    "00:44 - 01:01\n",
    "\n",
    "ML algorithms can also work with categorical data provided they are converted into numerical form through one-hot encoding. Let's say you have a categorical feature 'sex' with two categories 'male' and 'female'.\n",
    "\n",
    "```markdown\n",
    "| sex    |\n",
    "|--------|\n",
    "| female |\n",
    "| male   |\n",
    "| female |\n",
    "| male   |\n",
    "| female |\n",
    "| ...    |\n",
    "```\n",
    "\n",
    "4\\. One-hot encoding\n",
    "--------------------\n",
    "\n",
    "01:01 - 01:05\n",
    "\n",
    "One-hot encoding will convert this feature into two features,\n",
    "\n",
    "```markdown\n",
    "| sex    | one-hot encoding |\n",
    "|--------|------------------|\n",
    "| female | →                |\n",
    "| male   | →                |\n",
    "| female | →                |\n",
    "| male   | →                |\n",
    "| female | →                |\n",
    "| ...    | ...              |\n",
    "```\n",
    "\n",
    "5\\. One-hot encoding\n",
    "--------------------\n",
    "\n",
    "01:05 - 01:17\n",
    "\n",
    "'sex_male' and 'sex_female' such that each male instance has a 'sex_male' value of 1 and 'sex_female' value of 0. For females, it is the vice versa.\n",
    "\n",
    "| sex | one-hot encoding | sex_female | sex_male |\n",
    "| --- | ---------------- | ---------- | -------- |\n",
    "| female | → | 1 | 0 |\n",
    "| male | → | 0 | 1 |\n",
    "| female | → | 1 | 0 |\n",
    "| male | → | 0 | 1 |\n",
    "| female | → | 1 | 0 |\n",
    "| ... | ... | ... | ... |\n",
    "\n",
    "6\\. One-hot encoding with pandas\n",
    "--------------------------------\n",
    "\n",
    "01:17 - 01:54\n",
    "\n",
    "To do this in code, we use pandas' get_dummies() function. Let's import pandas using the alias pd. We can then pass our dataframe df into the pd.get_dummies() function and pass a list of features to be encoded as the columns argument. Not mentioning columns will lead pandas to automatically encode all non-numerical features. Finally, we overwrite the original dataframe with the encoded version by assigning the dataframe returned by get_dummies() back to df.\n",
    "\n",
    "```python\n",
    "# Import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Perform one-hot encoding on the 'sex' feature of df\n",
    "df = pd.get_dummies(df, columns=['sex'])\n",
    "```\n",
    "\n",
    "7\\. Textual data\n",
    "----------------\n",
    "\n",
    "01:54 - 02:10\n",
    "\n",
    "Consider a movie reviews dataset. This data cannot be utilized by any machine learning or ML algorithm. The training feature 'review' isn't numerical. Neither is it categorical to perform one-hot encoding on.\n",
    "\n",
    "#### Movie Review Dataset\n",
    "\n",
    "| review | class |\n",
    "| --- | --- |\n",
    "| This movie is for dog lovers. A very poignant... | positive |\n",
    "| The movie is forgettable. The plot lacked... | negative |\n",
    "| A truly amazing movie about dogs. A gripping... | positive |\n",
    "\n",
    "8\\. Text pre-processing\n",
    "-----------------------\n",
    "\n",
    "02:10 - 02:34\n",
    "\n",
    "We need to perform two steps to make this dataset suitable for ML. The first is to standardize the text. This involves steps like converting words to lowercase and their base form. For instance, 'Reduction' gets lowercased and then converted to its base form, reduce. We will cover these concepts in more detail in subsequent lessons.\n",
    "\n",
    "- Converting to lowercase\n",
    "    - Example:`Reduction` to `reduction`\n",
    "- Converting to base-form\n",
    "    - Example:`reduction` to `reduce`\n",
    "\n",
    "\n",
    "9\\. Vectorization\n",
    "-----------------\n",
    "\n",
    "02:34 - 02:48\n",
    "\n",
    "After preprocessing, the reviews are converted into a set of numerical training features through a process known as vectorization. After vectorization, our original review dataset gets converted\n",
    "\n",
    "| review | class |\n",
    "| --- | --- |\n",
    "| This movie is for dog lovers. A very poignant... | positive |\n",
    "| The movie is forgettable. The plot lacked... | negative |\n",
    "| A truly amazing movie about dogs. A gripping... | positive |\n",
    "\n",
    "10\\. Vectorization\n",
    "------------------\n",
    "\n",
    "02:48 - 02:55\n",
    "\n",
    "into something like this. We will learn techniques to achieve this in later lessons.\n",
    "\n",
    "| 0 | 1 | 2 | ... | n | class |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| 0.03 | 0.71 | 0.00 | ... | 0.22 | positive |\n",
    "| 0.45 | 0.00 | 0.03 | ... | 0.19 | negative |\n",
    "| 0.14 | 0.18 | 0.00 | ... | 0.45 | positive |\n",
    "\n",
    "11\\. Basic features\n",
    "-------------------\n",
    "\n",
    "02:55 - 03:20\n",
    "\n",
    "We can also extract certain basic features from text. It maybe useful to know the word count, character count and average word length of a particular text. While working with niche data such as tweets, it also maybe useful to know how many hashtags have been used in a tweet. This tweet by Silverado Records,for instance, uses two.\n",
    "\n",
    "- Number of words\n",
    "- Number of characters\n",
    "- Average length of words\n",
    "- Tweets\n",
    "\n",
    "```markdown\n",
    "testbook @books\n",
    "What book are ypu guys reading?\n",
    "\n",
    "#books #reading\n",
    "```\n",
    "\n",
    "12\\. POS tagging\n",
    "----------------\n",
    "\n",
    "03:20 - 03:50\n",
    "\n",
    "So far, we have seen how to extract features out of an entire body of text. Some NLP applications may require you to extract features for individual words. For instance, you may want to do parts-of-speech tagging to know the different parts-of-speech present in your text as shown. As an example, consider the sentence 'I have a dog'. POS tagging will label each word with its corresponding part-of-speech.\n",
    "\n",
    "| Word | POS |\n",
    "| --- | --- |\n",
    "| I | Pronoun |\n",
    "| have | Verb |\n",
    "| a | Article |\n",
    "| dog | Noun |\n",
    "\n",
    "13\\. Named Entity Recognition\n",
    "-----------------------------\n",
    "\n",
    "03:50 - 04:16\n",
    "\n",
    "You may also want to know perform named entity recognition to find out if a particular noun is referring to a person, organization or country. For instance, consider the sentence \"Brian works at DataCamp\". Here, there are two nouns \"Brian\" and \"DataCamp\". Brian refers to a person whereas DataCamp refers to an organization.\n",
    "\n",
    "#### Noun Reference\n",
    "\n",
    "The image asks whether nouns refer to persons, organizations, or countries.\n",
    "\n",
    "| Noun | NER |\n",
    "| --- | --- |\n",
    "| Brian | Person |\n",
    "| DataCamp | Organization |\n",
    "\n",
    "The image contains three main visual elements:\n",
    "1. A photo of a person playing a guitar, which is likely a reference to the \"Brian\" noun.\n",
    "2. A Swiss flag, which could represent a country.\n",
    "3. The TED logo, which represents the organization \"TED\".\n",
    "\n",
    "Based on the table in the image, the nouns \"Brian\" and \"DataCamp\" are classified as referring to a person and an organization, respectively. The image is prompting the viewer to consider whether nouns generally refer to persons, organizations, or countries.\n",
    "\n",
    "14\\. Concepts covered\n",
    "---------------------\n",
    "\n",
    "04:16 - 04:33\n",
    "\n",
    "Therefore, broadly speaking, this course will teach you how to conduct text preprocessing, extract certain basic features, word features and convert documents into a set of numerical features (using a process known as vectorization).\n",
    "\n",
    "- Text Preprocessing\n",
    "- Basic Features\n",
    "- Word Features\n",
    "- Vectorization\n",
    "\n",
    "\n",
    "15\\. Let's practice!\n",
    "--------------------\n",
    "\n",
    "04:33 - 04:36\n",
    "\n",
    "Great! Now, let's practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data format for ML algorithms\n",
    "=============================\n",
    "\n",
    "In this exercise, you have been given four dataframes `df1`, `df2`, `df3` and `df4`. The final column of each dataframe is the predictor variable and the rest of the columns are training features. \n",
    "\n",
    "Using the console, determine which dataframe is in a suitable format to be trained by a classifier.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "### Possible answers\n",
    "\n",
    "`df1`\n",
    "\n",
    "`df2`\n",
    "\n",
    "[/] `df3`\n",
    "\n",
    "`df4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding\n",
    "================\n",
    "\n",
    "In the previous exercise, we encountered a dataframe `df1` which contained categorical features and therefore, was unsuitable for applying ML algorithms to.\n",
    "\n",
    "In this exercise, your task is to convert `df1`into a format that is suitable for machine learning.\n",
    "\n",
    "Instructions 1/3\n",
    "----------------\n",
    "\n",
    "-   Use the `columns` attribute to print the features of `df1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 2/3\n",
    "----------------\n",
    "\n",
    "-   Use the `pd.get_dummies()` function to perform one-hot encoding on `feature 5` of `df1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the features of df1\n",
    "print(df1.columns)\n",
    "\n",
    "# Perform one-hot encoding\n",
    "df1 = pd.get_dummies(df1, columns=['feature 5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 3/3\n",
    "----------------\n",
    "\n",
    "-   Use the `columns` attribute again to print the new features of `df1`.\n",
    "-   Print the first five rows of `df1` using `head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the features of df1\n",
    "print(df1.columns)\n",
    "\n",
    "# Perform one-hot encoding\n",
    "df1 = pd.get_dummies(df1, columns=['feature 5'])\n",
    "\n",
    "# Print the new features of df1\n",
    "print(df1.columns)\n",
    "\n",
    "# Print first five rows of df1\n",
    "print(df1.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
