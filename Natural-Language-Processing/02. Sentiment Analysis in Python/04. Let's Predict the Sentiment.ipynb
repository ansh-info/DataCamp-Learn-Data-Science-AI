{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Let's predict the sentiment!\n",
    "--------------------------------\n",
    "\n",
    "00:00 - 00:07\n",
    "\n",
    "In this final chapter, we will use a supervised learning model to predict the sentiment.\n",
    "\n",
    "2\\. Classification problems\n",
    "---------------------------\n",
    "\n",
    "00:07 - 00:42\n",
    "\n",
    "Imagine we are working with the product reviews. A supervised learning task will try to classify any new review as either positive or negative based on already labeled reviews. This is what we call a classification problem. In the case of the product and movie reviews, we have two classes - positive and negative. This is a binary classification problem. The airline sentiment Twitter data has three categories of sentiment: positive, neutral and negative. This is a multi-class classification problem.\n",
    "\n",
    "3\\. Linear and logistic regressions\n",
    "-----------------------------------\n",
    "\n",
    "00:42 - 01:12\n",
    "\n",
    "One algorithm commonly applied in classification tasks is a logistic regression. You might be familiar with a linear regression, where we fit a straight line to approximate a relationship, shown in the graph on the left. With a logistic regression, instead of fitting a line, we are fitting an S-shaped curve, called a sigmoid function. A property of this function is that for any value of x, y will be between 0 and 1.\n",
    "\n",
    "4\\. Logistic function\n",
    "---------------------\n",
    "\n",
    "01:12 - 01:49\n",
    "\n",
    "When performing linear regression, we are predicting a numeric outcome (say the sale price of a house). With logistic regression, we estimate the probability that the outcome (sentiment) belongs to a particular category(positive or negative) given the review. Since we are estimating a probability and want an output between 0 and 1, we model the X values using the sigmoid/logistic function, as shown on the graph. For more details on logistic regression, refer to other courses on DataCamp.\n",
    "\n",
    "5\\. Logistic regression in Python\n",
    "---------------------------------\n",
    "\n",
    "01:49 - 02:31\n",
    "\n",
    "In Python, we import the LogisticRegression from the sklearn.linear_model library. Keep in mind that the sklearn API works only with continuous variables. It also requires either a DataFrame or an array as arguments and cannot handle missing data. Therefore, all transformation of the data needs to be completed beforehand. We call the logistic regression function and create a Logistic classifier object. We fit it by specifying the X matrix, which is an numpy array of our features or a pandas DataFrame, and the vector of targets y.\n",
    "\n",
    "6\\. Measuring model performance\n",
    "-------------------------------\n",
    "\n",
    "02:31 - 03:15\n",
    "\n",
    "How do we know if the model is any good? We look at the discrepancy between the predicted label and what was the real label for each instance (observation) in our dataset. One common metric to use is the accuracy score. Though not appropriate in all contexts, it is still useful. Accuracy gives us the fraction of predictions that our model got right. The higher and closer it is to 1, the better. One way we can calculate the accuracy score of a logistic regression model is by calling the score method on the logistic regression object. It takes as arguments the X matrix and y vector.\n",
    "\n",
    "7\\. Using accuracy score\n",
    "------------------------\n",
    "\n",
    "03:15 - 04:02\n",
    "\n",
    "Alternatively, we can use the accuracy_score function from sklearn.metrics. There is an accuracy_score function apart from the score function because different models have different default score metrics. Thus, the accuracy_score function always returns the accuracy but the score function might return other metrics if we use it to evaluate other models. Here, we need to explicitly calculate the predictions of the model, by calling predict on the matrix of features. The accuracy score takes as arguments the vector of true labels and the predicted labels. We see in the case of logistic regression, both score and accuracy score return value of 0.9009.\n",
    "\n",
    "8\\. Let's practice!\n",
    "-------------------\n",
    "\n",
    "04:02 - 04:19\n",
    "\n",
    "Can we trust such high accuracy? We should be careful in making strong conclusions just yet. In the next video, we will see how to check how robust the model performance is but before that, let's solve some exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression of movie reviews\n",
    "====================================\n",
    "\n",
    "In the video we learned that logistic regression is a common way to model a classification task, such as classifying the sentiment as positive or negative. \n",
    "\n",
    "In this exercise, you will work with the `movies`reviews dataset. The `label` column stores the sentiment, which is `1` when the review is positive, and `0` when negative. The text review has been transformed, using BOW, to numeric columns. \n",
    "\n",
    "Your task is to build a logistic regression model using the `movies` dataset and calculate its accuracy.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import the logistic regression function.\n",
    "-   Create and fit a logistic regression on the labels `y` and the features `X`.\n",
    "-   Calculate the accuracy of the logistic regression model, using the default `.score()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the vector of targets and matrix of features\n",
    "y = movies.label\n",
    "X = movies.drop('label', axis=1)\n",
    "\n",
    "# Build a logistic regression model and calculate the accuracy\n",
    "log_reg = LogisticRegression().fit(X, y)\n",
    "print('Accuracy of logistic regression: ', log_reg.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression using Twitter data\n",
    "======================================\n",
    "\n",
    "In this exercise, you will build a logistic regression model using the `tweets` dataset. The target is given by the `airline_sentiment`, which is `0` for negative tweets, `1` for neutral, and `2` for positive ones. So, in this case, you are given a multi-class classification task. Everything we learned about binary problems applies to multi-class classification problems as well. \n",
    "\n",
    "You will evaluate the accuracy of the model using the two different approaches from the slides. \n",
    "\n",
    "The logistic regression function and accuracy score have been imported for you.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Build and fit a logistic regression model using the defined `X` and `y` as arguments. \n",
    "-   Calculate the accuracy of the logistic regression model.\n",
    "-   Predict the labels.\n",
    "-   Calculate the *accuracy score* using the predicted and true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vector of targets and matrix of features\n",
    "y = tweets.airline_sentiment\n",
    "X = tweets.drop('airline_sentiment', axis=1)\n",
    "\n",
    "# Build a logistic regression model and calculate the accuracy\n",
    "log_reg = LogisticRegression().fit(X, y)\n",
    "print('Accuracy of logistic regression: ', log_reg.score(X,y))\n",
    "\n",
    "# Create an array of prediction\n",
    "y_predict = log_reg.predict(X)\n",
    "\n",
    "# Print the accuracy using accuracy score\n",
    "print('Accuracy of logistic regression: ', accuracy_score(y, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Did we really predict the sentiment well?\n",
    "---------------------------------------------\n",
    "\n",
    "00:00 - 00:17\n",
    "\n",
    "In the previous video, we used all of the available data to build a logistic regression model and assess its accuracy. However, we want to make sure our machine learning model generalizes and performs well on unseen data. How to do that?\n",
    "\n",
    "2\\. Train/test split\n",
    "--------------------\n",
    "\n",
    "00:17 - 00:54\n",
    "\n",
    "To get any idea on how well a model will perform on unseen data, we randomly split the dataset in 2 parts: one used for training (building the model) and one for testing (evaluate the performance of the model). In some cases, when we want to tune the parameters of our algorithm, we might have 3 sets: training, testing and validation, but this is out of scope for our course. The training set is usually around 70 or 80% of the whole dataset, and the rest is used for testing.\n",
    "\n",
    "3\\. Train/test in Python\n",
    "------------------------\n",
    "\n",
    "00:54 - 01:59\n",
    "\n",
    "In Python, we can perform a random train-test split using the train_test_split function from the sklearn.model_selection package. It takes as arguments arrays, lists, or DataFrames. The X-train and test matrices and y-train and test vectors are the output of the train_test_split. The first arguments we provide in the function are the features matrix X and labels vector y. We can specify the proportion of the data going to testing; here, it is equal to 0.2. Another parameter is the random state, which is the seed generator used to make the random split. It ensures that every time you perform the train-test split on the same data, you will get the same instances in each set. We can also specify the stratify argument. If we want to ensure that the train and test set have similar proportions of both classes, we can do that by specifying stratify to be equal to y.\n",
    "\n",
    "4\\. Logistic regression with train/test split\n",
    "---------------------------------------------\n",
    "\n",
    "01:59 - 02:32\n",
    "\n",
    "Let's revisit our logistic regression example, executed after a train-test split. We create the LogisticRegression object and fit it on the training set. We can calculate the accuracy on the training data, calling score on the logistic regression with arguments X_train and y_train. We can also calculate the accuracy score of the model using the test set - X_test and y_test. It is slightly lower than the accuracy on the training data, which is usually the case.\n",
    "\n",
    "5\\. Accuracy score with train/test split\n",
    "----------------------------------------\n",
    "\n",
    "02:32 - 02:59\n",
    "\n",
    "You may recall that another way to calculate the accuracy was to use the accuracy_score function from the sklearn.metrics. After we have built the logistic regression model, we apply predict to the logistic regression specifying X_test as an argument. In the last step, we call the accuracy score on the true and predicted labels. The value is identical to the accuracy produced by the score function.\n",
    "\n",
    "6\\. Confusion matrix\n",
    "--------------------\n",
    "\n",
    "02:59 - 03:33\n",
    "\n",
    "The accuracy is a useful measure of a model's performance but it's not always the most informative. We can instead use something called a 'confusion matrix'. It shows the number of predicted and true values of each of the classes, as displayed in the table. A confusion matrix will allow us to calculate the values in each cell and say how many observations of each class we have predicted correctly. For more details of when we would want to optimize for the different cells, refer to other DataCamp courses.\n",
    "\n",
    "7\\. Confusion matrix in Python\n",
    "------------------------------\n",
    "\n",
    "03:33 - 04:00\n",
    "\n",
    "In Python, we import the confusion_matrix from the sklearn.metrics module. After we have built our logistic regression and predicted the test set labels, we call the confusion matrix where we give as arguments the true and predicted labels. We have divided the matrix by the length of the y-vector in order to obtain proportions in the cells of the matrix.\n",
    "\n",
    "8\\. Let's practice!\n",
    "-------------------\n",
    "\n",
    "04:00 - 04:04\n",
    "\n",
    "Now let's solve some exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and assess a model: movies reviews\n",
    "========================================\n",
    "\n",
    "In this problem, you will build a logistic regression model using the `movies` dataset. The score is stored in the `label` column and is `1` when the review is positive, and `0` when negative. The text review has been transformed, using BOW, to numeric columns. \n",
    "\n",
    "You have already built a classifier but evaluated it using the same data employed in the training step. Make sure you now assess the model using an unseen test dataset. How does the performance of the model change when evaluated on the test set?\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import the function required for a train/test split.\n",
    "-   Perform the train/test split, specifying that 20% of the data should be used as a test set.\n",
    "-   Train a logistic regression model.\n",
    "-   Print out the accuracy of the model on the training and on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the vector of labels and matrix of features\n",
    "y = movies.label\n",
    "X = movies.drop('label', axis=1)\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a logistic regression model and print out the accuracy\n",
    "log_reg = LogisticRegression().fit(X_train,y_train)\n",
    "print('Accuracy on train set: ', log_reg.score(X_train, y_train))\n",
    "print('Accuracy on test set: ', log_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance metrics of Twitter data\n",
    "===================================\n",
    "\n",
    "You will train a logistic regression model that predicts the sentiment of tweets and evaluate its performance on the test set using different metrics. \n",
    "\n",
    "A matrix `X` has been created for you. It contains features created with a BOW on the `text` column.\n",
    "\n",
    "The labels are stored in a vector called `y`. Vector `y` is `0` for negative tweets, `1` for neutral, and `2` for positive ones.\\\n",
    "Note that although we have 3 classes, it is still a classification problem. The accuracy still measures the proportion of correctly predicted instances. The confusion matrix will now be of size 3x3, each row will give the number of predicted cases for classes 2, 1, and 0, and each column - the true number of cases in class 2, 1, and 0. \n",
    "\n",
    "All required packages have been imported for you.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Perform the train/test split, and stratify by `y`.\n",
    "-   Train a a logistic regression classifier.\n",
    "-   Predict the performance on the test set.\n",
    "-   Print the accuracy score and confusion matrix obtained on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "\n",
    "# Train a logistic regression\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predicted = log_reg.predict(X_test)\n",
    "\n",
    "# Print the performance metrics\n",
    "print('Accuracy score test set: ', accuracy_score(y_test, y_predicted))\n",
    "print('Confusion matrix test set: \\n', confusion_matrix(y_test, y_predicted)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and assess a model: product reviews data\n",
    "==============================================\n",
    "\n",
    "In this exercise, you will build a logistic regression using the `reviews` dataset, containing customers' reviews of Amazon products. The array `y` contains the sentiment : `1` if positive and `0` otherwise. The array `X`contains all numeric features created using a BOW approach. Feel free to explore them in the IPython Shell.\n",
    "\n",
    "Your task is to build a logistic regression model and calculate the accuracy and confusion matrix using the test dataset. \n",
    "\n",
    "The logistic regression and train/test splitting functions have been imported for you.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import the accuracy score and confusion matrix functions.\n",
    "-   Split the data into training and testing, using 30% of it as a test set and set the random seed to `42`. \n",
    "-   Train a logistic regression model.\n",
    "-   Print out the accuracy score and confusion matrix using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the accuracy and confusion matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=42)\n",
    "\n",
    "# Build a logistic regression\n",
    "log_reg = LogisticRegression().fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels \n",
    "y_predict = log_reg.predict(X_test)\n",
    "\n",
    "# Print the performance metrics\n",
    "print('Accuracy score of test data: ', accuracy_score(y_test, y_predict))\n",
    "print('Confusion matrix of test data: \\n', confusion_matrix(y_test, y_predict)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Logistic regression: revisited\n",
    "----------------------------------\n",
    "\n",
    "00:00 - 00:14\n",
    "\n",
    "Before we build a logistic regression using text features, we transformed the text fields to numeric columns. As a result, we might end up having hundreds or even thousands of features, which can make the model quite complex.\n",
    "\n",
    "2\\. Complex models and regularization\n",
    "-------------------------------------\n",
    "\n",
    "00:14 - 01:03\n",
    "\n",
    "A complex model can occur in a few scenarios. If we use a very complicated function to explain the relationship of interest, we will inevitably fit the noise in the data. Such a model will not perform well when used to score unseen data. This is also called overfitting. A complex model could stem from including too many unnecessary features and parameters; especially with transformed text data, where we might create thousands of extra numeric columns. These two sources of complexity often go hand-in-hand. One way to artificially discourage complex models is by the use of regularization. When using regularization, we are penalizing, or restricting the function of the model.\n",
    "\n",
    "3\\. Regularization in a logistic regression\n",
    "-------------------------------------------\n",
    "\n",
    "01:03 - 02:11\n",
    "\n",
    "Regularization is applied by default in the logistic regression function from sklearn. It uses the so-called L2 penalty; the details of it are outside of the scope of this course, but intuitively it's good to know that the L2 penalty shrinks all the coefficients towards zero, effectively reducing the impact of each feature. The parameter that determines the strength of regularization is given by C, which takes a default value of 1. Higher values of C correspond to less regularization, in other words, the model will try to fit the data as best as possible. Small values of C correspond to high penalization(or regularization), meaning that the coefficients of the logistic regression will be closer to zero; the model will be less flexible because it will not fit the training data so well. How to find the most appropriate value of C? Usually we need to test different values and see which one gives us the best performance on the test data.\n",
    "\n",
    "4\\. Predicting a probability vs. predicting a class\n",
    "---------------------------------------------------\n",
    "\n",
    "02:11 - 02:39\n",
    "\n",
    "You should recall that when we trained a logistic regression model, we applied the predict function to the test set to predict the labels. The predict function predicts a class: 0 or 1 if we are working with a binary classifier. However, instead of a class, we can predict a probability using the predict_proba function. We again pass as an argument the test dataset.\n",
    "\n",
    "5\\. Predicting a probability vs. predicting a class\n",
    "---------------------------------------------------\n",
    "\n",
    "02:39 - 03:07\n",
    "\n",
    "This returns an array of probabilities, ordered by the label of classes - first the class 0 then the class 1. The probabilities for each observation are displayed on a separate row. The first value is the probability that the instance is of class 0, and the second of a class 1. Therefore, is is common when predicting the probabilities to specify already that we want to extract the probabilities of the class 1.\n",
    "\n",
    "6\\. Model metrics with predicted probabilities\n",
    "----------------------------------------------\n",
    "\n",
    "03:07 - 04:06\n",
    "\n",
    "One important thing to know is that we cannot directly apply the accuracy score or confusion matrix to the predicted probabilities. If you do that in sklearn, you will get a ValueError. The reason is that the accuracy and the confusion matrix work directly with classes. If we have predicted probabilities, we need to encode them as classes. The default is that any probability higher or equal to 0.5 is translated to class 1, otherwise to class 0. However, you can change that threshold depending on your problem. Imagine only 1% of the reviews are positive and you have built a model to predict whether a new review is positive or negative. In that context, you don't want to translate any predicted probability higher than 0.5 to class 1, this threshold should be much lower.\n",
    "\n",
    "7\\. Let's practice!\n",
    "-------------------\n",
    "\n",
    "04:06 - 04:11\n",
    "\n",
    "Let's apply what we've learned in the exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict probabilities of movie reviews\n",
    "======================================\n",
    "\n",
    "In this problem, you will build a logistic regression using the `movies` dataset. The labels are stored in the array`y` and the features in `X`.\n",
    "\n",
    "Train the model on the training data. Instead of predicting classes, predict the probabilities that each instance in the test set belongs to each of the two classes.\n",
    "\n",
    "The logistic regression and train/test splitting functions have been imported for you.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Split the data into training and testing set.\n",
    "-   Train a logistic regression model.\n",
    "-   Predict the probabilities for class 0 and for class 1 of the testing data. Class 0 is located as the first column in the predicted probabilities, and class 1 is the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=321)\n",
    "\n",
    "# Train a logistic regression\n",
    "log_reg = LogisticRegression().fit(X_train,y_train)\n",
    "\n",
    "# Predict the probability of the 0 class\n",
    "prob_0 = log_reg.predict_proba(X_test)[:, 0]\n",
    "# Predict the probability of the 1 class\n",
    "prob_1 = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"First 10 predicted probabilities of class 0: \", prob_0[:10])\n",
    "print(\"First 10 predicted probabilities of class 1: \", prob_1[:10])\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product reviews with regularization\n",
    "===================================\n",
    "\n",
    "In this exercise, you will work once more with the `reviews` dataset of Amazon product reviews. A vector of labels `y` contains the sentiment : `1` if positive and `0` otherwise. The matrix `X` contains all numeric features created using a BOW approach. \n",
    "\n",
    "You will need to train two logistic regression models with different levels of regularization and compare how they perform on the test data. Remember that regularization is a way to control the complexity of the model. The more regularized a model is, the less flexible it is but the better it can generalize. Models with higher level of regularization are often less accurate than non-regularized ones.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Split the data into a train and test sets.\n",
    "-   Train a logistic regression with regularization parameter of `1000`. Train a second logistic regression with regularization parameter equal to `0.001`.\n",
    "-   Print the accuracy scores of both models on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Train a logistic regression with regularization of 1000\n",
    "log_reg1 = LogisticRegression(C=1000).fit(X_train, y_train)\n",
    "# Train a logistic regression with regularization of 0.001\n",
    "log_reg2 = LogisticRegression(C=0.001).fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracies\n",
    "print('Accuracy of model 1: ', log_reg1.score(X_test, y_test))\n",
    "print('Accuracy of model 2: ', log_reg2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularizing models with Twitter data\n",
    "=====================================\n",
    "\n",
    "You will work with the Twitter data expressing customers' sentiment about airline companies. The `X` matrix of features and `y` vector of labels have been created for you. In addition, the training and testing split has been performed. You can work with the `X_train`, `X_test`, `y_train` and `y_test` arrays directly. \n",
    "\n",
    "You will train regularized and a more flexible models and evaluate them using different model performance metrics.\n",
    "\n",
    "All required packages have been imported for you.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Train two logistic regressions: one with regularization parameter of 100 and a second of 0.1.\n",
    "-   Print the accuracy scores of both models.\n",
    "-   Print the confusion matrix of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a logistic regression with regularizarion parameter of 100\n",
    "log_reg1 = LogisticRegression(C=100).fit(X_train,y_train)\n",
    "# Build a logistic regression with regularizarion parameter of 0.1\n",
    "log_reg2 = LogisticRegression(C=0.1).fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels for each model\n",
    "y_predict1 = log_reg1.predict(X_test)\n",
    "y_predict2 = log_reg2.predict(X_test)\n",
    "\n",
    "# Print performance metrics for each model\n",
    "print('Accuracy of model 1: ', accuracy_score(y_test, y_predict1))\n",
    "print('Accuracy of model 2: ', accuracy_score(y_test, y_predict2))\n",
    "print('Confusion matrix of model 1: \\n' , confusion_matrix(y_test, y_predict1)/len(y_test))\n",
    "print('Confusion matrix of model 2: \\n', confusion_matrix(y_test, y_predict2)/len(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
