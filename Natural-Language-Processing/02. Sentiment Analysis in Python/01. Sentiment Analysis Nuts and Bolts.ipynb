{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Welcome!\n",
    "------------\n",
    "\n",
    "00:00 - 00:15\n",
    "\n",
    "Welcome to the course! In this course, we will build upon some of your Python skills and introduce methods for sentiment analysis using movie and product reviews, Twitter data and a lot of literary examples.\n",
    "\n",
    "2\\. What is sentiment analysis?\n",
    "-------------------------------\n",
    "\n",
    "00:15 - 00:34\n",
    "\n",
    "Let's start with defining what sentiment analysis is. Sentiment analysis, also called opinion mining, is the process of understanding the opinion of an author about a subject. In other words, \"What is the emotion or opinion of the author of the text about the subject discussed?\"\n",
    "\n",
    "3\\. What goes into a sentiment analysis system?\n",
    "-----------------------------------------------\n",
    "\n",
    "00:34 - 01:02\n",
    "\n",
    "In a sentiment analysis system, depending on the context, we usually have 3 elements: First is the opinion or an emotion. An opinion (also called \"polarity\") can be positive, neutral or negative. An emotion could be qualitative (like joy, surprise, or anger) or quantitative (like rating a movie on the scale from 1 to 10).\n",
    "\n",
    "4\\. What goes into a sentiment analysis system?\n",
    "-----------------------------------------------\n",
    "\n",
    "01:02 - 01:30\n",
    "\n",
    "The second element in a sentiment analysis system is the subject that is being talked about, such as a book, a movie, or a product. Sometimes one opinion could discuss multiple aspects of the same subject. For example: \"The camera on this phone is great but its battery life is rather disappointing.\"\" The third element is the opinion holder, or entity, expressing the opinion.\n",
    "\n",
    "5\\. Why sentiment analysis?\n",
    "---------------------------\n",
    "\n",
    "01:30 - 02:15\n",
    "\n",
    "Sentiment analysis has many practical applications. In social media monitoring, we don't just want to know if people are talking about a brand; we want to know how they are talking about it. Social media isn't our only source of information; we can also find sentiment on forums, blogs, and the news. Most brands analyze all of these sources to enrich their understanding of how customers interact with their brand, what they are happy or unhappy about, and what matters most to consumers. Sentiment analysis is thus very important in brand monitoring, and in fields such as customer and product analytics and market research and analysis.\n",
    "\n",
    "6\\. Let's look at movie reviews!\n",
    "--------------------------------\n",
    "\n",
    "02:15 - 02:37\n",
    "\n",
    "Let's look at the first dataset we will use in this course: a sample of IMDB movie reviews. We have two columns: one for the text of the review, and a second one called \"label\", which expresses the overall sentiment: the category or class 1 means positive and 0 means negative.\n",
    "\n",
    "7\\. How many positive and negative reviews?\n",
    "-------------------------------------------\n",
    "\n",
    "02:37 - 02:55\n",
    "\n",
    "Let's find out how many positive and negative reviews we have in the data. To do this, we call the .value_counts() method on the \"label\" column. The output is the number of negative reviews (the 0 class) and positive reviews (the class 1).\n",
    "\n",
    "8\\. Percentage of positive and negative reviews\n",
    "-----------------------------------------------\n",
    "\n",
    "02:55 - 03:11\n",
    "\n",
    "If we want to see the number of positives and negatives as a percentage, we can divide the expression by the number of rows, which we obtain with the len() method. We see that the sample is rather balanced: around half of the reviews are positive and half are negative.\n",
    "\n",
    "9\\. How long is the longest review?\n",
    "-----------------------------------\n",
    "\n",
    "03:11 - 03:52\n",
    "\n",
    "How long is the longest review? To find that, we create a pandas Series called length_reviews by selecting the review column of the dataset, followed by .str.len(). Str is short for string. We need to call the string function to transform the Series of reviews to a string. If we skip it, we get an AttributeError when the len() function is called. The result returns a pandas Series with the number of characters in each review. To find the length of the longest review, we need to call the max() function on the length_reviews Series.\n",
    "\n",
    "10\\. How long is the shortest review?\n",
    "-------------------------------------\n",
    "\n",
    "03:52 - 03:59\n",
    "\n",
    "To find the shortest review, we call the min() function on the length_reviews Series, instead of the max() function.\n",
    "\n",
    "11\\. Let's practice!\n",
    "--------------------\n",
    "\n",
    "03:59 - 04:03\n",
    "\n",
    "Let's practice what we've learned in the exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elements of a sentiment analysis problem\n",
    "========================================\n",
    "\n",
    "What are the three typical elements of a sentiment analysis system?\n",
    "\n",
    "##### Answer the question\n",
    "\n",
    "#### Possible Answers\n",
    "\n",
    "Select one answer\n",
    "\n",
    "[/] -   Opinion, emotion, and subject.\n",
    "\n",
    "-   Opinion, subject, and opinion holder.\n",
    "\n",
    "-   Emotion, polarity, and opinion.\n",
    "\n",
    "-   Opinion, subject, and polarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many positive and negative reviews are there?\n",
    "=================================================\n",
    "\n",
    "As a first step in a sentiment analysis task, similar to other data science problems, we might want to explore the dataset in more detail.\n",
    "\n",
    "You will work with a sample of the IMDB movies reviews. A dataset called `movies` has been created for you. It is a sample of the data we saw in the slides. Feel free to explore it in the IPython Shell, calling the `.head()` method, for example.\n",
    "\n",
    "*Be aware that this exercise uses real data, and as such there is always a risk that it may contain profanity or other offensive content (in this exercise, and any following exercises that also use real data).*\n",
    "\n",
    "\n",
    "-   Find the number of positive and negative reviews in the `movies` dataset.\n",
    "-   Find the proportion (percentage) of positive and negative reviews in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of positive and negative reviews\n",
    "print('Number of positive and negative reviews: ', movies.label.value_counts())\n",
    "\n",
    "# Find the proportion of positive and negative reviews\n",
    "print('Proportion of positive and negative reviews: ', movies.label.value_counts() / len(movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Longest and shortest reviews\n",
    "============================\n",
    "\n",
    "In this exercise, you will continue to work with the `movies` dataset. You explored how many positive and negative reviews there are. Now your task is to explore the `review` column in more detail.\n",
    "\n",
    "Instructions 1/2\n",
    "----------------\n",
    "\n",
    "-   Use the `review` column of the `movies` dataset to find the length of the longest review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_reviews = movies.review.str.len()\n",
    "\n",
    "# How long is the longest review\n",
    "print(max(length_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 2/2\n",
    "----------------\n",
    "\n",
    "-   Use the `review` column of the `movies` dataset to find the length of the longest review.\n",
    "\n",
    "-   Similarly, find the length of the shortest review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_reviews = movies.review.str.len()\n",
    "\n",
    "# How long is the shortest review\n",
    "print(min(length_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Sentiment analysis types and approaches\n",
    "-------------------------------------------\n",
    "\n",
    "00:00 - 00:11\n",
    "\n",
    "Welcome back! In the previous video, we learned what sentiment analysis is and why it is useful. But how do we even start with a sentiment analysis task?\n",
    "\n",
    "2\\. Levels of granularity\n",
    "-------------------------\n",
    "\n",
    "00:11 - 01:01\n",
    "\n",
    "Sentiment analysis tasks can be carried out at different levels of granularity. First is document level. This is when we look at the whole review of a product, for example. Second is the sentence level. This refers to determining whether the opinion expressed in each sentence is positive, negative, or neutral. The last level of granularity is the aspect level. The aspect refers to expressing opinions about different features of a product. Imagine a sentence such as \"The camera in this phone is pretty good but the battery life is disappointing.\" It expresses both positive and negative opinions about a phone and we might want to be able to say which features of the product clients like and which they don't.\n",
    "\n",
    "3\\. Type of sentiment analysis algorithms\n",
    "-----------------------------------------\n",
    "\n",
    "01:01 - 02:12\n",
    "\n",
    "The algorithms used for sentiment analysis could be split into 2 main categories. The first is rule or lexicon based. Such methods most commonly have a predefined list of words with a valence score. For example, nice could be +2, good +1, terrible -3, and so on. The algorithm then matches the words from the lexicon to the words in the text and either sums or averages the scores in some way. As an example, let's take the sentence, 'Today was a good day.' Each word gets a score, and to get the total valence we sum the words. In this case, we have a positive sentence. A second category is automated systems, which are based on machine learning. This is going to be our focus in this course. The task is usually modeled as a classification problem where using some historical data with known sentiment, we need to predict the sentiment of a new piece of text.\n",
    "\n",
    "4\\. What is the valence of a sentence?\n",
    "--------------------------------------\n",
    "\n",
    "02:12 - 03:22\n",
    "\n",
    "We can calculate the valence score of a text, using Python's textblob library. We continue working with our 'Today was a good day' string. We import the TextBlob function from the textblob package and apply it to our string. A TextBlob object is like a Python string, which has obtained some natural language processing skills. We can call different properties of the TextBlob object. We are interested in its sentiment; that's why we call sentiment on our TextBlob. The sentiment property returns a tuple: polarity, which is measured on the scale from [-1.0 to 1.0], where -1.0 is very negative, 0 is neutral and +1.0 is very positive. Our example 'Today was a good day' carries positive emotion and thus will have a positive polarity score: 0.7. The second element in the tuple displays the subjectivity, measured from [0.0 to 1.0] where 0.0 is very objective and 1.0 is very subjective. So our example is rather positive and subjective.\n",
    "\n",
    "5\\. Automated or rule-based?\n",
    "----------------------------\n",
    "\n",
    "03:22 - 04:11\n",
    "\n",
    "Which method should one use? A machine learning sentiment analysis relies on having labeled historical data whereas lexicon-based methods rely on having manually created rules or dictionaries. Lexicon-based methods fail at certain tasks because the polarity of words might change with the problem, which will not be reflected in a predefined dictionary. However, lexicon-based approaches can be quite fast, whereas Machine learning models might take a while to train. At the same time, machine learning models can be quite powerful. So, the jury is still out on that one. Many people find that a hybrid approach tends to work best in many, usually complex scenarios.\n",
    "\n",
    "6\\. Let's practice!\n",
    "-------------------\n",
    "\n",
    "04:11 - 04:16\n",
    "\n",
    "Now let's test what we've learned by solving some exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting the sentiment of Tale of Two Cities\n",
    "=============================================\n",
    "\n",
    "In the video we saw that one type of algorithms for detecting the sentiment are based on a lexicon of predefined words and their corresponding polarity score. Your task in this exercise is to detect the sentiment, including polarity and subjectivity of a given string using such a rule-based approach and the `textblob`library in Python.\n",
    "\n",
    "You will work with the `two_cities` string. It contains the first sentence of Dickens's *A Tale of Two Cities* novel. Feel free to explore it in the Shell.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Create a text blob object from the `two_cities` string.\n",
    "-   Print out the polarity and subjectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Create a textblob object  \n",
    "blob_two_cities = TextBlob(two_cities)\n",
    "\n",
    "# Print out the sentiment \n",
    "print(blob_two_cities.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the sentiment of two strings\n",
    "======================================\n",
    "\n",
    "In this exercise, you will compare the sentiment of two different strings. A string called `annak`has been defined for you and it contains the first sentence of *Anna Karenina*. A second string called `catcher` has been created and it contains the first sentence of *The Catcher in the Rye*. Feel free to explore both in the IPython Shell.\n",
    "\n",
    "Your task is again to detect the sentiment of each string - both their polarity and subjectivity. Which one has higher sentiment score? Did you expect that to be the case?\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import the required function from the appropriate package.\n",
    "-   Create a text blob object from the `annak`string.\n",
    "-   Create a text blob from the `catcher` string as well.\n",
    "-   Print out the polarity and subjectivity of each of the created blobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Create a textblob object \n",
    "blob_annak = TextBlob(annak)\n",
    "blob_catcher = TextBlob(catcher)\n",
    "\n",
    "# Print out the sentiment   \n",
    "print('Sentiment of annak: ', blob_annak.sentiment)\n",
    "print('Sentiment of catcher: ', blob_catcher.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the sentiment of a movie review?\n",
    "========================================\n",
    "\n",
    "In a previous exercise, you detected the sentiment of the first sentence of the *Tale of Two Cities* novel by Dickens. Now you will continue to work with the **movie reviews**dataset. Do you remember how you found the longest and shortest reviews? One of the longest reviews has been imported for you. It is called `titanic` as it discusses the Titanic movie. Feel free to explore it in the Shell.\n",
    "\n",
    "Can you calculate the polarity and subjectivity of the `titanic` string? This review is positive (i.e. has a `label` of `1`). Is the polarity score also positive?\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import the required functionality. \n",
    "-   Create a text blob object from the `titanic`string.\n",
    "-   Print out the result of its sentiment property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Create a textblob object  \n",
    "blob_titanic = TextBlob(titanic)\n",
    "\n",
    "# Print out its sentiment  \n",
    "print(blob_titanic.sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
