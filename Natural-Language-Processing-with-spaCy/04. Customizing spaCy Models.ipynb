{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Customizing spaCy models\n",
    "----------------------------\n",
    "\n",
    "00:00 - 00:14\n",
    "\n",
    "Welcome! We have learned to use spaCy model functionality such as POS taggers and NER. We'll now learn about situations where we might seek to customize spaCy models.\n",
    "\n",
    "2\\. Why train spaCy models?\n",
    "---------------------------\n",
    "\n",
    "00:14 - 01:42\n",
    "\n",
    "spaCy models go a long way for general NLP use cases such as splitting a document into sentences, understanding sentence syntax, and extracting named entities. However, sometimes we seek to work on text data from specific domains that spaCy models haven't seen during their training. For example, Twitter data can contain hashtags or emotions, which may not have any specific meaning outside the Twitter platform. Additionally, Twitter sentences are usually just phrases and not full sentences. As a result, we might observe low quality sentence segmentation results from this data if we use of-the-shelf spaCy models. Similarly, text data from the medical domain typically contains several named entities, such as drugs and diseases. We don't expect these entities to be classified accurately using existing spaCy NER models, because the models don't generally contain disease or drug entity labels and they will perform poorly on such domain data. In such scenarios, it is worthwhile to train a spaCy model using our own domain-specific text data. The snapshot shows an example of a NER model results that is trained on medical domain data and hence performs well.\n",
    "\n",
    "Go a long way for general NLP use cases\n",
    "\n",
    "But may not have seen specific domains data during their training, e.g.\n",
    "- Twitter data\n",
    "- Medical data\n",
    "\n",
    "```\n",
    "PAST MEDICAL HISTORY: Significant for history of pulmonary fibrosis DISEASE and atrial fibrillation DISEASE. He is status post bilateral lung transplant back in 2004 because of the pulmonary fibrosis DISEASE.\n",
    "\n",
    "ALLERGIES: There are no known allergies.\n",
    "\n",
    "MEDICATIONS: Include multiple medications that are significant for his lung transplant including Prograf, CellCept CHEMICAL, prednisone CHEMICAL, omeprazole CHEMICAL, Bactrim CHEMICAL which he is on chronically, folic acid CHEMICAL, vitamin D CHEMICAL, Mag-Ox, Toprol-XL, calcium CHEMICAL 500 mg DOSAGE, vitamin B1, Centrum Silver, verapamil CHEMICAL, and digoxin CHEMICAL.\n",
    "```\n",
    "\n",
    "3\\. Why train spaCy models?\n",
    "---------------------------\n",
    "\n",
    "01:42 - 02:06\n",
    "\n",
    "We can usually make the model more accurate by showing it examples from our domain and we often also want to predict categories specific to our problem. Before starting to train, we need to ask the following questions. Do spaCy models perform well enough on our data? and does our domain include many labels that are absent in the spaCy models?\n",
    "\n",
    "Better results on your specific domain\n",
    "\n",
    "Essential for domain specific text classification\n",
    "\n",
    "Before start training, ask the following questions:\n",
    "\n",
    "- Do spaCy models perform well enough on our data?\n",
    "- Does our domain include many labels that are absent in spaCy models?\n",
    "\n",
    "4\\. Models performance on our data\n",
    "----------------------------------\n",
    "\n",
    "02:06 - 03:20\n",
    "\n",
    "To determine if training is needed, let's start with the question of whether existing spaCy models perform well enough on our data. If they do, we can use existing models in our NLP pipeline. However, there are multiple scenarios where the existing models do not perform as expected. For example, an en_core_web_sm spaCy model will not be able to correctly classify Oxford Street in \"The car was navigating to the Oxford Street.\" as a location with a GPE label, instead, it identifies this location as an organization with an ORG label. This is because the model did not observe similar location examples during its training phase, but might have observed Oxford in the title of organizations, hence it confuses this GPE entity with one that has an ORG type. If such behavior is observed from a spaCy model, we should train this spaCy model further to improve model performance.\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"The car was navigating to the Oxford Street.\"\n",
    "doc = nlp(text)\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "```\n",
    "\n",
    "• Do spaCy models perform well enough on our data?\n",
    "• Oxford Street is not correctly classified with a GPE label:\n",
    "\n",
    "`[('the Oxford Street', 'ORG')]`\n",
    "\n",
    "5\\. Output labels in spaCy models\n",
    "---------------------------------\n",
    "\n",
    "03:20 - 03:56\n",
    "\n",
    "Before rushing to train our own models, we also need to confirm if there are missing output labels in the existing spaCy models or not. The snapshot shows an example of NER entities on the common English domain on the top and an example of medical domain on the bottom. Common domain entities (LOC, ORG, DATE) that are used for training of existing spaCy models are considerably different from medical domain entities (DISEASE, DOSAGE, CHEMICAL).\n",
    "\n",
    "• Does our domain include many labels that are absent in spaCy models?\n",
    "\n",
    "Market Analysis Text:\n",
    "```\n",
    "In fact, the Chinese[NORP] market has the three[CARDINAL] most influential names of the retail and tech space - Alibaba[GPE], Baidu[ORG], and Tencent[PERSON] (collectively touted as BAT[ORG]), and is betting big in the global AI[GPE] in retail industry space. The three[CARDINAL] giants which are claimed to have a cut-throat competition with the U.S.[GPE] (in terms of resources and capital) are positioning themselves to become the future AI[PERSON] platforms. The trio is also expanding in other Asian[NORP] countries and investing heavily in the U.S.[GPE] based AI[GPE] startups to leverage the power of AI[GPE]. Backed by such powerful initiatives and presence of these conglomerates, the market in APAC AI is forecast to be the fastest-growing one[CARDINAL], with an anticipated CAGR[PERSON] of 45%[PERCENT] over 2018-2024[DATE].\n",
    "```\n",
    "\n",
    "Medical History Text:\n",
    "```\n",
    "PAST MEDICAL HISTORY: Significant for history of pulmonary fibrosis[DISEASE] and atrial fibrillation[DISEASE]. He is status post bilateral lung transplant back in 2004 because of the pulmonary fibrosis[DISEASE].\n",
    "\n",
    "ALLERGIES: There are no known allergies.\n",
    "\n",
    "MEDICATIONS: Include multiple medications that are significant for his lung transplant including Prograf, CellCept[CHEMICAL], prednisone[CHEMICAL], omeprazole[CHEMICAL], Bactrim[CHEMICAL] which he is on chronically, folic acid[CHEMICAL], vitamin D[CHEMICAL], Mag-Ox, Toprol-XL, calcium[CHEMICAL] 500 mg[DOSAGE], vitamin B1, Centrum Silver, verapamil[CHEMICAL], and digoxin[CHEMICAL].\n",
    "```\n",
    "\n",
    "6\\. Output labels in spaCy models\n",
    "---------------------------------\n",
    "\n",
    "03:56 - 04:20\n",
    "\n",
    "It is clear that the existing spaCy models do not have many of the output labels for an NER task on medical domain data and do not perform well on our data. In such case, we'll need to first collect our domain specific data, annotate our data and then update an existing model or train a model from scratch with our data.\n",
    "\n",
    "If we need custom model training, we follow these steps:\n",
    "\n",
    "• Collect our domain specific data\n",
    "• Annotate our data \n",
    "• Determine to update an existing model or train a model from scratch\n",
    "\n",
    "7\\. Let's practice!\n",
    "-------------------\n",
    "\n",
    "04:20 - 04:28\n",
    "\n",
    "Great! Let's practice and then begin our journey of training spaCy models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training spaCy models\n",
    "=====================\n",
    "\n",
    "spaCy models go a long way for general NLP use cases such as splitting a document into sentences, understanding sentence syntax, and extracting named entities. However, sometimes you seek to train a spaCy model. \n",
    "\n",
    "When do you need to train a spaCy model? Please select all options that apply.\n",
    "\n",
    "##### Answer the question\n",
    "\n",
    "#### Possible Answers\n",
    "\n",
    "Select all correct answers\n",
    "\n",
    "[/] Models do not include many labels for your specific domain.\n",
    "\n",
    "[] Models perform well on your data out-of-the-box.\n",
    "\n",
    "[/] The accuracy of the spaCy model on your data is unacceptably low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performance on your data\n",
    "==============================\n",
    "\n",
    "In this exercise, you will practice evaluating an existing model on your data. In this case, the aim is to examine model performance on a specific entity label, `PRODUCT`. If a model can accurately classify a large percentage of `PRODUCT` entities (e.g. more than 75%), you do not need to train the model on examples of `PRODUCT` entities, otherwise, you should consider training the model to improve its performance on `PRODUCT` entity prediction.\n",
    "\n",
    "You'll use two reviews from the Amazon Fine Food Reviews dataset for this exercise. You can access these reviews by using the `texts` list. \n",
    "\n",
    "The `en_core_web_sm` model is already loaded for you. You can access it by calling `nlp()`. The model is already ran on the `texts` list and `documents`, a list of `Doc` containers is available for your use.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Compile a `target_entities` list, of all the entities for each of the `documents`, and append a tuple of (entities text, entities label) only if `Jumbo` is in the entity text.\n",
    "-   For any tuple in the `target_entities`, append `True` to a `correct_labels` list if the entity label (second attribute in the tuple) is `PRODUCT`, otherwise append `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append a tuple of (entities text, entities label) if Jumbo is in the entity\n",
    "target_entities = []\n",
    "for doc in documents:\n",
    "  target_entities.extend([(ent.text, ent.label_) for ent in doc.ents if \"Jumbo\" in ent.text])\n",
    "print(target_entities)\n",
    "\n",
    "# Append True to the correct_labels list if the entity label is `PRODUCT`\n",
    "correct_labels = []\n",
    "for ent in target_entities:\n",
    "  if ent[1] == \"PRODUCT\":\n",
    "    correct_labels.append(True)\n",
    "  else:\n",
    "    correct_labels.append(False)\n",
    "print(correct_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Training data preparation\n",
    "-----------------------------\n",
    "\n",
    "00:00 - 00:11\n",
    "\n",
    "Welcome! Now that we have learned how to identify whether training a spaCy model is necessary, let's learn how to prepare training data.\n",
    "\n",
    "2\\. Training steps\n",
    "------------------\n",
    "\n",
    "00:11 - 00:57\n",
    "\n",
    "spaCy allows us to update existing models using examples from our own annotated data. To do so, we initialize a spaCy model, either with weights from an existing model, or random values. Next, we predict a batch of examples with the current weights. The model then checks the predictions against the correct answers we provide and aims at optimizing the weights to achieve better results. Optimizer objects will be used in this stage, we will learn more about them later on. We then move on to next batch of examples, and spaCy continues calling the model to predict another batch of examples in the data and refine the weights.\n",
    "\n",
    "1. Annotate and prepare input data\n",
    "2. Initialize the model weight\n",
    "3. Predict a few examples with the current weights \n",
    "4. Compare prediction with correct answers\n",
    "5. Use optimizer to calculate weights that improve model performance\n",
    "6. Update weights slightly\n",
    "7. Go back to step 3.\n",
    "\n",
    "3\\. Annotating and preparing data\n",
    "---------------------------------\n",
    "\n",
    "00:57 - 01:50\n",
    "\n",
    "It is clear now that the first step of training a model is always preparing training data. spaCy model training code works with dictionaries. After collecting data, we annotate data in the required format for a spaCy model. Annotation means labeling the intent, entities, POS tags, and so on. We can see an example of an annotated data record for a NER task in the medical domain. The annotated data has two key value pairs. The first attribute records the input text with a \"sentence\" key and the second attribute captures all the labeled entities of the input text with an \"entities\" key. In this instance, there is only one labeled entity with the entity type of \"Medicine\".\n",
    "\n",
    "• First step is to prepare training data in required format\n",
    "• After collecting data, we annotate it\n",
    "• Annotation means labeling the intent, entities, etc.\n",
    "• This is an example of annotated data:\n",
    "\n",
    "```python\n",
    "annotated_data = {\n",
    "    \"sentence\": \"An antiviral drugs used against influenza is neuraminidase inhibitors.\",\n",
    "    \"entities\": {\n",
    "        \"label\": \"Medicine\",\n",
    "        \"value\": \"neuraminidase inhibitors\",\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "4\\. Annotating and preparing data\n",
    "---------------------------------\n",
    "\n",
    "01:50 - 02:22\n",
    "\n",
    "Let's check another example of an annotated data record for a NER task of the common English language. In this instance, the annotated data has two entities for the given text. In such scenarios, a list of dictionaries will be stored for the entities attribute. For example, the first element captures the Bill Gates entity with the type PERSON and the second element shows the SFO Airport entity with the type LOC (location).\n",
    "\n",
    "• Here's another example of annotated data:\n",
    "\n",
    "```python\n",
    "annotated_data = {\n",
    "    \"sentence\": \"Bill Gates visited the SFO Airport.\",\n",
    "    \"entities\": [{\"label\": \"PERSON\", \"value\": \"Bill Gates\"},\n",
    "                 {\"label\": \"LOC\", \"value\": \"SFO Airport\"}]\n",
    "}\n",
    "```\n",
    "\n",
    "5\\. spaCy training data format\n",
    "------------------------------\n",
    "\n",
    "02:22 - 03:05\n",
    "\n",
    "The goal of data annotation is to prepare training data and point the spaCy model to what we want the model to learn. This annotated data has to be stored as a dictionary format and we also need to provide start and end characters of the text span with a given label. Let's see an example of a training dataset. This dataset consists of three example pairs for a named entity recognition task. Each example pair includes a sentence as the first element. The second element of the pair is a list of annotated entities and their corresponding start and end characters and labels.\n",
    "\n",
    "• Data annotation prepares training data for what we want the model to learn\n",
    "• Training dataset has to be stored as a dictionary:\n",
    "\n",
    "```python\n",
    "training_data = [\n",
    "(\"I will visit you in Austin.\", {\"entities\": [(20, 26, \"GPE\")]}),\n",
    "(\"I'm going to Sam's house.\", {\"entities\": [(13,18, \"PERSON\"), (19, 24, \"GPE\")]}),\n",
    "(\"I will go.\", {\"entities\": []})\n",
    "]\n",
    "```\n",
    "\n",
    "Three example pairs:\n",
    "• Each example pair includes a sentence as the first element\n",
    "• Pair's second element is list of annotated entities and start and end characters\n",
    "\n",
    "6\\. Example object data for training\n",
    "------------------------------------\n",
    "\n",
    "03:05 - 04:11\n",
    "\n",
    "We cannot feed the raw text and annotations directly to spaCy and need to create an Example object for each training example. Let's check an example for a NER model. Let's assume we have a training data point we want to feed to our NER component to ensure the model will correctly predict Austin as GPE (Geopolitical entity). First, we will convert the associated text to a Doc container, and then use the Example class from spaCy to convert the Doc container and the relevant annotation to an Example object which is compatible for training with spaCy. For this purpose, we use Example-dot-from_dict() method and pass two arguments: the Doc container and the annotations dictionary. We can view attributes that are processed and stored at the example object by using the example-dot-to_dict() method.\n",
    "\n",
    "• We cannot feed the raw text directly to spaCy\n",
    "• We need to create an Example object for each training example\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"I will visit you in Austin.\")\n",
    "annotations = {\"entities\": [(20, 26, \"GPE\")]}\n",
    "\n",
    "example_sentence = Example.from_dict(doc, annotations)\n",
    "print(example_sentence.to_dict())\n",
    "```\n",
    "\n",
    "7\\. Let's practice!\n",
    "-------------------\n",
    "\n",
    "04:11 - 04:24\n",
    "\n",
    "Great! We learned about the training data format and the Example object that converts a training data to a compatible format for training a spaCy model. Let's practice our learnings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training steps\n",
    "\n",
    "You may work on very specific domains that spaCy models didn't see during training such as the medical domain. spaCy allows to update existing models with more examples from your own data to improve the model performance on our own data. \n",
    "\n",
    "100XP\n",
    "\n",
    "-   Organize and order the given steps for training a spaCy model for a single epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training steps\n",
    "\n",
    "You may work on very specific domains that spaCy models didn't see during training such as the medical domain. spaCy allows to update existing models with more examples from your own data to improve the model performance on our own data. \n",
    "\n",
    "100XP\n",
    "\n",
    "-   Organize and order the given steps for training a spaCy model for a single epoch.\n",
    "\n",
    "1. Annotate and/or prepare input data\n",
    "2. Initialize model weights randomly or from an existing model\n",
    "3. Predict a few examples using the current weights\n",
    "4. Compare predictions with correct answers\n",
    "5. Use optimizer to calculate weights that increase the chance of correct predictions\n",
    "6. Update weights slightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation and preparing training data\n",
    "======================================\n",
    "\n",
    "After collecting data, you can annotate data in the required format for a spaCy model. In this exercise, you will practice forming the correct annotated data record for an NER task in the medical domain.\n",
    "\n",
    "A `sentence` and two entities of `entity_1`with a text of `chest pain` and a `SYMPTOM`type and `entity_2` with a text of `hyperthyroidism` and a `DISEASE` type are available for you to use.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Complete the `annotated_data` record in the correct format.\n",
    "-   Extract start and end characters of each entity and store as the corresponding variables.\n",
    "-   Store the same input sentence and its entities in the proper training format as `training_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A patient with chest pain had hyperthyroidism.\"\n",
    "entity_1 = \"chest pain\"\n",
    "entity_2 = \"hyperthyroidism\"\n",
    "\n",
    "# Store annotated data information in the correct format\n",
    "annotated_data = {\"sentence\": text, \"entities\": [{\"label\": \"SYMPTOM\", \"value\": entity_1}, {\"label\": \"DISEASE\", \"value\": entity_2}]}\n",
    "\n",
    "# Extract start and end characters of each entity\n",
    "entity_1_start_char = text.index(entity_1)\n",
    "entity_1_end_char = entity_1_start_char + len(entity_1)\n",
    "entity_2_start_char = text.index(entity_2)\n",
    "entity_2_end_char = entity_2_start_char + len(entity_2)\n",
    "\n",
    "# Store the same input information in the proper format for training\n",
    "training_data = [(text, {\"entities\": [(entity_1_start_char, entity_1_end_char, \"SYMPTOM\"), \n",
    "                                      (entity_2_start_char, entity_2_end_char, \"DISEASE\")]})]\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compatible training data\n",
    "========================\n",
    "\n",
    "Recall that you cannot feed the raw text directly to `spaCy`. Instead, you need to create an `Example` object for each training example. In this exercise, you will practice converting a `training_data` with a single annotated sentence into a list of `Example` objects.\n",
    "\n",
    "`en_core_web_sm` model is already imported and ready for use as `nlp`. The `Example` class is also imported for your use.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Iterate through the text and annotations in the `training_data`, convert the text to a `Doc` container and store it at `doc`.\n",
    "-   Create an `Example` object using the `doc`object and the annotations of each training data point, and store it at `example_sentence`.\n",
    "-   Append `example_sentence` to a list of `all_examples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = 'A patient with chest pain had hyperthyroidism.'\n",
    "training_data = [(example_text, {'entities': [(15, 25, 'SYMPTOM'), (30, 45, 'DISEASE')]})]\n",
    "\n",
    "all_examples = []\n",
    "# Iterate through text and annotations and convert text to a Doc container\n",
    "for text, annotations in training_data:\n",
    "  doc = nlp(text)\n",
    "  \n",
    "  # Create an Example object from the doc container and annotations\n",
    "  example_sentence = Example.from_dict(doc, annotations)\n",
    "  print(example_sentence.to_dict(), \"\\n\")\n",
    "  \n",
    "  # Append the Example object to the list of all examples\n",
    "  all_examples.append(example_sentence)\n",
    "  \n",
    "print(\"Number of formatted training data: \", len(all_examples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
