{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Creating transcription helper functions\n",
    "-------------------------------------------\n",
    "\n",
    "00:00 - 00:45\n",
    "\n",
    "You've come a long way. From exploring an audio file from scratch to manipulating audio files to working with different transcription APIs. In this chapter, you're going to be putting everything you've learned together by building a proof of concept spoken language processing pipeline. Acme Studios, a technology company, has approached you to use your speech processing skills to gain insights on their customer support calls. They've sent you a handful of audio samples to explore and to see what you can find. They let you know they're not quite sure of the quality of the files or the format they're recorded in.\n",
    "\n",
    "2\\. Exploring audio files\n",
    "-------------------------\n",
    "\n",
    "00:45 - 01:07\n",
    "\n",
    "You open the folder of audio files Acme have sent through using the os module's listdir function and notice they're in the mp3 format. You've seen this before but before continuing you decide to write down a list of things you're going to do to prepare for building the proof of concept.\n",
    "\n",
    "```python\n",
    "# Import os module\n",
    "import os\n",
    "\n",
    "# Check the folder of audio files\n",
    "os.listdir(\"acme_audio_files\")\n",
    "\n",
    "# List of audio file names\n",
    "['call_1.mp3', 'call_2.mp3', 'call_3.mp3', 'call_4.mp3']\n",
    "```\n",
    "\n",
    "3\\. Preparing for the proof of concept\n",
    "--------------------------------------\n",
    "\n",
    "01:07 - 01:37\n",
    "\n",
    "The first thing will be to listen to a few of the files using your media player or PyDub's play function to get an understanding of what you're working with, and then to transcribe one as soon as possible using recognize google so you have a baseline to work off. You convert the first file to wav and transcribe but you know from previous work, doing this for every file is tedious.\n",
    "\n",
    "```python\n",
    "# Import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Import call 1 and convert to .wav\n",
    "call_1 = AudioSegment.from_file(\"acme_audio_files/call_1.mp3\")\n",
    "call_1.export(\"acme_audio_files/call_1.wav\", format=\"wav\")\n",
    "\n",
    "# Transcribe call 1\n",
    "recognizer = sr.Recognizer()\n",
    "call_1_file = sr.AudioFile(\"acme_audio_files/call_1.wav\")\n",
    "\n",
    "with call_1_file as source:\n",
    "    call_1_audio = recognizer.record(call_1_file)\n",
    "    recognizer.recognize_google(call_1_audio)\n",
    "```\n",
    "\n",
    "4\\. Functions we'll create\n",
    "--------------------------\n",
    "\n",
    "01:37 - 01:54\n",
    "\n",
    "You decide it's a good idea to create functions which will help you for the rest of the proof of concept. One to convert files to wav format, one to find stats of an audio file using PyDub and another to transcribe an audio file using recognize google.\n",
    "\n",
    "### Convert non-.wav files to .wav format\n",
    "`convert_to_wav()` converts non-.wav files to .wav files.\n",
    "\n",
    "### Show audio file attributes\n",
    "`show_pydub_stats()` displays the audio attributes of a .wav file.\n",
    "\n",
    "### Transcribe audio\n",
    "`transcribe_audio()` uses `recognize_google()` to transcribe a .wav file.\n",
    "\n",
    "5\\. Creating a file format conversion function\n",
    "----------------------------------------------\n",
    "\n",
    "01:54 - 02:24\n",
    "\n",
    "The first one convert to wav takes a file pathname and converts the file to a wav file. You'll first import the file as an AudioSegment, then create a new file name for it using the split function on the filename and adding the dot wav string extension. Finally, you'll use the export function to export it to wav format with the new file name, similar to what you did in a previous lesson.\n",
    "\n",
    "```python\n",
    "def convert_to_wav(filename):\n",
    "    \"\"\"Takes an audio file of non .wav format and converts to .wav\"\"\"\n",
    "    \n",
    "    # Import audio file\n",
    "    audio = AudioSegment.from_file(filename)\n",
    "    \n",
    "    # Create new filename\n",
    "    new_filename = filename.split(\".\")[0] + \".wav\"\n",
    "    \n",
    "    # Export file as .wav\n",
    "    audio.export(new_filename, format=\"wav\")\n",
    "    \n",
    "    print(f\"Converting {filename} to {new_filename}...\")\n",
    "```\n",
    "\n",
    "This Python function `convert_to_wav()` takes an audio file of a non-.wav format and converts it to a .wav file. Here's how it works:\n",
    "\n",
    "1. The `AudioSegment.from_file()` function is used to import the audio file.\n",
    "2. A new filename is created by taking the original filename, splitting it on the \".\" and adding \".wav\" to the end.\n",
    "3. The `audio.export()` method is used to export the audio to the new .wav file format.\n",
    "4. A print statement is included to show the conversion progress.\n",
    "\n",
    "This function can be called with the filename of the audio file you want to convert to .wav format.\n",
    "\n",
    "6\\. Using the file format conversion function\n",
    "---------------------------------------------\n",
    "\n",
    "02:24 - 02:36\n",
    "\n",
    "Great, now you can convert audio files without repeating yourself. Now let's make one to find an audio files attributes using PyDub.\n",
    "\n",
    "```python\n",
    "convert_to_wav(\"acme_studios_audio/call_1.mp3\")\n",
    "```\n",
    "Converting acme_audio_files/call_1.mp3 to acme_audio_files/call_1.wav...\n",
    "\n",
    "This code calls the `convert_to_wav()` function with the file path `\"acme_studios_audio/call_1.mp3\"` as the argument. It will convert the `call_1.mp3` audio file located in the `acme_studios_audio` directory to a `.wav` format file.\n",
    "\n",
    "The function handles the conversion process, including:\n",
    "\n",
    "1. Importing the audio file using `AudioSegment.from_file()`.\n",
    "2. Creating a new filename by taking the original filename, splitting it on the \".\" and adding \".wav\" to the end.\n",
    "3. Exporting the audio to the new .wav file format using `audio.export()`.\n",
    "4. Printing a message to show the conversion progress.\n",
    "\n",
    "After running this code, the converted .wav file will be available in the same directory as the original .mp3 file.\n",
    "\n",
    "\n",
    "7\\. Creating an attribute showing function\n",
    "------------------------------------------\n",
    "\n",
    "02:36 - 02:51\n",
    "\n",
    "show pydub stats takes a filename of an audio file and imports it as an AudioSegment. It then prints a number of attributes such as number of channels, sample width, frame rate and more.\n",
    "\n",
    "```python\n",
    "def show_pydub_stats(filename):\n",
    "    \"\"\"Returns different audio attributes related to an audio file.\"\"\"\n",
    "\n",
    "    audio_segment = AudioSegment.from_file(filename)\n",
    "\n",
    "    print(f\"Channels: {audio_segment.channels}\")\n",
    "    print(f\"Sample width: {audio_segment.sample_width}\")\n",
    "    print(f\"Frame rate (sample rate): {audio_segment.frame_rate}\")\n",
    "    print(f\"Frame width: {audio_segment.frame_width}\")\n",
    "    print(f\"Length (ms): {len(audio_segment)}\")\n",
    "    print(f\"Frame count: {audio_segment.frame_count()}\")\n",
    "```\n",
    "\n",
    "This Python function `show_pydub_stats()` takes an audio file path as input and prints various attributes of the audio file, including:\n",
    "\n",
    "- Number of channels\n",
    "- Sample width\n",
    "- Frame rate (sample rate)\n",
    "- Frame width\n",
    "- Length in milliseconds\n",
    "- Frame count\n",
    "\n",
    "It creates an `AudioSegment` instance from the input file and then accesses and prints the relevant attributes of the audio file.\n",
    "\n",
    "8\\. Using the attribute showing function\n",
    "----------------------------------------\n",
    "\n",
    "02:51 - 03:07\n",
    "\n",
    "Since you're working with customer support calls, this will help especially with files with different numbers of channels. If there are two channels, you might be able to split them and transcribe each speaker separately.\n",
    "\n",
    "```python\n",
    "show_pydub_stats(\"acme_audio_files/call_1.wav\")\n",
    "```\n",
    "\n",
    "This code calls the `show_pydub_stats()` function with the file path `\"acme_audio_files/call_1.wav\"` as the argument. It will print various audio attributes related to the `call_1.wav` audio file, including:\n",
    "\n",
    "- Channels: 2\n",
    "- Sample width: 2 \n",
    "- Frame rate (sample rate): 32000\n",
    "- Frame width: 4\n",
    "- Length (ms): 54888\n",
    "- Frame count: 1756416.0\n",
    "\n",
    "9\\. Creating a transcribe function\n",
    "----------------------------------\n",
    "\n",
    "03:07 - 03:33\n",
    "\n",
    "Finally, since you could be transcribing many audio files, you create a function to transcribe an audio file. transcribe audio takes a file path of an audio file and creates a speech recognition recognizer instance. It transcribes the audio file using recognize google as you've done in a previous lesson and returns the transcribed text.\n",
    "\n",
    "```python\n",
    "def transcribe_audio(filename):\n",
    "    \"\"\"Takes a .wav format audio file and transcribes it to text.\"\"\"\n",
    "\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio_file = sr.AudioFile(filename)\n",
    "\n",
    "    with audio_file as source:\n",
    "        audio_data = recognizer.record(audio_file)\n",
    "        return recognizer.recognize_google(audio_data)\n",
    "```\n",
    "\n",
    "This function `transcribe_audio()` takes a `.wav` format audio file and uses the `recognize_google()` method from the `speech_recognition` library to transcribe the audio into text. Here's how it works:\n",
    "\n",
    "1. It creates a `Recognizer` instance to perform the speech recognition.\n",
    "2. It loads the audio file using `sr.AudioFile()`.\n",
    "3. It records the audio data from the file using `recognizer.record()`.\n",
    "4. It then passes the audio data to `recognizer.recognize_google()` to transcribe the audio to text.\n",
    "5. The transcribed text is returned as the output of the function.\n",
    "\n",
    "To use this function, you can call it with the path to a `.wav` audio file:\n",
    "\n",
    "```python\n",
    "transcribed_text = transcribe_audio(\"acme_audio_files/call_1.wav\")\n",
    "print(transcribed_text)\n",
    "```\n",
    "\n",
    "This will print the transcribed text of the `call_1.wav` audio file.\n",
    "\n",
    "10\\. Using the transcribe function\n",
    "----------------------------------\n",
    "\n",
    "03:33 - 03:51\n",
    "\n",
    "Testing out the function on one of the calls works as expected. It reads in an audio file and returns the transcribed text. Excellent. Setting up helper functions like this at the start of a project may seem time-consuming but they'll help save time in the long run.\n",
    "\n",
    "```python\n",
    "def transcribe_audio(filename):\n",
    "    \"\"\"Takes a .wav format audio file and transcribes it to text.\"\"\"\n",
    "\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio_file = sr.AudioFile(filename)\n",
    "\n",
    "    with audio_file as source:\n",
    "        audio_data = recognizer.record(audio_file)\n",
    "        return recognizer.recognize_google(audio_data)\n",
    "```\n",
    "\n",
    "`\"hello welcome to Acme studio support line my name is Daniel how can I best help you hey Daniel this is John I've recently bought a smart from you guys and I know that's not good to hear John let's let's get your cell number and then we can we can set up a way to fix it for you one number for 1757 varies how long do you reckon this is going to take about an hour now while John we're going to try our best hour I will we get the sealing member will start up this support case I'm just really really really I've been trying to contact 34 been put on hold more than an hour and a half so I'm not really happy I kind of wanna get this issue 6 is fossil\"`\n",
    "\n",
    "The `transcribe_audio()` function takes a `.wav` format audio file, loads it using `sr.AudioFile()`, records the audio data, and then uses the `recognize_google()` method to transcribe the audio to text. The transcribed text is returned as the output.\n",
    "\n",
    "To use this function, you can call it with the path to a `.wav` audio file:\n",
    "\n",
    "```python\n",
    "transcribed_text = transcribe_audio(\"acme_audio_files/call_1.wav\")\n",
    "print(transcribed_text)\n",
    "```\n",
    "\n",
    "This will print the transcribed text of the `call_1.wav` audio file.\n",
    "\n",
    "11\\. Let's practice!\n",
    "--------------------\n",
    "\n",
    "03:51 - 04:05\n",
    "\n",
    "With that said, it's time to build them! Once you've got these ready to go, you'll be able to use some of your natural language processing skills on the transcribed text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting audio to the right format\n",
    "====================================\n",
    "\n",
    "Acme Studios have asked you to do a proof of concept to find out more about their audio files.\n",
    "\n",
    "After exploring them briefly, you find there's a few calls but they're in the wrong file format for transcription.\n",
    "\n",
    "As you'll be interacting with many audio files, you decide to begin by creating some helper functions.\n",
    "\n",
    "The first one, `convert_to_wav(filename)`takes a file path and uses `PyDub` to convert it from a non-wav format to `.wav` format.\n",
    "\n",
    "Once it's built, we'll use the function to convert [Acme's first call](https://assets.datacamp.com/production/repositories/4637/datasets/83ef1650407e911a0f52f491068e3082661db743/ex4_call_1_stereo_mp3.mp3), `call_1.mp3`, from `.mp3`format to `.wav`.\n",
    "\n",
    "`PyDub`'s `AudioSegment` class has already been imported. Remember, to work with non-wav files, you'll need `ffmpeg` ([docs](https://www.ffmpeg.org/)).\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import the `filename` parameter using `AudioSegment`'s `from_file()`.\n",
    "-   Set the export format to `\"wav\"`.\n",
    "-   Pass the target audio file, `call_1.mp3`, to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to convert audio file to wav\n",
    "def convert_to_wav(filename):\n",
    "  \"\"\"Takes an audio file of non .wav format and converts to .wav\"\"\"\n",
    "  # Import audio file\n",
    "  audio = AudioSegment.from_file(filename)\n",
    "  \n",
    "  # Create new filename\n",
    "  new_filename = filename.split(\".\")[0] + \".wav\"\n",
    "  \n",
    "  # Export file as .wav\n",
    "  audio.export(new_filename, format='wav')\n",
    "  print(f\"Converting {filename} to {new_filename}...\")\n",
    " \n",
    "# Test the function\n",
    "convert_to_wav(\"call_1.mp3\")  #takes \"call_1.mp3\" not 'call_1.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding PyDub stats\n",
    "===================\n",
    "\n",
    "You decide it'll be helpful to know the audio attributes of any given file easily. This will be especially helpful for finding out how many channels an audio file has or if the frame rate is adequate for transcription.\n",
    "\n",
    "In this exercise, we'll create `show_pydub_stats()` which takes a filename of an audio file as input. It then imports the audio as a `PyDub` `AudioSegment` instance and prints attributes such as number of channels, length and more.\n",
    "\n",
    "It then returns the `AudioSegment` instance so it can be used later on.\n",
    "\n",
    "We'll use our function on the [newly converted .wav file](https://assets.datacamp.com/production/repositories/4637/datasets/43c5aff8c419d07f8cef70fdf40e4657b78b70be/ex4_call_1_stereo_formatted.wav), `call_1.wav`\n",
    "\n",
    "`AudioSegment` has already imported from `PyDub`.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Create an `AudioSegment` instance called `audio_segment` by importing the `filename`parameter.\n",
    "-   Print the number of channels using the `channels` attribute.\n",
    "-   Return the `audio_segment` variable.\n",
    "-   Test the function on `\"call_1.wav\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pydub_stats(filename):\n",
    "  \"\"\"Returns different audio attributes related to an audio file.\"\"\"\n",
    "  # Create AudioSegment instance\n",
    "  audio_segment = AudioSegment.from_file(filename)\n",
    "  \n",
    "  # Print audio attributes and return AudioSegment instance\n",
    "  print(f\"Channels: {audio_segment.channels}\")\n",
    "  print(f\"Sample width: {audio_segment.sample_width}\")\n",
    "  print(f\"Frame rate (sample rate): {audio_segment.frame_rate}\")\n",
    "  print(f\"Frame width: {audio_segment.frame_width}\")\n",
    "  print(f\"Length (ms): {len(audio_segment)}\")\n",
    "  return audio_segment\n",
    "\n",
    "# Try the function\n",
    "call_1_audio_segment = show_pydub_stats(\"call_1.wav\")\n",
    "# output:\n",
    "#     Channels: 2\n",
    "#     Sample width: 2\n",
    "#     Frame rate (sample rate): 32000\n",
    "#     Frame width: 4\n",
    "#     Length (ms): 54888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribing audio with one line\n",
    "================================\n",
    "\n",
    "Alright, now you've got functions to convert audio files and find out their attributes, it's time to build one to transcribe them.\n",
    "\n",
    "In this exercise, you'll build `transcribe_audio()` which takes a `filename`as input, imports the `filename` using `speech_recognition`'s `AudioFile` class and then transcribes it using `recognize_google()`.\n",
    "\n",
    "You've seen these functions before but now we'll put them together so they're accessible in a function.\n",
    "\n",
    "To test it out, we'll transcribe [Acme's first call](https://assets.datacamp.com/production/repositories/4637/datasets/43c5aff8c419d07f8cef70fdf40e4657b78b70be/ex4_call_1_stereo_formatted.wav), `\"call_1.wav\"`.\n",
    "\n",
    "`speech_recognition` has been imported as `sr`.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Define a function called `transcribe_audio`which takes `filename` as an input parameter.\n",
    "-   Setup a `Recognizer()` instance as `recognizer`.\n",
    "-   Use `recognize_google()` to transcribe the audio data.\n",
    "-   Pass the target call to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(filename):\n",
    "  \"\"\"Takes a .wav format audio file and transcribes it to text.\"\"\"\n",
    "  # Setup a recognizer instance\n",
    "  recognizer = sr.Recognizer()\n",
    "  \n",
    "  # Import the audio file and convert to audio data\n",
    "  audio_file = sr.AudioFile(filename)\n",
    "  with audio_file as source:\n",
    "    audio_data = recognizer.record(source)\n",
    "  \n",
    "  # Return the transcribed text\n",
    "  return recognizer.recognize_google(audio_data)\n",
    "\n",
    "# Test the function\n",
    "print(transcribe_audio(\"call_1.wav\"))\n",
    "# output:\n",
    "#     hello welcome to Acme studio support line my name is Daniel how can \n",
    "# I best help you hey Daniel this is John I've recently bought a smart from \n",
    "# you guys 3 weeks ago and I'm already having issues with it I know that's not \n",
    "# good to hear John let's let's get your cell number and then we can we can set up \n",
    "# a way to fix it for you one number for 17 varies how long do you reckon this is going \n",
    "# to try our best to get the steel number will start up this support case I'm just really \n",
    "# really really really I've been trying to contact past three 4 days now and I've been put \n",
    "# on hold more than an hour and a half so I'm not really happy I kind of wanna get this issue 6 is f***** possible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the helper functions you've built\n",
    "=======================================\n",
    "\n",
    "Okay, now we've got some helper functions ready to go, it's time to put them to use!\n",
    "\n",
    "You'll first use `convert_to_wav()` to convert Acme's `call_1.mp3` ([file](https://assets.datacamp.com/production/repositories/4637/datasets/56f523fb855eaecc14a87c5619ec5e6e7c4490bc/ex4_call_1_stereo_formatted_mp3.mp3)) to `.wav` format and save it as `call_1.wav`\n",
    "\n",
    "Using `show_pydub_stats()` you find `call_1.wav` has 2 channels so you decide to split them using `PyDub`'s `split_to_mono()`. Acme tells you the [customer channel](https://assets.datacamp.com/production/repositories/4637/datasets/03ace2e9b866aaa554c465d6698500aaf48599dc/ex4_call_1_channel_2_split.wav) is likely channel 2. So you export channel 2 using `PyDub`'s `.export()`.\n",
    "\n",
    "Finally, you'll use `transcribe_audio()` to transcribe channel 2 only.\n",
    "\n",
    "Instructions 1/3\n",
    "----------------\n",
    "\n",
    "-   Convert the `.mp3` version of `call_1` to `.wav` and then check the stats of the `.wav` version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mp3 file to wav\n",
    "convert_to_wav(\"call_1.mp3\")\n",
    "\n",
    "# Check the stats of new file\n",
    "call_1 = show_pydub_stats(\"call_1.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 2/3\n",
    "----------------\n",
    "\n",
    "-   Split `call_1` to mono and then export the second channel in `.wav` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mp3 file to wav\n",
    "convert_to_wav(\"call_1.mp3\")\n",
    "\n",
    "# Check the stats of new file\n",
    "call_1 = show_pydub_stats(\"call_1.wav\")\n",
    "\n",
    "# Split call_1 to mono\n",
    "call_1_split = call_1.split_to_mono()\n",
    "\n",
    "# Export channel 2 (the customer channel)\n",
    "call_1_split[1].export(\"call_1_channel_2.wav\",\n",
    "                       format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 3/3\n",
    "----------------\n",
    "\n",
    "-   Transcribe the audio of call 1's channel 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mp3 file to wav\n",
    "convert_to_wav(\"call_1.mp3\")\n",
    "\n",
    "# Check the stats of new file\n",
    "call_1 = show_pydub_stats(\"call_1.wav\")\n",
    "\n",
    "# Split call_1 to mono\n",
    "call_1_split = call_1.split_to_mono()\n",
    "\n",
    "# Export channel 2 (the customer channel)\n",
    "call_1_split[1].export(\"call_1_channel_2.wav\",\n",
    "                       format=\"wav\")\n",
    "\n",
    "# Transcribe the single channel\n",
    "print(transcribe_audio(call_1_split[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Sentiment analysis on spoken language text\n",
    "----------------------------------------------\n",
    "\n",
    "00:00 - 00:32\n",
    "\n",
    "Now you've got some helper functions ready, it's time to start extracting information from the transcribed text. Your proposal to Acme Studios suggested sentiment analysis, the process of figuring out if text is positive, neutral or negative, would be helpful and they agreed. Knowing the sentiment of different calls may help them figure out where customers are having the most trouble. To do sentiment analysis, you decide on using the NLTK Python library.\n",
    "\n",
    "2\\. Installing sentiment analysis libraries\n",
    "-------------------------------------------\n",
    "\n",
    "00:32 - 01:17\n",
    "\n",
    "To begin, you install NLTK using pip. Then you download the neceesary NLTK packages for sentiment analysis, punkt and vader lexicon using NLTK's download function. Since we don't have a large enough dataset to train our own sentiment analysis model, we'll use NLTK's VADER or Valance Aware Dictionary and sEntiment analyzeR as it has a pretrained sentiment analysis model in it. VADER works by analyzing each word in a piece of text and giving it a sentiment score. It was pretrained on social media text passages but will lend itself well for our proof of concept.\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"vader_lexicon\")\n",
    "```\n",
    "\n",
    "#### Download required NLTK packages\n",
    "\n",
    "1. `import nltk`\n",
    "2. `nltk.download(\"punkt\")`\n",
    "3. `nltk.download(\"vader_lexicon\")`\n",
    "\n",
    "3\\. Sentiment analysis with VADER\n",
    "---------------------------------\n",
    "\n",
    "01:17 - 02:17\n",
    "\n",
    "To start sentiment analysis, you import the SentimentIntensityAnalyzer class from the nltk sentiment vader module. And then instantiate an instance of SentimentIntensityAnalyzer and save it to the commonly named variable sid. You can then find the sentiment scores of a piece of text by calling polarity scores on sid and passing it a string. Running the function will return four values, neg for negative, neu for neutral, pos for positive and compound as an overall. The more negative a piece of text is, the higher the negative score will be and the same goes for the positive score if the text is positive. If it's in the middle, neutral will be higher. And the compound value can be thought of as the overall score with -1 being most negative and positive 1 being most positive.\n",
    "\n",
    "```python\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create sentiment analysis instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Test sentiment analysis on negative text\n",
    "print(sid.polarity_scores(\"This customer service is terrible.\"))\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "{'neg': 0.437, 'neu': 0.563, 'pos': 0.0, 'compound': -0.4767}\n",
    "```\n",
    "\n",
    "4\\. Sentiment analysis on transcribed text\n",
    "------------------------------------------\n",
    "\n",
    "02:17 - 02:44\n",
    "\n",
    "You try out the sentiment analysis on one of your transcribed phone calls using only the customer channel. Reading the transcription and comparing it to what you hear when you listen to the audio file, you can see it's not perfect. But you can see the sentiment scores are leaning in the right direction. The sentiment is fairly neutral since the customer hasn't received their product yet.\n",
    "\n",
    "```python\n",
    "# Transcribe customer channel of call_3\n",
    "call_3_channel_2_text = transcribe_audio(\"call_3_channel_2.wav\")\n",
    "print(call_3_channel_2_text)\n",
    "\n",
    "# Sentiment analysis on customer channel of call_3\n",
    "print(sid.polarity_scores(call_3_channel_2_text))\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "\"hey Dave is this any better do I order products are currently on July 1st and I haven't received the product a three-week step down this parable 6987 5\"\n",
    "\n",
    "{'neg': 0.0, 'neu': 0.892, 'pos': 0.108, 'compound': 0.4404}\n",
    "```\n",
    "\n",
    "5\\. Sentence by sentence\n",
    "------------------------\n",
    "\n",
    "02:44 - 03:22\n",
    "\n",
    "From your experience with sentiment analysis, you know the sentiment can change sentence by sentence. But your current transcription function doesn't return sentences, only a large block of text. In your proposal, you mentioned this to Acme and they allocated budget for you to try a paid transcription API. You try transcribing the same audio files using a paid API service and find it returns sentences. Using NLTK's sent tokenize, you break the transcription into sentences and analyze the sentiment sentence by sentence.\n",
    "\n",
    "```python\n",
    "call_3_paid_api_text = \"Okay. Yeah. Hi, Diane. This is paid on this call and obvi...\"\n",
    "\n",
    "# Import sent tokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# Find sentiment on each sentence\n",
    "for sentence in sent_tokenize(call_3_paid_api_text):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))\n",
    "```\n",
    "\n",
    "6\\. Sentence by sentence\n",
    "------------------------\n",
    "\n",
    "03:22 - 03:36\n",
    "\n",
    "This is helpful because it allows you to figure out which parts of the conversation the customer may be most displeased with. You can see the line where the transcription says this service is terrible gets a negative compound score.\n",
    "\n",
    "```\n",
    "Okay.\n",
    "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.2263}\n",
    "\n",
    "Yeah.\n",
    "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.296}\n",
    "\n",
    "Hi, Diane.\n",
    "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
    "\n",
    "This is paid on this call and obviously the status of my orders at three weeks ago, and that service is terrible.\n",
    "{'neg': 0.129, 'neu': 0.871, 'pos': 0.0, 'compound': -0.4767}\n",
    "\n",
    "Is this any better?\n",
    "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
    "\n",
    "Yes...\n",
    "```\n",
    "\n",
    "7\\. Time to code!\n",
    "-----------------\n",
    "\n",
    "03:36 - 03:44\n",
    "\n",
    "It's still early, but you're starting to see some insights you can report back to Acme. Let's code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing sentiment of a phone call\n",
    "===================================\n",
    "\n",
    "Once you've transcribed the text from an audio file, it's possible to perform natural language processing on the text.\n",
    "\n",
    "In this exercise, we'll use `NLTK`'s VADER (Valence Aware Dictionary and sEntiment Reasoner) to analyze the sentiment of the transcribed text of `call_2.wav` ([file](https://assets.datacamp.com/production/repositories/4637/datasets/82c77dc404e914eb08ce2a54a10603ef027711b8/ex4_call_2_stereo_native.wav)).\n",
    "\n",
    "To transcribe the text, we'll use the `transcribe_audio()` function we created earlier.\n",
    "\n",
    "Once we have the text, we'll use `NLTK`'s `SentimentIntensityAnalyzer()` class to obtain a sentiment polarity score.\n",
    "\n",
    "`.polarity_scores(text)` returns a value for pos (positive), neu (neutral), neg (negative) and compound. Compound is a mixture of the other three values. The higher it is, the more positive the text. Lower means more negative.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Instantiate an instance of `SentimentIntensityAnalyzer()` and save it to the variable `sid`.\n",
    "-   Transcribe the target call and save it to `call_2_text`.\n",
    "-   Print the `polarity_scores()` of `call_2_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create SentimentIntensityAnalyzer instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Let's try it on one of our phone calls\n",
    "call_2_text = transcribe_audio('call_2.wav')\n",
    "\n",
    "# Display text and sentiment polarity scores\n",
    "print(call_2_text)\n",
    "print(sid.polarity_scores(call_2_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis on formatted text\n",
    "====================================\n",
    "\n",
    "In this exercise, you'll calculate the sentiment on the customer channel of `call_2.wav` ([file](https://assets.datacamp.com/production/repositories/4637/datasets/82c77dc404e914eb08ce2a54a10603ef027711b8/ex4_call_2_stereo_native.wav)).\n",
    "\n",
    "You've split the customer channel and saved it to `call_2_channel_2.wav` ([file](https://assets.datacamp.com/production/repositories/4637/datasets/bc1fa0595fda765634de7b09864a26566b5f11db/ex4_call_2_channel_2_formatted.wav)).\n",
    "\n",
    "But from your experience with sentiment analysis, you know it can change sentence to sentence.\n",
    "\n",
    "To calculate it sentence to sentence, you split the split using `NLTK`'s `sent_tokenize()`module.\n",
    "\n",
    "But `transcribe_audio()` doesn't return sentences. To try sentiment anaylsis with sentences, you've tried a paid API service to get `call_2_channel_2_paid_api_text` which has sentences.\n",
    "\n",
    "Instructions 1/3\n",
    "----------------\n",
    "\n",
    "-   -   Transcribe the audio of `call_2_channel_2.wav` and find the sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create SentimentIntensityAnalyzer instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Transcribe customer channel of call 2\n",
    "call_2_channel_2_text = transcribe_audio('call_2.wav')\n",
    "\n",
    "# Display text and sentiment polarity scores\n",
    "print(call_2_channel_2_text)\n",
    "print(sid.polarity_scores(call_2_channel_2_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 2/3\n",
    "----------------\n",
    "\n",
    "-   -   Split `call_2_channel_2_text` into sentences and find the sentiment score of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sent_tokenize from nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create SentimentIntensityAnalyzer instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Split call 2 channel 2 into sentences and score each\n",
    "for sentence in sent_tokenize(call_2_channel_2_text):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))\n",
    "# output:\n",
    "#     oh hi Daniel my name is Sally I recently purchased a smartphone from you guys and extremely happy with it I've just gotta issue not an issue but I've just got to learn a little bit more about the message bank on I have Google the location but I'm I'm finding it hard I thought you were on the corner of Edward and Elizabeth according to Google according to the match but would you be able to help me in some way because I think I've actually walk straight past your shop\n",
    "#     {'neg': 0.017, 'neu': 0.891, 'pos': 0.091, 'compound': 0.778} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 3/3\n",
    "----------------\n",
    "\n",
    "-   -   Split `call_2_channel_2_paid_api_text`into sentences and score the sentiment of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sent_tokenize from nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create SentimentIntensityAnalyzer instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Split channel 2 paid text into sentences and score each\n",
    "for sentence in sent_tokenize(call_2_channel_2_paid_api_text):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Named entity recognition on transcribed text\n",
    "------------------------------------------------\n",
    "\n",
    "00:00 - 00:21\n",
    "\n",
    "Now you've done some sentiment analysis on Acme's transcribed calls, you decide named entity recognition is a good next step. Entity recognition is the process of extracting objects of interest from text. To do this, you turn to spaCy, the natural language processing library.\n",
    "\n",
    "2\\. Installing spaCy\n",
    "--------------------\n",
    "\n",
    "00:21 - 00:37\n",
    "\n",
    "To get started with spaCy, you can install it using pip. Once spaCy is installed, we can use spaCy's built-in language models for natural language processing by downloading them using the spacy download command on the command line.\n",
    "\n",
    "```\n",
    "# Install spaCy\n",
    "$ pip install spacy\n",
    "\n",
    "# Download spaCy language model  \n",
    "$ python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "3\\. Using spaCy\n",
    "---------------\n",
    "\n",
    "00:37 - 01:13\n",
    "\n",
    "spaCy works by turning blocks of text into docs. Docs are made up of tokens and spans. You can think of tokens as individual words and groups of tokens or sentences as spans. Let's see. First we import spacy. Then we load the language model and save it to the conventional variable nlp. Then to create a spaCy doc, we pass the string of text we want to use to nlp. Now we've got a spaCy doc, we can use spaCy's built-in features to find out more.\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "\n",
    "# Load spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a spaCy doc\n",
    "doc = nlp(\"I'd like to talk about a smartphone I ordered on July 31st from your Sydney store, my order number is 40939440. I spoke to Georgia about it last week.\")\n",
    "```\n",
    "\n",
    "4\\. spaCy tokens\n",
    "----------------\n",
    "\n",
    "01:13 - 01:29\n",
    "\n",
    "You can see what tokens a doc contains and the index where they start using dot text and dot idx on objects in your doc. The number returned by idx indicates the index of the first letter in the token.\n",
    "\n",
    "```python\n",
    "# Show different tokens and positions\n",
    "for token in doc:\n",
    "    print(token.text, token.idx)\n",
    "```\n",
    "\n",
    "```\n",
    "I 0\n",
    "'d 1\n",
    "like 4 \n",
    "to 9\n",
    "talk 12\n",
    "about 17\n",
    "a 23\n",
    "smartphone 25\n",
    "```\n",
    "\n",
    "5\\. spaCy sentences\n",
    "-------------------\n",
    "\n",
    "01:29 - 01:37\n",
    "\n",
    "You can see where the sentences are with dot sents. Here spaCy has broken the text in our doc into sentences.\n",
    "\n",
    "```python\n",
    "# Show sentences in doc\n",
    "for sentences in doc.sents:\n",
    "    print(sentence)\n",
    "```\n",
    "\n",
    "```\n",
    "I'd like to talk about a smartphone I ordered on July 31st from your Sydney store, my order number is 409382.\n",
    "I spoke to one of your customer service team, Georgia, yesterday.\n",
    "```\n",
    "\n",
    "6\\. spaCy named entities\n",
    "------------------------\n",
    "\n",
    "01:37 - 01:55\n",
    "\n",
    "Beautiful, now let's try using spaCy's named entity recognition. A named entity is an object which is given a name, such as, a person, product, location or date. spaCy has several of these named entities built-in it can recognize straight away.\n",
    "\n",
    "```markdown\n",
    "Some of spaCy's built-in named entities:\n",
    "\n",
    "- PERSON People, including fictional.\n",
    "- ORG Companies, agencies, institutions, etc. \n",
    "- GPE Countries, cities, states.\n",
    "- PRODUCT Objects, vehicles, foods, etc. (Not services.)\n",
    "- DATE Absolute or relative dates or periods.\n",
    "- TIME Times smaller than a day.\n",
    "- MONEY Monetary values, including unit.\n",
    "- CARDINAL Numerals that do not fall under another type.\n",
    "```\n",
    "\n",
    "7\\. spaCy named entities\n",
    "------------------------\n",
    "\n",
    "01:55 - 02:15\n",
    "\n",
    "You can access the named entities in a doc using dot ents. Let's try. dot text shows us the token that the label belongs to. And dot label underscore gives us the named entity label of the text. You can see Sydney is given GPE for geopolitical entity.\n",
    "\n",
    "```python\n",
    "# Find named entities in doc\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)\n",
    "```\n",
    "\n",
    "```\n",
    "July 31st DATE\n",
    "Sydney GPE\n",
    "4093829 CARDINAL\n",
    "one CARDINAL\n",
    "Georgia GPE\n",
    "yesterday DATE\n",
    "```\n",
    "\n",
    "8\\. Custom named entities\n",
    "-------------------------\n",
    "\n",
    "02:15 - 02:56\n",
    "\n",
    "spaCy's built-in named entities are excellent but depending your problem, you'll probably want to develop some of your own. Since Acme is a technology company, you decide it's a good idea to create a custom entity recognizer for their products. To do so, you can use spaCy's pipeline class EntityRuler. A pipeline is what spaCy uses to parse text into a doc. You can see the current pipeline you're using by calling pipeline on nlp. In our case, our pipeline has three steps, a tagger, a parser and ner for named entity recognition.\n",
    "\n",
    "```python\n",
    "# Import EntityRuler class\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# Check spaCy pipeline  \n",
    "print(nlp.pipeline)\n",
    "```\n",
    "\n",
    "```\n",
    "[('tagger', <spacy.pipeline.pipes.Tagger at 0x1c3aa8a470>),\n",
    "('parser', <spacy.pipeline.pipes.DependencyParser at 0x1c3bb60588>),\n",
    "('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x1c3bb605e8>)]\n",
    "```\n",
    "\n",
    "9\\. Changing the pipeline\n",
    "-------------------------\n",
    "\n",
    "02:56 - 03:29\n",
    "\n",
    "The EntityRuler class allows us to create another step in the pipeline. We start by making an instance of EntityRuler called ruler, passing it nlp. Then we use add patterns to add the token pattern we'd like spaCy to consider an entity. In our case, we want the smartphone token to have the entity label PRODUCT. We can add this rule to the pipeline before ner so we can be sure it gets used.\n",
    "\n",
    "```python\n",
    "# Create EntityRuler instance\n",
    "ruler = EntityRuler(nlp)\n",
    "\n",
    "# Add token pattern to ruler\n",
    "ruler.add_patterns([{\"label\":\"PRODUCT\", \"pattern\": \"smartphone\"}])\n",
    "\n",
    "# Add new rule to pipeline before ner\n",
    "nlp.add_pipe(ruler, before=\"ner\")\n",
    "\n",
    "# Check updated pipeline\n",
    "nlp.pipeline\n",
    "```\n",
    "\n",
    "```\n",
    "[('tagger', <spacy.pipeline.pipes.Tagger at 0x1c3aa8a470>),\n",
    "('parser', <spacy.pipeline.pipes.DependencyParser at 0x1c3bb60588>), \n",
    "('entityruler', <spacy.pipeline.EntityRuler at 0x1c3bb605a8>),\n",
    "('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x1c3bb605e8>)]\n",
    "```\n",
    "\n",
    "10\\. Changing the pipeline\n",
    "--------------------------\n",
    "\n",
    "03:29 - 03:34\n",
    "\n",
    "Now when we check our pipeline we've got a new step called entity ruler.\n",
    "\n",
    "```\n",
    "[('tagger', <spacy.pipeline.pipes.Tagger at 0x1c1f9c9b38>),\n",
    "('parser', <spacy.pipeline.pipes.DependencyParser at 0x1c3c9cba08>),\n",
    "('entity_ruler', <spacy.pipeline.entityruler.EntityRuler at 0x1c1d834b70>),\n",
    "('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x1c3c9cba68>)]\n",
    "```\n",
    "\n",
    "11\\. Testing the new pipeline\n",
    "-----------------------------\n",
    "\n",
    "03:34 - 03:42\n",
    "\n",
    "Let's try it with our doc from before. You can see the token smartphone now has the PRODUCT named entity label.\n",
    "\n",
    "```python\n",
    "# Test new entity rule\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)\n",
    "```\n",
    "\n",
    "```\n",
    "smartphone PRODUCT  \n",
    "July 31st DATE\n",
    "Sydney GPE\n",
    "4093829 CARDINAL \n",
    "one CARDINAL\n",
    "Georgia GPE\n",
    "yesterday DATE\n",
    "```\n",
    "\n",
    "12\\. Let's rocket and practice spaCy!\n",
    "-------------------------------------\n",
    "\n",
    "03:42 - 03:47\n",
    "\n",
    "Woah, we covered a lot of ground in this lesson. Let's make it happen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named entity recognition in spaCy\n",
    "=================================\n",
    "\n",
    "Named entities are real-world objects which have names, such as, cities, people, dates or times. We can use `spaCy` to find named entities in our transcribed text.\n",
    "\n",
    "In this exercise, you'll transcribe `call_4_channel_2.wav` ([file](https://assets.datacamp.com/production/repositories/4637/datasets/2e039462d95117677db6ddfe24377d9cadcdf730/ex4_call_4_channel_2_formatted.wav)) using `transcribe_audio()` and then use `spaCy`'s language model, `en_core_web_sm` to convert the transcribed text to a `spaCy` doc.\n",
    "\n",
    "Transforming text to a `spaCy` doc allows us to leverage `spaCy`'s built-in features for analyzing text, such as, `.text` for tokens (single words), `.sents` for sentences and `.ents` for named entities.\n",
    "\n",
    "Instructions 1/4\n",
    "----------------\n",
    "\n",
    "-   -   Create a `spaCy` `doc` by passing the transcribed call 4 channel 2 text to `nlp()` and then check its type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Transcribe call 4 channel 2\n",
    "call_4_channel_2_text = transcribe_audio(\"call_4_channel_2.wav\")\n",
    "\n",
    "# Create a spaCy language model instance\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a spaCy doc with call 4 channel 2 text\n",
    "doc = nlp(call_4_channel_2_text)\n",
    "\n",
    "# Check the type of doc\n",
    "print(type(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 2/4\n",
    "----------------\n",
    "\n",
    "-   -   Create a `spaCy` `doc` with `call_4_channel_2_text` then print all the token text in it using the `.text`attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a spaCy doc with call 4 channel 2 text\n",
    "doc = nlp(call_4_channel_2_text)\n",
    "\n",
    "# Show tokens in doc\n",
    "for token in doc:\n",
    "    print(token.text, token.idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 3/4\n",
    "----------------\n",
    "\n",
    "-   -   Load the `\"en_core_web_sm\"` language model and then print the sentences in the `doc` using the `.sents` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a spaCy doc with call 4 channel 2 text\n",
    "doc = nlp(call_4_channel_2_text)\n",
    "\n",
    "# Show sentences in doc\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 4/4\n",
    "----------------\n",
    "\n",
    "-   -   Access the entities in the doc using `.ents` and then print the text of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a spaCy doc with call 4 channel 2 text\n",
    "doc = nlp(call_4_channel_2_text)\n",
    "\n",
    "# Show named entities and their labels\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a custom named entity in spaCy\n",
    "=======================================\n",
    "\n",
    "If `spaCy`'s built-in named entities aren't enough, you can make your own using `spaCy`'s `EntityRuler()` class.\n",
    "\n",
    "`EntityRuler()` allows you to create your own entities to add to a `spaCy` pipeline.\n",
    "\n",
    "You start by creating an instance of `EntityRuler()` and passing it the current pipeline, `nlp`.\n",
    "\n",
    "You can then call `add_patterns()` on the instance and pass it a dictionary of the text `pattern` you'd like to label with an entity.\n",
    "\n",
    "Once you've setup a pattern you can add it the `nlp` pipeline using `add_pipe()`.\n",
    "\n",
    "Since Acme is a technology company, you decide to tag the pattern `\"smartphone\"` with the `\"PRODUCT\"` entity tag.\n",
    "\n",
    "`spaCy` has been imported and a `doc` already exists containing the transcribed text from `call_4_channel_2.wav` file).\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import `EntityRuler` from `spacy.pipeline`.\n",
    "-   Add `\"smartphone\"` as the value for the `\"pattern\"` key.\n",
    "-   Add the `EntityRuler()` instance, `ruler`, to the `nlp` pipeline.\n",
    "-   Print the entity attributes contained in `doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import EntityRuler class\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# Create EntityRuler instance\n",
    "ruler = EntityRuler(nlp)\n",
    "\n",
    "# Define pattern for new entity\n",
    "ruler.add_patterns([{\"label\": \"PRODUCT\", \"pattern\": \"smartphone\"}])\n",
    "\n",
    "# Update existing pipeline\n",
    "nlp.add_pipe(ruler.add_patterns, before=\"ner\")\n",
    "\n",
    "# Test new entity\n",
    "for entity in doc.ents:\n",
    "  print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Classifying transcribed speech with Sklearn\n",
    "-----------------------------------------------\n",
    "\n",
    "00:00 - 00:32\n",
    "\n",
    "Acme are impressed with your work so far and have sent over two folders full of phone call audio snippets. And they've manually labelled them with pre-purchase if the customer was calling before a purchase or post-purchase if the customer was calling after making a purchase. They said the process of labeling audio files was labor intensive and want to know if machine learning can help. You immediately start to think of building an sklearn text classifier, and that's what we'll be doing in this lesson.\n",
    "\n",
    "2\\. Inspecting the data\n",
    "-----------------------\n",
    "\n",
    "00:32 - 00:47\n",
    "\n",
    "You inspect the folders by importing os and using the listdir function on the folder path. You notice there's about 50 files in each but they're in the mp3 format. Luckily you built a function to handle this earlier.\n",
    "\n",
    "```python\n",
    "# Inspect post purchase audio folder\n",
    "import os\n",
    "\n",
    "post_purchase_audio = os.listdir(\"post_purchase\")\n",
    "print(post_purchase_audio[:5])\n",
    "```\n",
    "\n",
    "```\n",
    "['post-purchase-audio-0.mp3',\n",
    " 'post-purchase-audio-1.mp3', \n",
    " 'post-purchase-audio-2.mp3',\n",
    " 'post-purchase-audio-3.mp3',\n",
    " 'post-purchase-audio-4.mp3']\n",
    "```\n",
    "\n",
    "3\\. Converting to wav\n",
    "---------------------\n",
    "\n",
    "00:47 - 00:53\n",
    "\n",
    "Using your convert to wav function you built earlier, you convert all the files from mp3 to wav.\n",
    "\n",
    "```python\n",
    "# Loop through mp3 files\n",
    "for file in post_purchase_audio:\n",
    "    print(f\"Converting {file} to .wav...\")\n",
    "    # Use previously made function to convert to .wav\n",
    "    convert_to_wav(file)\n",
    "```\n",
    "\n",
    "```\n",
    "Converting post-purchase-audio-0.mp3 to .wav...\n",
    "Converting post-purchase-audio-1.mp3 to .wav...\n",
    "Converting post-purchase-audio-2.mp3 to .wav...\n",
    "Converting post-purchase-audio-3.mp3 to .wav...\n",
    "Converting post-purchase-audio-4.mp3 to .wav...\n",
    "```\n",
    "\n",
    "4\\. Transcribing all phone call excerpts\n",
    "----------------------------------------\n",
    "\n",
    "00:53 - 01:25\n",
    "\n",
    "Excellent, now they're all in wav format, you decide to create a function, create text list, to transcribe all of the files in a folder to text. You start with an empty list, then looping through the folder, if a file ends with a wav extension, you pass the filepath to your transcribe audio function which returns the text. Once you have the text, you append it to your empty list and then return the list full of transcribed text.\n",
    "\n",
    "```python\n",
    "# Transcribe text from wav files\n",
    "def create_text_list(folder):\n",
    "    text_list = []\n",
    "    # Loop through folder\n",
    "    for file in folder:\n",
    "        # Check for .wav extension\n",
    "        if file.endswith(\".wav\"):\n",
    "            # Transcribe audio\n",
    "            text = transcribe_audio(file)\n",
    "            # Add transcribed text to list\n",
    "            text_list.append(text)\n",
    "    return text_list\n",
    "```\n",
    "\n",
    "5\\. Transcribing all phone call excerpts\n",
    "----------------------------------------\n",
    "\n",
    "01:25 - 01:34\n",
    "\n",
    "Running the function on the post purchase folder, returns a list of text. Let's see what the first five look like.\n",
    "\n",
    "```python\n",
    "# Convert post purchase audio to text\n",
    "post_purchase_text = create_text_list(post_purchase_audio)\n",
    "print(post_purchase_text[:5])\n",
    "```\n",
    "\n",
    "```\n",
    "['hey man I just water product from you guys and I think is amazing but I leave a li',\n",
    "'these clothes I just bought from you guys too small is there anyway I can change t',\n",
    "'I recently got these pair of shoes but they\\'re too big can I change the size',\n",
    "'I bought a pair of pants from you guys but they\\'re way too small',\n",
    "'I bought a pair of pants and they\\'re the wrong colour is there any chance I can ch']\n",
    "```\n",
    "\n",
    "6\\. Organizing transcribed text\n",
    "-------------------------------\n",
    "\n",
    "01:34 - 02:11\n",
    "\n",
    "Okay, we're making progress. Those helper functions came in handy. To make building your text classifier easier, you decide to put all the text into a pandas dataframe. You start by importing pandas as pd. Then create a post purchase dataframe by passing pd DataFrame a dictionary with a key named label which has a value of post purchase and a text key whose value is the text list. You do the same for the pre purchase text. And to have everything in one place, you combine the two dataframes with pd dot concat. Let's set it.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create post purchase dataframe\n",
    "post_purchase_df = pd.DataFrame({\"label\": \"post_purchase\", \"text\": post_purchase_text})\n",
    "\n",
    "# Create pre purchase dataframe\n",
    "pre_purchase_df = pd.DataFrame({\"label\": \"pre_purchase\", \"text\": pre_purchase_text})\n",
    "\n",
    "# Combine pre purchase and post purhcase\n",
    "df = pd.concat([post_purchase_df, pre_purchase_df])\n",
    "\n",
    "# View the combined dataframe \n",
    "df.head()\n",
    "```\n",
    "\n",
    "7\\. Organizing transcribed text\n",
    "-------------------------------\n",
    "\n",
    "02:11 - 02:19\n",
    "\n",
    "Beautiful! Now you've got your data in a dataframe, you can use it to build a text classifier with sklearn.\n",
    "\n",
    "```\n",
    "             label                                               text\n",
    "0  post_purchase  yeah hello someone this morning delivered a pa...\n",
    "1  post_purchase  my shipment arrived yesterday but it's not the...\n",
    "2  post_purchase  hey my name is Daniel I received my shipment y...\n",
    "3  post_purchase  hey mate how are you doing I'm just calling in...\n",
    "4   pre_purchase  hey I was wondering if you know where my new p...\n",
    "```\n",
    "\n",
    "8\\. Building a text classifier\n",
    "------------------------------\n",
    "\n",
    "02:19 - 03:00\n",
    "\n",
    "We'll start by importing the necessary packages. Numpy as np, Pipeline from sklearn's pipeline module, MultinomialNB from sklearn's naive bayes module for our classifier, CountVectorizer and TfidfTransformer from sklearn's text feature extraction module to transform our text into numbers. And train test split to split our data into training and test sets. To start, we'll use train test split to split the data using a test size of 30%. Where our X value is the text column and our y value is the label column of the dataframe we created earlier.\n",
    "\n",
    "```python\n",
    "# Import text classification packages\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X=df[\"text\"],\n",
    "    y=df[\"label\"],\n",
    "    test_size=0.3)\n",
    "```\n",
    "\n",
    "9\\. Naive Bayes Pipeline\n",
    "------------------------\n",
    "\n",
    "03:00 - 03:28\n",
    "\n",
    "Next, you setup a classifier pipeline as text classifier which uses CountVectorizer and TfidfTransformer to transform each of the test samples into a certain value depending on the words they contain. Then MultinomialNB builds a naive bayes model to classifiy each sample. To train the model you call the fit function on your text classifier and pass it the training data.\n",
    "\n",
    "```python\n",
    "# Create text classifier pipeline \n",
    "text_classifier = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer()),\n",
    "    (\"tfidf\", TfidfTransformer()),\n",
    "    (\"classifier\", MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit the classifier pipeline on the training data\n",
    "text_classifier.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "10\\. Not so Naive\n",
    "-----------------\n",
    "\n",
    "03:28 - 03:47\n",
    "\n",
    "Once you've got a trained model, you can evaluate it by calling the predict function on your classifier and passing it the test set data. Then you can use Numpy to compare the predictions to the test data labels. That's not a bad model! Not so Naive after all.\n",
    "\n",
    "```python\n",
    "# Make predictions and compare them to test labels\n",
    "predictions = text_classifier.predict(X_test)\n",
    "accuracy = 100 * np.mean(predictions == y_test.label)\n",
    "print(f\"The model is {accuracy:.2f}% accurate.\")\n",
    "```\n",
    "\n",
    "```\n",
    "The model is 97.87% accurate.\n",
    "```\n",
    "\n",
    "11\\. Let's practice!\n",
    "--------------------\n",
    "\n",
    "03:47 - 03:54\n",
    "\n",
    "Alright, you've seen enough, time to get this model into Acme's hands! Let's code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing audio files for text classification\n",
    "=============================================\n",
    "\n",
    "Acme are very impressed with your work so far. So they've sent over two more folders of audio files.\n",
    "\n",
    "One folder is called `pre_purchase` and contains audio snippets from customers who are pre-purchase, like `pre_purchase_audio_25.mp3` ([file](https://assets.datacamp.com/production/repositories/4637/datasets/2acd3f72cd3753f200fae1479d7c06f2ea70cf7d/pre-purchase-audio-25.wav)). \n",
    "\n",
    "And the other is called `post_purchase` and contains audio snippets from customers who have made a purchase (post-purchase), like `post_purchase_audio_27.mp3` ([file](https://assets.datacamp.com/production/repositories/4637/datasets/30c755abc91782decd347c0b7c3b2c9ab86751a0/post-purchase-audio-27.wav)).\n",
    "\n",
    "Upon inspecting the files you find there's about 50 in each and they're in the `.mp3` format.\n",
    "\n",
    "Acme want to know if you can build a classifier to classify future calls. You tell them you sure can.\n",
    "\n",
    "So in this exercise, you'll go through each folder and convert the audio files to `.wav` format using `convert_to_wav()` so you can transcribe them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in post_purchase:\n",
    "    print(f\"Converting {file} to .wav...\")\n",
    "    convert_to_wav(\"post_purchase_audio_0.mp3\")\n",
    "\n",
    "# Convert pre purchase\n",
    "for file in pre_purchase:\n",
    "    print(f\"Converting {file} to .wav...\")\n",
    "    convert_to_wav(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribing phone call excerpts\n",
    "================================\n",
    "\n",
    "In this exercise, we'll transcribe the audio files we converted to `.wav` format to text using `transcribe_audio()`.\n",
    "\n",
    "Since there's lots of them and there could be more, we'll build a function `create_test_list()` which takes a list of filenames of audio files as input and goes through each file transcribing the text.\n",
    "\n",
    "`create_test_list()` uses our `transcribe_audio()` function we created earlier and returns a list of strings containing the transcribed text from each audio file.\n",
    "\n",
    "`pre_purchase_wav_files` and `post_purchase_wav_files` are lists of audio snippet filenames.\n",
    "\n",
    "Instructions 1/2\n",
    "----------------\n",
    "\n",
    "-   Use `transcribe_audio()` to transcribe the current `file` to text and add it to the text list.\n",
    "-   Return the text list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_list(folder):\n",
    "  # Create empty list\n",
    "  text_list = []\n",
    "  \n",
    "  # Go through each file\n",
    "  for file in folder:\n",
    "    # Make sure the file is .wav\n",
    "    if file.endswith(\".wav\"):\n",
    "      print(f\"Transcribing file: {file}...\")\n",
    "      \n",
    "      # Transcribe audio and append text to list\n",
    "      text_list.append(transcribe_audio(file))   \n",
    "  return text_list\n",
    "\n",
    "create_text_list(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 2/2\n",
    "----------------\n",
    "\n",
    "-   Use `create_text_list()` to transcribe all post and pre purchase audio snippets.\n",
    "-   Check the first transcription of the post purchase text list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_purchase_text = create_text_list(post_purchase_wav_files)\n",
    "pre_purchase_text = create_text_list(pre_purchase_wav_files)\n",
    "\n",
    "# Inspect the first transcription of post purchase\n",
    "print(post_purchase_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizing transcribed phone call data\n",
    "======================================\n",
    "\n",
    "We're almost ready to build a text classifier. But right now, all of our transcribed text data is in two lists, `pre_purchase_text` and `post_purchase_text`.\n",
    "\n",
    "To organize it better for building a text classifier as well as for future use, we'll put it together into a pandas DataFrame.\n",
    "\n",
    "To start we'll import `pandas` as `pd` then we'll create a post purchase dataframe, `post_purchase_df` using `pd.DataFrame()`.\n",
    "\n",
    "We'll pass `pd.DataFrame()` a dictionary containing a `\"label\"` key with a value of `\"post_purchase\"` and a `\"text\"` key with a value of our `post_purchase_text` list.\n",
    "\n",
    "We'll do the same for `pre_purchase_df` except with `pre_purchase_text`.\n",
    "\n",
    "To have all the data in one place, we'll use `pd.concat()` and pass it the pre and post purchase DataFrames.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Create `post_purchase_df` using the `post_purchase_text` list.\n",
    "-   Create `pre_purchase_df` using the `pre_purchase_text` list.\n",
    "-   Combine the two DataFrames using `pd.concat()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Make dataframes with the text\n",
    "post_purchase_df = pd.DataFrame({\"label\": \"post_purchase\",\n",
    "                                 \"text\": post_purchase_text})\n",
    "pre_purchase_df = pd.DataFrame({\"label\": \"pre_purchase\",\n",
    "                                \"text\": pre_purchase_text})\n",
    "\n",
    "# Combine DataFrames\n",
    "df = pd.concat([post_purchase_df, pre_purchase_df])\n",
    "\n",
    "# Print the combined DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a spoken language text classifier\n",
    "========================================\n",
    "\n",
    "Now you've transcribed some customer call audio data, we'll build a model to classify whether the text from the customer call is `pre_purchase` or `post_purchase`.\n",
    "\n",
    "We've got 45 examples of `pre_purchase` calls and 57 examples of `post_purchase` calls.\n",
    "\n",
    "The data the model will train on is stored in `train_df` and the data the model will predict on is stored in `test_df`.\n",
    "\n",
    "Try printing the `.head()` of each of these to the console.\n",
    "\n",
    "We'll build an `sklearn pipeline` using `CountVectorizer()` and `TfidfTransformer()`to convert our text samples to numbers and then use a `MultinomialNB()` classifier to learn what category each sample belongs to.\n",
    "\n",
    "This model will work well on our small example here but for larger amounts of text, you may want to consider something more sophisticated.\n",
    "\n",
    "Instructions 1/2\n",
    "----------------\n",
    "\n",
    "-   Create `text_classifier` using `CountVectorizer()`, `TfidfTransformer()`, and `MultinomialNB()`.\n",
    "-   Fit `text_classifier` on `train_df.text`and `train_df.label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the text_classifier as an sklearn pipeline\n",
    "text_classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Fit the classifier pipeline on the training data\n",
    "text_classifier.fit(train_df.text, train_df.label)\n",
    "\n",
    "# Evaluate the MultinomialNB model\n",
    "predicted = text_classifier.predict(test_df.text)\n",
    "accuracy = 100 * np.mean(predicted == test_df.label)\n",
    "print(f'The model is {accuracy}% accurate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 2/2\n",
    "----------------\n",
    "\n",
    "-   Create `predicted` by calling `predict()` on `text_classifier` and passing it the text column of `test_df`.\n",
    "-   Evaluate the model by seeing how `predicted` compares to the `test_df.label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the text_classifier as an sklearn pipeline\n",
    "text_classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Fit the classifier pipeline on the training data\n",
    "text_classifier.fit(train_df.text, train_df.label)\n",
    "\n",
    "# Evaluate the MultinomialNB model\n",
    "predicted = text_classifier.predict(test_df.text)\n",
    "accuracy = 100 * np.mean(predicted == test_df.label)\n",
    "print(f'The model is {accuracy}% accurate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
