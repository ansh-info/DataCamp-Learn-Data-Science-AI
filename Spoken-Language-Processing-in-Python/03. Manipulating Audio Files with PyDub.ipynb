{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Introduction to PyDub\n",
    "-------------------------\n",
    "\n",
    "00:00 - 00:31\n",
    "\n",
    "As you know, a big part of working with data, especially audio files, is ensuring it's all in a consistent format. PyDub is a Python library made by James Robert which provides a gold mine of tools for manipulating audio files. Becoming familiar with PyDub will give you a programmatic way to ensure your audio files are consistent and in an ideal format for transcription locally or through an API.\n",
    "\n",
    "2\\. Installing PyDub\n",
    "--------------------\n",
    "\n",
    "00:31 - 01:00\n",
    "\n",
    "You can install PyDub via pip, by running pip install PyDub on the command line. If you're working with only wav files, PyDub works out of the box. However, for file formats like mp3, you'll need ffmpeg, an open source audio library, which can be installed via ffmpeg dot org.\n",
    "\n",
    "```python\n",
    "$ pip install pydub\n",
    "```\n",
    "\n",
    "- If using files other than `.wav`, install ffmpeg via ffmpeg.org\n",
    "\n",
    "3\\. PyDub's main class, AudioSegment\n",
    "------------------------------------\n",
    "\n",
    "01:00 - 02:06\n",
    "\n",
    "Once you've installed PyDub, you'll find all of its functionality is built on one main class, AudioSegment. To use it, we import it using from pydub import AudioSegment. Then we can use AudioSegment and the from file method, to import an audio file. The from file method requires the argument file, which takes a string containing an audio file's file path. In our case, wav file dot wav. The format parameter takes the target audio file's file format but is optional as it gets inferred from the audio file name. Remember, for file types other than wav, you'll need ffmpeg. Running this will create an instance of AudioSegment called wav file of type pydub audio segment. You'll see soon how useful this class is.\n",
    "\n",
    "```python\n",
    "# Import PyDub main class\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Import an audio file\n",
    "wav_file = AudioSegment.from_file(file=\"wav_file.wav\", format=\"wav\")\n",
    "\n",
    "# Format parameter only for readability \n",
    "wav_file = AudioSegment.from_file(file=\"wav_file.wav\")\n",
    "\n",
    "type(wav_file)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "pydub.audio_segment.AudioSegment\n",
    "```\n",
    "\n",
    "4\\. Playing an audio file\n",
    "-------------------------\n",
    "\n",
    "02:06 - 02:59\n",
    "\n",
    "Let's say you wanted to play an audio file to check its quality, you can use the play function on any AudioSegment. The play function requires simpleaudio or pyaudio for wav files and ffmpeg for all others. Since ours is a wav file, we'll install simpleaudio via pip. Then we import play from pydub dot playback. And to play our AudioSegment instance variable, wav_file, we pass it to the play function. Running the play function will play wav_file out loud. Note, due to limitations of the DataCamp classroom, the play function does not work on DataCamp but will work locally.\n",
    "\n",
    "Here is the content of the image converted to markdown format:\n",
    "\n",
    "```python\n",
    "# Install simpleaudio for wav playback\n",
    "$pip install simpleaudio\n",
    "```\n",
    "\n",
    "```python\n",
    "# Import play function\n",
    "from pydub.playback import play\n",
    "```\n",
    "\n",
    "```python\n",
    "# Import audio file\n",
    "wav_file = AudioSegment.from_file(file=\"wav_file.wav\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# Play audio file\n",
    "play(wav_file)\n",
    "```\n",
    "\n",
    "5\\. Audio parameters\n",
    "--------------------\n",
    "\n",
    "02:59 - 03:27\n",
    "\n",
    "When you import a file with from file, PyDub automatically infers a number of parameters about the file. These are stored as attributes in the AudioSegment instance. For example, calling channels on AudioSegment will show you the number of channels, 1 for mono, 2 for stereo audio. Calling frame rate gives you the sample of your AudioSegment in Hertz.\n",
    "\n",
    "```python\n",
    "# Import audio files\n",
    "wav_file = AudioSegment.from_file(file=\"wav_file.wav\") \n",
    "two_speakers = AudioSegment.from_file(file=\"two_speakers.wav\")\n",
    "\n",
    "# Check number of channels\n",
    "print(wav_file.channels)  # Output: 1, 2\n",
    "print(two_speakers.channels)  # Output: 1, 2\n",
    "\n",
    "# Access frame rate\n",
    "print(wav_file.frame_rate)  # Output: 480000\n",
    "```\n",
    "\n",
    "The key points are:\n",
    "\n",
    "1. The code imports two audio files, `wav_file.wav` and `two_speakers.wav`, using the `AudioSegment.from_file()` method.\n",
    "\n",
    "2. It then checks the number of channels for each audio file by accessing the `channels` attribute of the `AudioSegment` objects. Both files have 2 channels.\n",
    "\n",
    "3. Finally, it prints the frame rate of the `wav_file`, which is 480000 frames per second.\n",
    "\n",
    "Let me know if you need any clarification or have additional questions!\n",
    "\n",
    "6\\. Audio parameters\n",
    "--------------------\n",
    "\n",
    "03:27 - 03:45\n",
    "\n",
    "sample width tells you the number of bytes per sample. 1 means 8-bit, 2 means 16-bit. max will tell you the max amplitude of your audio file, which can be considered loudness and is useful for normalizing sound levels.\n",
    "\n",
    "```python\n",
    "# Find the number of bytes per sample\n",
    "wav_file.sample_width\n",
    "\n",
    "2\n",
    "\n",
    "# Find the max amplitude\n",
    "wav_file.max\n",
    "\n",
    "8488\n",
    "```\n",
    "\n",
    "7\\. Audio parameters\n",
    "--------------------\n",
    "\n",
    "03:45 - 03:51\n",
    "\n",
    "Finally, calling len on any AudioSegment will tell you the duration of the audio file in milliseconds.\n",
    "\n",
    "```python\n",
    "# Duration of audio file in milliseconds\n",
    "len(wav_file)\n",
    "\n",
    "3284\n",
    "```\n",
    "\n",
    "8\\. Changing audio parameters\n",
    "-----------------------------\n",
    "\n",
    "03:51 - 04:11\n",
    "\n",
    "Having these parameters readily available is helpful to ensure all of your audio files are consistent. You can adjust them using set attribute name style functions like set sample width to adjust the sample width.\n",
    "\n",
    "```python\n",
    "# Change ATTRIBUTENAME of AudioSegment to x\n",
    "changeed_audio_segment = audio_segment.set_ATTRIBUTENAME(x)\n",
    "\n",
    "# Change sample width to 1\n",
    "wav_file_width_1 = wav_file.sample_width(1)\n",
    "wav_file_width_1.sample_width\n",
    "\n",
    "1\n",
    "```\n",
    "\n",
    "9\\. Changing audio parameters\n",
    "-----------------------------\n",
    "\n",
    "04:11 - 04:45\n",
    "\n",
    "Or set frame rate to change the sample rate. And set channels to alter the number of channels. Some APIs require your audio files to have certain values for these parameters. A rule of thumb is the higher the values, excluding channels, the better. You should aim for a minimum of 16,000 Hertz as the frame rate and to have your audio files in wav format. We'll see how to convert audio files using PyDub in a later lesson.\n",
    "\n",
    "```python\n",
    "# Change sample rate\n",
    "wav_file_16k = wav_file.frame_rate(16000)\n",
    "wav_file_16k.frame_rate\n",
    "\n",
    "16000\n",
    "\n",
    "# Change number of channels\n",
    "wav_file_1_channel = wav_file.set_channels(1)\n",
    "wav_file_1_channel.channels\n",
    "\n",
    "1\n",
    "```\n",
    "\n",
    "10\\. Let's practice!\n",
    "--------------------\n",
    "\n",
    "04:45 - 04:51\n",
    "\n",
    "For now, let's practice importing and altering some audio files!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import an audio file with PyDub\n",
    "===============================\n",
    "\n",
    "`PyDub`'s `AudioSegment` class makes it easy to import and manipulate audio files with Python.\n",
    "\n",
    "In this exercise, we'll import an audio file of interest by creating an instance of `AudioSegment`.\n",
    "\n",
    "To import an audio file, you can use the `from_file()` function on `AudioSegment` and pass it your target audio file's pathname as a string. The `format` parameter gives you an option to specify the format of your audio file, however, this is optional as `PyDub` will automatically infer it.\n",
    "\n",
    "`PyDub` works with `.wav` files without any extra dependencies but for other file types like `.mp3`, you'll need to install [ffmpeg](https://www.ffmpeg.org/).\n",
    "\n",
    "A sample audio file has been setup as `wav_file.wav`, you can listen to it [here](https://assets.datacamp.com/production/repositories/4637/datasets/6238f8088db33efb5d103dfac1e42eb9fe3e6f2b/wav_file.wav).\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import `AudioSegment` from `pydub`.\n",
    "-   Call the `from_file` method and pass it the audio file pathname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AudioSegment from Pydub\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Create an AudioSegment instance\n",
    "wav_file = AudioSegment.from_file(file='wav_file.wav', \n",
    "                                  format=\"wav\")\n",
    "\n",
    "# Check the type\n",
    "print(type(wav_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play an audio file with PyDub\n",
    "=============================\n",
    "\n",
    "If you're working with audio files, chances are you want to listen to them.\n",
    "\n",
    "`PyDub`'s `playback` module provides a function called `play()` which can be passed an AudioSegment. Running the `play()`function with an AudioSegment passed in will play the AudioSegment out loud.\n",
    "\n",
    "This can be helpful to check the quality of your audio files and assess any changes you need to make.\n",
    "\n",
    "In this exercise you'll see how simple it is to use the `play()` function.\n",
    "\n",
    "Remember: to use the `play()` function, you'll need `simpleaudio` or `pyaudio` installed for `.wav` files and `ffmpeg` for other kinds of files.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import `play` from the `pydub.playback`module.\n",
    "-   Call `play()` whilst passing it the `wav_file`AudioSegment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AudioSegment and play\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "# Create an AudioSegment instance\n",
    "wav_file = AudioSegment.from_file(file=\"wav_file.wav\", \n",
    "                                  format=\"wav\")\n",
    "\n",
    "# Play the audio file\n",
    "play(wav_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio parameters with PyDub\n",
    "===========================\n",
    "\n",
    "Every audio file you work with will have a number of characteristics associated with them, such as, channels, frame rate (or sample rate), sample width and more.\n",
    "\n",
    "Knowing these parameters is useful to ensure your audio files are compatible with various API requirements for speech transcription.\n",
    "\n",
    "For example, many APIs recommend a minimum frame rate (`wav_file.frame_rate`) of 16,000 Hz.\n",
    "\n",
    "When you create an instance of `AudioSegment`, `PyDub` automatically infers these parameters from your audio files and saves them as attributes.\n",
    "\n",
    "In this exercise, we'll explore these attributes.\n",
    "\n",
    "Instructions 1/4\n",
    "----------------\n",
    "\n",
    "-   -   Find the `frame_rate` of `wav_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio file\n",
    "wav_file = AudioSegment.from_file(file=\"wav_file.wav\")\n",
    "\n",
    "# Find the frame rate\n",
    "print(wav_file.frame_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 2/4\n",
    "----------------\n",
    "\n",
    "-   -   Find the number of channels of `wav_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio file\n",
    "wav_file = AudioSegment.from_file(file=\"wav_file.wav\")\n",
    "\n",
    "# Find the number of channels\n",
    "print(wav_file.channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 3/4\n",
    "----------------\n",
    "\n",
    "-   -   Find the max amplitude of `wav_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio file\n",
    "wav_file = AudioSegment.from_file(file=\"wav_file.wav\")\n",
    "\n",
    "# Find the max amplitude\n",
    "print(wav_file.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 4/4\n",
    "----------------\n",
    "\n",
    "-   -   Find the length of `wav_file` in milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio file\n",
    "wav_file = AudioSegment.from_file(file=\"wav_file.wav\")\n",
    "\n",
    "# Find the length\n",
    "print(len(wav_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting audio parameters\n",
    "==========================\n",
    "\n",
    "During your exploratory data analysis, you may find some of the parameters of your audio files differ or are incompatible with speech recognition APIs.\n",
    "\n",
    "Don't worry, `PyDub` has built-in functionality which allows you to change various attributes.\n",
    "\n",
    "For example, you can set the frame rate of your audio file calling `set_frame_rate()` on your `AudioSegment` instance and passing it an integer of the desired frame rate measured in Hertz.\n",
    "\n",
    "In this exercise, we'll practice altering some audio attributes.\n",
    "\n",
    "Instructions 1/3\n",
    "----------------\n",
    "\n",
    "-   -   Create a new `wav_file` with a frame rate of 16,000 Hz and then check its frame rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio file\n",
    "wav_file = AudioSegment.from_file(file=\"wav_file.wav\")\n",
    "\n",
    "# Create a new wav file with adjusted frame rate\n",
    "wav_file_16k = wav_file.set_frame_rate(16000)\n",
    "\n",
    "# Check the frame rate of the new wav file\n",
    "print(wav_file_16k.frame_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 2/3\n",
    "----------------\n",
    "\n",
    "-   -   Set the `wav_file` number of channels to 1 and then check the number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio file\n",
    "wav_file = AudioSegment.from_file(file=\"wav_file.wav\")\n",
    "\n",
    "# Set number of channels to 1\n",
    "wav_file_1_ch = wav_file.set_channels(1)\n",
    "\n",
    "# Check the number of channels\n",
    "print(wav_file_1_ch.channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 3/3\n",
    "----------------\n",
    "\n",
    "-   -   Print the sample width of `wav_file` and then set it to 1 and print it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio file\n",
    "wav_file = AudioSegment.from_file(file=\"wav_file.wav\")\n",
    "\n",
    "# Print sample_width\n",
    "print(f\"Old sample width: {wav_file.sample_width}\")\n",
    "\n",
    "# Set sample_width to 1\n",
    "wav_file_sw_1 = wav_file.set_sample_width(1)\n",
    "\n",
    "# Check new sample_width\n",
    "print(f\"New sample width: {wav_file_sw_1.sample_width}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Manipulating audio files with PyDub\n",
    "---------------------------------------\n",
    "\n",
    "00:00 - 00:10\n",
    "\n",
    "Now you've had a little experience with PyDub and the AudioSegment class, in this lesson, we'll start to see just how powerful it is.\n",
    "\n",
    "2\\. Turning it down to 11\n",
    "-------------------------\n",
    "\n",
    "00:10 - 00:37\n",
    "\n",
    "Are your audio files too loud or too quiet? You can make your AudioSegments louder or quieter by adding or subtracting integers. Let's make our wav file 60 decibels quieter. You'll see if you tried to transcribe audio this quiet with recognize google as we saw in an earlier lesson, it would return an error.\n",
    "\n",
    "```python\n",
    "# Import audio file\n",
    "wav_file = AudioSegment.from_file(\"wav_file.wav\")\n",
    "\n",
    "# Minus 60 dB\n",
    "quiet_wav_file = wav_file - 60\n",
    "\n",
    "# Try to recognize quiet audio\n",
    "recognizer.recognize_google(quiet_wav_file)\n",
    "```\n",
    "\n",
    "#### Unknown Value Error:\n",
    "\n",
    "3\\. Increasing the volume\n",
    "-------------------------\n",
    "\n",
    "00:37 - 01:11\n",
    "\n",
    "In practice, you're more likely to want to increase the volume of your AudioSegments. You can do this by adding an integer. This will increase your AudioSegment's average volume level by the same number of decibels. If your audio files are too quiet or too loud, they may produce transcription errors. As you could imagine, speech transcription works best on clear, audible speech. If you can't hear it, chances are, a speech recognition system can't either.\n",
    "\n",
    "```python\n",
    "# Increase the volume by 10 dB\n",
    "louder_wav_file = wav_file + 10\n",
    "\n",
    "# Try to recognize\n",
    "recognizer.recognize_google(louder_wav_file)\n",
    "```\n",
    "\n",
    "This is a WAV file.\n",
    "\n",
    "4\\. This all sounds the same\n",
    "----------------------------\n",
    "\n",
    "01:11 - 02:02\n",
    "\n",
    "Some audio files might differ in loudness throughout. They might begin quiet and then increase in sound as a person gets comfortable talking or adjusts the microphone. The normalize function is great for taking care of this. It finds the highest level of audio throughout an AudioSegment and then boosts the rest of the audio up to match. You can import the normalize function via the PyDub effects module. Then to even out the sound levels in an AudioSegment, you pass it to the normalize function. You can check the sound using the play function. Ensuring your audio file is the same loudness throughout can help with transcription.\n",
    "\n",
    "```python\n",
    "# Import AudioSegment and normalize\n",
    "from pydub import AudioSegment\n",
    "from pydub.effects import normalize\n",
    "from pydub.playback import play\n",
    "\n",
    "# Import uneven sound audio file\n",
    "Loud_quiet = AudioSegment.from_file(\"Loud_quiet.wav\") \n",
    "\n",
    "# Normalize the sound levels\n",
    "normalized_loud_quiet = normalize(Loud_quiet)\n",
    "\n",
    "# Check the sound\n",
    "play(normalized_loud_quiet)\n",
    "```\n",
    "\n",
    "5\\. Remixing your audio files\n",
    "-----------------------------\n",
    "\n",
    "02:02 - 02:43\n",
    "\n",
    "Another handy feature of AudioSegments is that they are sliceable and combinable. This is helpful if you need to cut your audio files down or combine them in some way. Let's say you knew your audio files had 5-seconds of static at the beginning and you didn't want to waste compute power trying to transcribe the static. You could use slicing to remove the first 5-seconds of audio. Since AudioSegments are measured in milliseconds, you would do this by only keeping everything after 5000. And then the new AudioSegment won't contain the 5-seconds of static.\n",
    "\n",
    "```python\n",
    "# Import audio with static at start\n",
    "static_at_start = AudioSegment.from_file(\"static_at_start.wav\")\n",
    "\n",
    "# Remove the static via slicing\n",
    "no_static_at_start = static_at_start[5000:]\n",
    "\n",
    "# Check the new sound\n",
    "play(no_static_at_start)\n",
    "```\n",
    "\n",
    "6\\. Remixing your audio files\n",
    "-----------------------------\n",
    "\n",
    "02:43 - 03:27\n",
    "\n",
    "Or what if your audio file came in separate parts? Due to length issues or a broken recording? You can easily add two AudioSegments together using the addition operator. Operators on AudioSegments work in order of operation. So wav file 1 plus wav file 2 plus 10 will combine wav file 1 and 2 and increase the combination by 10 decibels. If your audio files have different characteristics, combining them like this automatically scales parameters such as frame rate to be equal to the higher quality audio file.\n",
    "\n",
    "```python\n",
    "# Import two audio files\n",
    "wav_file_1 = AudioSegment.from_file(\"wav_file_1.wav\")\n",
    "wav_file_2 = AudioSegment.from_file(\"wav_file_2.wav\")\n",
    "\n",
    "# Combine the two audio files\n",
    "wav_file_3 = wav_file_1 + wav_file_2\n",
    "\n",
    "# Check the sound\n",
    "play(wav_file_3)\n",
    "\n",
    "# Combine two wav files and make the combination louder\n",
    "louder_wav_file_3 = wav_file_1 + wav_file_2 + 10\n",
    "```\n",
    "\n",
    "7\\. Splitting your audio\n",
    "------------------------\n",
    "\n",
    "03:27 - 04:03\n",
    "\n",
    "You saw in a previous lesson, the issue of transcribing multiple speakers on one audio file. Well, let's say you were trying to transcribe phone calls and using PyDub, you found your audio files are recorded in stereo format, two channels. PyDub allows for a stereo AudioSegment to split into two mono, single channel, AudioSegments using the split to mono function. Calling this returns a list containing each channel.\n",
    "\n",
    "```python\n",
    "# Import phone call audio\n",
    "phone_call = AudioSegment.from_file(\"phone_call.wav\")\n",
    "\n",
    "# Find number of channels\n",
    "phone_call.channels\n",
    "\n",
    "# Split stereo to mono\n",
    "phone_call_channels = phone_call.split_to_mono()\n",
    "phone_call_channels\n",
    "```\n",
    "\n",
    "The code first imports the phone call audio file using the `AudioSegment.from_file()` function. It then checks the number of audio channels in the `phone_call` object using the `phone_call.channels` attribute.\n",
    "\n",
    "Next, the code splits the stereo audio into separate left and right mono channels using the `phone_call.split_to_mono()` method. The resulting channels are stored in the `phone_call_channels` variable.\n",
    "\n",
    "This allows you to work with the individual mono channels if needed, for example, to process or play back the audio independently.\n",
    "\n",
    "8\\. Splitting your audio\n",
    "------------------------\n",
    "\n",
    "04:03 - 04:20\n",
    "\n",
    "Because each of these is an AudioSegment, you can use all of the functionality you've seen previously on them. And as long as your speakers have been recorded on separate channels, you can now transcribe their audio individually.\n",
    "\n",
    "```python\n",
    "# Find number of channels of first list item \n",
    "phone_call_channels[0].channels\n",
    "\n",
    "# Recognize the first channel\n",
    "recognizer.recognize_google(phone_call_channel_1)\n",
    "\n",
    "the pydub library is really useful\n",
    "```\n",
    "\n",
    "9\\. Let's code!\n",
    "---------------\n",
    "\n",
    "04:20 - 04:32\n",
    "\n",
    "Okay, I bet you're now starting to realise how helpful PyDub can be for working with your audio and speech files. Before we go further, let's get hands-on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning it down... then up\n",
    "==========================\n",
    "\n",
    "Speech recognition works best on clean, audible speech. If your audio files are too quiet or too loud, it can hinder transcription.\n",
    "\n",
    "In this exercise, you'll see how to make an `AudioSegment` quieter or louder.\n",
    "\n",
    "Since the `play()` function won't play your changes in the DataCamp classroom.\n",
    "\n",
    "The baseline audio file, `volume_adjusted.wav`can be heard [here](https://assets.datacamp.com/production/repositories/4637/datasets/520b312f96433535f93656d9e6d61fdb10f5c517/volume_adjusted.wav).\n",
    "\n",
    "Instructions 1/2\n",
    "----------------\n",
    "\n",
    "-   -   Import `volume_adjusted.wav` and lower its volume by 60 dB and save it to a new variable `quiet_volume_adjusted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Import audio file\n",
    "volume_adjusted = AudioSegment.from_file('volume_adjusted.wav')\n",
    "\n",
    "# Lower the volume by 60 dB\n",
    "quiet_volume_adjusted = volume_adjusted - 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions 2/2\n",
    "----------------\n",
    "\n",
    "-   -   Import the target audio file, increase its volume by 15 dB and save it to the variable `louder_volume_adjusted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Import audio file\n",
    "volume_adjusted = AudioSegment.from_file('volume_adjusted.wav')\n",
    "\n",
    "# Increase the volume by 15 dB\n",
    "louder_volume_adjusted = volume_adjusted + 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing an audio file with PyDub\n",
    "====================================\n",
    "\n",
    "Sometimes you'll have audio files where the speech is loud in some portions and quiet in others. Having this variance in volume can hinder transcription.\n",
    "\n",
    "Luckily, `PyDub`'s effects module has a function called `normalize()` which finds the maximum volume of an `AudioSegment`, then adjusts the rest of the `AudioSegment` to be in proportion. This means the quiet parts will get a volume boost.\n",
    "\n",
    "You can listen to an example of an audio file which starts as loud then goes quiet, `loud_then_quiet.wav`, [here](https://assets.datacamp.com/production/repositories/4637/datasets/9251c751d3efccf781f3e189d68b37c8d22be9ca/ex3_datacamp_loud_then_quiet.wav).\n",
    "\n",
    "In this exercise, you'll use `normalize()` to normalize the volume of our file, making it sound [more like this](https://assets.datacamp.com/production/repositories/4637/datasets/f0c1ba35ff99f07df8cfeee810c7b12118d9cd0f/ex3_datamcamp_normalized_loud_quiet.wav).\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import `AudioSegment` from `PyDub` and `normalize` from the `PyDub`'s effects module.\n",
    "-   Import the target audio file, `loud_then_quiet.wav` and save it to `loud_then_quiet`.\n",
    "-   Normalize the imported audio file using the `normalize()` function and save it to `normalized_loud_then_quiet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AudioSegment and normalize\n",
    "from pydub import AudioSegment\n",
    "from pydub.effects import normalize\n",
    "\n",
    "# Import target audio file\n",
    "loud_then_quiet = AudioSegment.from_file('loud_then_quiet.wav')\n",
    "\n",
    "# Normalize target audio file\n",
    "normalized_loud_then_quiet = normalize(loud_then_quiet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chopping and changing audio files\n",
    "=================================\n",
    "\n",
    "Some of your audio files may have sections of redundancy. For example, you might find at the beginning of each file, there's a few seconds of static.\n",
    "\n",
    "Instead of wasting compute trying to transcribe static, you can remove it. \n",
    "\n",
    "Since an `AudioSegment` is iterable, and measured in milliseconds, you can use slicing to alter the length.\n",
    "\n",
    "To get the first 3-seconds of `wav_file`, you'd use `wav_file[:3000]`.\n",
    "\n",
    "You can also add two `AudioSegment`'s together using the addition operator. This is helpful if you need to combine several audio files.\n",
    "\n",
    "To practice both of these, we're going to remove the first four seconds of [part*1.wav*](https://assets.datacamp.com/production/repositories/4637/datasets/6ef2e43497070fd23c6ce4c0fe1d9d0e46469750/ex3_slicing_part_1.wav), and add the remainder to [part2.wav](https://assets.datacamp.com/production/repositories/4637/datasets/3b47eb5ca2c696e816af04053150d96fd95b4c7f/ex3_slicing_part_2.wav). Leaving the end result sounding like [part_3.wav](https://assets.datacamp.com/production/repositories/4637/datasets/3803042506ed07d707fe264d0bc6ec6ffa891e63/ex3_slicing_part_3.wav).\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import `part_1.wav` and `part_2.wav` and save them to `part_1` and `part_2`respectively.\n",
    "-   Remove the first 4-seconds of `part_1` using slicing and save the new audio to `part_1_removed`.\n",
    "-   Add `part_1_removed` to `part_2` and save it to `part_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Import part 1 and part 2 audio files\n",
    "part_1 = AudioSegment.from_file('part_1.wav')\n",
    "part_2 = AudioSegment.from_file('part_2.wav')\n",
    "\n",
    "# Remove the first four seconds of part 1\n",
    "part_1_removed = part_1[4000:]\n",
    "\n",
    "# Add the remainder of part 1 and part 2 together\n",
    "part_3 = part_1_removed + part_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting stereo audio to mono with PyDub\n",
    "=========================================\n",
    "\n",
    "If you're trying to transcribe phone calls, there's a chance they've been recorded in stereo format, with one speaker on each channel.\n",
    "\n",
    "As you've seen, it's hard to transcribe an audio file with more than one speaker. One solution is to split the audio file with multiple speakers into single files with individual speakers.\n",
    "\n",
    "`PyDub`'s `split_to_mono()` function can help with this. When called on an `AudioSegment`recorded in stereo, it returns a list of two separate `AudioSegment`'s in mono format, one for each channel.\n",
    "\n",
    "In this exercise, you'll practice this by splitting this [stereo phone call](https://assets.datacamp.com/production/repositories/4637/datasets/810bb65e2e681e086e90bc2c6c2372bc4bd2cb52/ex3_stereo_call.wav) (`stereo_phone_call.wav`) recording into [channel 1](https://assets.datacamp.com/production/repositories/4637/datasets/0aa876f5cb924035481d7b786a3701624e86d1e7/ex3_stereo_call_channel_1.wav) and [channel 2](https://assets.datacamp.com/production/repositories/4637/datasets/2a16db969efc35186fe25ca45a4dbd506318a1cd/ex3_stereo_call_channel_2.wav). This separates the two speakers, allowing for easier transcription.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import `AudioSegment` from `pydub`.\n",
    "-   Create an `AudioSegment` instance `stereo_phone_call` with `stereo_phone_call.wav`.\n",
    "-   Split `stereo_phone_call` into `channels`using `split_to_mono()` and check the channels of the resulting output.\n",
    "-   Save each channel to new variables, `phone_call_channel_1` and `phone_call_channel_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AudioSegment\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Import stereo audio file and check channels\n",
    "stereo_phone_call = AudioSegment.from_file(\"stereo_phone_call.wav\")\n",
    "print(f\"Stereo number channels: {stereo_phone_call.channels}\")\n",
    "\n",
    "# Split stereo phone call and check channels\n",
    "channels = stereo_phone_call.split_to_mono()\n",
    "print(f\"Split number channels: {channels[0].channels}, {channels[1].channels}\")\n",
    "\n",
    "# Save new channels separately\n",
    "phone_call_channel_1 = channels[0]\n",
    "phone_call_channel_2 = channels[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
