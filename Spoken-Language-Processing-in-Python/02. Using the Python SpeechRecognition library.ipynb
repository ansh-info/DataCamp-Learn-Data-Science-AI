{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. SpeechRecognition Python library\n",
    "------------------------------------\n",
    "\n",
    "00:00 - 00:15\n",
    "\n",
    "To get started with spoken language recognition, let's check out the SpeechRecognition Python Library. We'll start with why the SpeechRecognition Library. And then we'll get into seeing how we can use Google's web speech API to transcribe speech to text.\n",
    "\n",
    "2\\. Why the SpeechRecognition library?\n",
    "--------------------------------------\n",
    "\n",
    "00:15 - 00:55\n",
    "\n",
    "Automatic speech recognition is a tough challenge. And there's no shortage of companies and research institutions working on libraries to help solve it. There's the Sphinx library by Carnegie Mellon University, Kaldi, SpeechRecognition, and more. Some have more robust features than others but they all have the same goal of transcribing audio files to text. We're going to be focused on the SpeechRecognition library because of its low barrier to entry and its compatibility with many available speech recognition APIs we'll see shortly.\n",
    "\n",
    "3\\. Getting started with SpeechRecognition\n",
    "------------------------------------------\n",
    "\n",
    "00:55 - 01:15\n",
    "\n",
    "We can get started with the SpeechRecognition library by installing it from PyPi using pip and running the pip install SpeechRecognition command in a terminal or shell. It's compatible with Python 2 and 3 but we'll be using Python 3.\n",
    "\n",
    "4\\. Using the Recognizer class\n",
    "------------------------------\n",
    "\n",
    "01:15 - 02:23\n",
    "\n",
    "Now we have SpeechRecognition installed, let's check out where all the magic happens, the recognizer class. So how do we use it? To access the Recognizer class, we'll first import the SpeechRecognition module as the abbreviation sr. Then we'll create an instance of the recognizer class by calling it from sr and assigning to a variable, recognizer. Finally, we'll set the recognizers energy threshold to 300. The energy threshold can be thought of as the loudness of audio which is considered speech. Values below the threshold are considered silence, values above are considered speech. A silent room is typically between 0 and 100. SpeechRecognition's documentation recommends 300 as a starting value which covers most speech files. The energy threshold value will adjust automatically as the recognizer listens to an audio file.\n",
    "\n",
    "5\\. Using the Recognizer class to recognize speech\n",
    "--------------------------------------------------\n",
    "\n",
    "02:23 - 03:14\n",
    "\n",
    "Now we've got a recognizer instance ready, it's time to recognize some speech. We chose SpeechRecognition for its flexibility. Here's what I mean. SpeechRecognition has functions built-in to work with many of the best speech recognition APIs. Recognize bing accesses Microsoft's cognitive services, recognize Google uses Google's free web speech API, recognize Google Cloud accesses Google's cloud speed API. And recognize wit uses the wit dot ai platform. They all accept an audio file and return text, which is hopefully the transcribed speech from the audio file. Remember, speech recognition is still far from perfect.\n",
    "\n",
    "6\\. SpeechRecognition Example\n",
    "-----------------------------\n",
    "\n",
    "03:14 - 04:18\n",
    "\n",
    "We'll be using the recognize google function since it's free and doesn't require an API key. However, this limits us to 50 requests per day and if our audio files are too long, it may time out. In my experience, I've had no issues with audio files under 5-minutes. So if you have more audio files or long audio files, you may want to look into one of the paid API services. Let's put everything together with an example. We'll start by importing the speech recognition library as sr. Then we'll initialize a recognizer class. Finally we call recognize google which takes the required parameter audio data. We can also pass it the language our audio file is in. The default language is US English. We're using a mocked version of recognize google for this course so we don't go over the API limit. Running the function returns the speech detected in the audio file as text.\n",
    "\n",
    "7\\. Your turn!\n",
    "--------------\n",
    "\n",
    "04:18 - 04:26\n",
    "\n",
    "Now you've seen a starter example of the SpeechRecognition library, it's time to try it out for yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the wrong speech_recognition API\n",
    "=====================================\n",
    "\n",
    "Which of the following is **not** a speech recognition API within the `speech_recognition` library?\n",
    "\n",
    "An instance of the `Recognizer` class has been created and saved to `recognizer`. You can try calling the API on `recognizer` to see what happens.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "### Possible answers\n",
    "\n",
    "`recognize_google()`\n",
    "\n",
    "`recognize_bing()`\n",
    "\n",
    "`recognize_wit()`\n",
    "\n",
    "[/] `what_does_this_say()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the SpeechRecognition library\n",
    "===================================\n",
    "\n",
    "To save typing `speech_recognition` every time, we'll import it as `sr`.\n",
    "\n",
    "We'll also setup an instance of the `Recognizer`class to use later.\n",
    "\n",
    "The `energy_threshold` is a number between 0 and 4000 for how much the `Recognizer` class should listen to an audio file.\n",
    "\n",
    "`energy_threshold` will dynamically adjust whilst the recognizer class listens to audio.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import the `speech_recognition` library as `sr`.\n",
    "-   Setup an instance of the `Recognizer` class and save it to `recognizer`.\n",
    "-   Set the `recognizer.energy_threshold` to 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the speech_recognition library\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Create an instance of the Recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Set the energy threshold\n",
    "recognizer.energy_threshold = 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Recognizer class\n",
    "==========================\n",
    "\n",
    "Now you've created an instance of the `Recognizer` class we'll use the `recognize_google()` method on it to access the Google web speech API and turn spoken language into text.\n",
    "\n",
    "`recognize_google()` requires an argument `audio_data` otherwise it will return an error.\n",
    "\n",
    "US English is the default language. If your audio file isn't in US English, you can change the language with the `language` argument. A list of language codes can be seen [here](https://cloud.google.com/speech-to-text/docs/languages).\n",
    "\n",
    "An audio file containing English speech has been imported as `clean_support_call_audio`. You can [listen to the audio file here](https://assets.datacamp.com/production/repositories/4637/datasets/393a2f76d057c906de27ec57ea655cb1dc999fce/clean-support-call.wav). SpeechRecognition has also been imported as `sr`.\n",
    "\n",
    "To avoid hitting the API request limit of Google's web API, we've mocked the `Recognizer` class to work with our audio files. This means some functionality will be limited.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Call the `recognize_google()` method on `recognizer` and pass it `clean_support_call_audio`.\n",
    "-   Set the language argument to `\"en-US\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Transcribe the support call audio\n",
    "text = recognizer.recognize_google(\n",
    "  audio_data=clean_support_call_audio, \n",
    "  language=\"en-US\")\n",
    "\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
