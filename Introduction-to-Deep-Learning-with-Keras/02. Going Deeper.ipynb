{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb2309ff",
   "metadata": {},
   "source": [
    "1\\. Binary classification\n",
    "-------------------------\n",
    "\n",
    "00:00 - 00:04\n",
    "\n",
    "You're now ready to learn about binary classification, so let's dive in.\n",
    "\n",
    "2\\. When to use binary classification?\n",
    "--------------------------------------\n",
    "\n",
    "00:04 - 00:19\n",
    "\n",
    "You will use binary classification when you want to solve problems where you predict whether an observation belongs to one of two possible classes. A simple binary classification problem could be learning the boundaries to separate blue from red circles as shown in the image.\n",
    "\n",
    "3\\. Our dataset\n",
    "---------------\n",
    "\n",
    "00:19 - 00:32\n",
    "\n",
    "The dataset for this problem is very simple. The coordinates are pairs of values corresponding to the X and Y coordinates of each circle in the graph. The labels are 1 for red circles and 0 for the blue circles.\n",
    "\n",
    "4\\. Pairplots\n",
    "-------------\n",
    "\n",
    "00:32 - 01:00\n",
    "\n",
    "We can make use of seaborn's pairplot function to explore a small dataset and identify whether our classification problem will be easily separable. We can get an intuition for this if we see that the classes separate well-enough along several variables. In this case, for the circles dataset, there is a very clear boundary: the red circles concentrate at the center while the blue are outside. It should be easy for our network to find a way to separate them just based on x and y coordinates.\n",
    "\n",
    "5\\. The NN architecture\n",
    "-----------------------\n",
    "\n",
    "01:00 - 01:05\n",
    "\n",
    "This is the neural network we will build to classify red and blue dots in our graph.\n",
    "\n",
    "6\\. The NN architecture 2\n",
    "-------------------------\n",
    "\n",
    "01:05 - 01:13\n",
    "\n",
    "We have two neurons as an input layer, one for the x coordinate and another for the y coordinate of each of the red and blue circles in the graph.\n",
    "\n",
    "7\\. The NN architecture 3\n",
    "-------------------------\n",
    "\n",
    "01:13 - 01:22\n",
    "\n",
    "Then we have one hidden layer with four neurons. Four is a good enough number to learn the separation of classes in this dataset. This was found by experimentation.\n",
    "\n",
    "8\\. The NN architecture 4\n",
    "-------------------------\n",
    "\n",
    "01:22 - 01:36\n",
    "\n",
    "We finally end up with a single output neuron which makes use of the sigmoid activation function. It's important to note that, regardless of the activation functions used for the previous layers, we do need the sigmoid activation function for this last output node.\n",
    "\n",
    "9\\. The sigmoid function\n",
    "------------------------\n",
    "\n",
    "01:36 - 01:44\n",
    "\n",
    "The sigmoid activation function squashes the neuron output of the second to last layer to a floating point number between 0 and 1.\n",
    "\n",
    "10\\. The sigmoid function\n",
    "-------------------------\n",
    "\n",
    "01:44 - 01:57\n",
    "\n",
    "You can consider the output of the sigmoid function as the probability of a pair of coordinates being in one class or another. So we can set a threshold and say everything below 0.5 will be a blue circle and everything above a red one.\n",
    "\n",
    "11\\. Let's build it\n",
    "-------------------\n",
    "\n",
    "01:57 - 02:06\n",
    "\n",
    "So let's build our model in keras: We start by importing the sequential model and the dense layer. We then instantiate a sequential model. We add a hidden\n",
    "\n",
    "12\\. Let's build it\n",
    "-------------------\n",
    "\n",
    "02:06 - 02:21\n",
    "\n",
    "layer of 4 neurons and we define an input shape, which consists of 2 neurons. We use the tanh as the activation function, for this hidden layer. Activation functions are covered later in the course, so don't worry about this choice for now. We finally add an output layer\n",
    "\n",
    "13\\. Let's build it\n",
    "-------------------\n",
    "\n",
    "02:21 - 02:34\n",
    "\n",
    "which contains a single neuron, we make use of the sigmoid activation function so that we achieve the behavior we expect from this network, that is obtaining a value between 0 and 1. Our model is now ready to be trained.\n",
    "\n",
    "14\\. Compiling, training, predicting\n",
    "------------------------------------\n",
    "\n",
    "02:34 - 03:01\n",
    "\n",
    "Just as before, we need to compile our model before training. We will use stochastic gradient descent as an optimizer and binary cross-entropy as our loss function. Binary cross-entropy is the function we use when our output neuron is using sigmoid as its activation function. We train our model for 20 epochs passing our coordinates and labels as parameters. Then, we obtain the predicted labels by calling predict on coordinates.\n",
    "\n",
    "15\\. Results\n",
    "------------\n",
    "\n",
    "03:01 - 03:07\n",
    "\n",
    "These are boundaries that were learned to classify our circles. It looks like our model did pretty well!\n",
    "\n",
    "16\\. Let's practice!\n",
    "--------------------\n",
    "\n",
    "03:07 - 03:11\n",
    "\n",
    "It's time to have some fun now with this new architecture you've learned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a0cf73",
   "metadata": {},
   "source": [
    "Exploring dollar bills\n",
    "======================\n",
    "\n",
    "You will practice building classification models in Keras with the **Banknote Authentication** dataset. \n",
    "\n",
    "Your goal is to distinguish between real and fake dollar bills. In order to do this, the dataset comes with 4 features: `variance`,`skewness`,`kurtosis` and `entropy`. These features are calculated by applying mathematical operations over the dollar bill images. The labels are found in the dataframe's `class` column.\n",
    "\n",
    "![](https://assets.datacamp.com/production/repositories/4335/datasets/6ce6fd4fdc548ecd6aaa27b033073c5bfc0995da/dollar_bills.png)\n",
    "\n",
    "A pandas DataFrame named `banknotes` is ready to use, let's do some data exploration!\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import `seaborn` as `sns`.\n",
    "-   Use `seaborn`'s `pairplot()` on `banknotes` and set `hue` to be the name of the column containing the labels.\n",
    "-   Generate descriptive statistics for the banknotes authentication data.\n",
    "-   Count the number of observations per label with `.value_counts()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cfdedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Use pairplot and set the hue to be our class column\n",
    "sns.pairplot(banknotes, hue='class') \n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Describe the data\n",
    "print('Dataset stats: \\n', banknotes.describe())\n",
    "\n",
    "# Count the number of observations per class\n",
    "print('Observations per class: \\n', banknotes['class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972f4e38",
   "metadata": {},
   "source": [
    "A binary classification model\n",
    "=============================\n",
    "\n",
    "Now that you know what the **Banknote Authentication** dataset looks like, we'll build a simple model to distinguish between real and fake bills. \n",
    "\n",
    "You will perform binary classification by using a single neuron as an output. The input layer will have 4 neurons since we have 4 features in our dataset. The model's output will be a value constrained between 0 and 1. \n",
    "\n",
    "We will interpret this output number as the probability of our input variables coming from a fake dollar bill, with 1 meaning we are certain it's a fake bill.\n",
    "\n",
    "![](https://assets.datacamp.com/production/repositories/4335/datasets/db1c482fd8cb154572c3ce79fe9a406c25ed1a9b/model_chapter2_binary_classification.JPG)\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Import the `Sequential` model and `Dense` layer from tensorflow.keras.\n",
    "-   Create a sequential model.\n",
    "-   Add a 4 neuron input layer with the `input_shape` parameter and a 1 neuron output layer with `sigmoid` activation. \n",
    "-   Compile your model using `sgd` as an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sequential model and dense layer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a dense layer\n",
    "model.add(Dense(1, input_shape=(4,), activation='sigmoid'))\n",
    "\n",
    "# Compile your model\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Display a summary of your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823971aa",
   "metadata": {},
   "source": [
    "Is this dollar bill fake ?\n",
    "==========================\n",
    "\n",
    "You are now ready to train your `model` and check how well it performs when classifying new bills! The dataset has already been partitioned into features: `X_train` & `X_test`, and labels: `y_train` & `y_test`.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Train your model for 20 epochs calling `.fit()`, passing in the training data.\n",
    "-   Check your model accuracy using the `.evaluate()` method on the test data.\n",
    "-   Print `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad3030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model for 20 epochs\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "\n",
    "# Evaluate your model accuracy on the test set\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "\n",
    "# Print accuracy\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6afd76",
   "metadata": {},
   "source": [
    "1\\. Multi-class classification\n",
    "------------------------------\n",
    "\n",
    "00:00 - 00:10\n",
    "\n",
    "What about when we have more than two classes to classify? We run into a multi-class classification problem, but don't worry, we just have to make a minor tweak to our neural network architecture.\n",
    "\n",
    "2\\. Throwing darts\n",
    "------------------\n",
    "\n",
    "00:10 - 00:26\n",
    "\n",
    "Identifying who threw which dart in a game of darts is a good example of a multi-class classification problem. Each dart can only be thrown by one competitor. And that means our classes are mutually exclusive since no dart can be thrown by two different competitors simultaneously.\n",
    "\n",
    "3\\. The dataset\n",
    "---------------\n",
    "\n",
    "00:26 - 00:35\n",
    "\n",
    "The darts dataset consist of dart throws by different competitors. The coordinate pairs xCoord and yCoord show where each dart landed.\n",
    "\n",
    "4\\. The dataset\n",
    "---------------\n",
    "\n",
    "00:35 - 00:49\n",
    "\n",
    "Based on the landing position of previously thrown darts we should be able to distinguish between throwers if there's enough variation between their throws. In our pairplot we can see that different players tend to aim at specific regions of the board.\n",
    "\n",
    "5\\. The architecture\n",
    "--------------------\n",
    "\n",
    "00:49 - 01:00\n",
    "\n",
    "The model for this dataset has two neurons as inputs, since our predictors are xCoord and yCoord. We will define them using the input_shape argument, just as we've done before.\n",
    "\n",
    "6\\. The architecture\n",
    "--------------------\n",
    "\n",
    "01:00 - 01:08\n",
    "\n",
    "In between there will be a series of hidden layers, we are using 3 Dense layers of 128, 64 and 32 neurons each.\n",
    "\n",
    "7\\. The architecture\n",
    "--------------------\n",
    "\n",
    "01:08 - 01:14\n",
    "\n",
    "As outputs we have 4 neurons, one per competitor. Let's look closer at the output layer now.\n",
    "\n",
    "8\\. The output layer\n",
    "--------------------\n",
    "\n",
    "01:14 - 01:39\n",
    "\n",
    "We have 4 outputs, each linked to a possible competitor. Each competitor has a probability of having thrown a given dart, so we must make sure the total sum of probabilities for the output neurons equals one. We achieve this with the softmax activation function. Once we have a probability per output neuron we then choose as our prediction the competitor whose associated output has the highest probability.\n",
    "\n",
    "9\\. Multi-class model\n",
    "---------------------\n",
    "\n",
    "01:39 - 01:58\n",
    "\n",
    "You can build this model as we did in the previous lesson; instantiate a sequential model, add a hidden layer, also defining an input layer with the input_shape parameter,and finish by adding the remaining hidden layers and an output layer with softmax activation. You will do all this yourself in the exercises.\n",
    "\n",
    "10\\. Categorical cross-entropy\n",
    "------------------------------\n",
    "\n",
    "01:58 - 02:26\n",
    "\n",
    "When compiling your model, instead of binary cross-entropy as we used before, we now use categorical cross-entropy or log loss. Categorical cross-entropy measures the difference between the predicted probabilities and the true label of the class we should have predicted. So if we should have predicted 1 for a given class, taking a look at the graph we see we would get high loss values for predicting close to 0 (since we'd be very wrong) and low loss values for predicting closer to 1 (the true label).\n",
    "\n",
    "11\\. Preparing a dataset\n",
    "------------------------\n",
    "\n",
    "02:26 - 03:06\n",
    "\n",
    "Since our outputs are vectors containing the probabilities of each class, our neural network must also be trained with vectors representing this concept. To achieve that we make use of the tensorflow.keras.utils to_categorical function. We first turn our response variable into a categorical variable with pandas Categorical, this allows us to redefine the column using the categorical codes (cat codes) of the different categories. Now that our categories are each represented by a unique integer, we can use the to_categorical function to turn them into one-hot encoded vectors, where each component is 0 except for the one corresponding to the labeled categories.\n",
    "\n",
    "12\\. One-hot encoding\n",
    "---------------------\n",
    "\n",
    "03:06 - 03:23\n",
    "\n",
    "Keras to_categorical essentially perform the process described in the picture above. Label encoded Apple, Chicken and Broccoli turn into a vector of 3 components. A 1 is placed to represent the presence of the class and a 0 to indicate its absence.\n",
    "\n",
    "13\\. Let's practice!\n",
    "--------------------\n",
    "\n",
    "03:23 - 03:29\n",
    "\n",
    "Let's further explore these concepts as you build a multi-class model that predicts who threw which dart!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd84457a",
   "metadata": {},
   "source": [
    "A multi-class model\n",
    "===================\n",
    "\n",
    "You're going to build a model that predicts who threw which dart only based on where that dart landed! (That is the dart's x and y coordinates on the board.)\n",
    "\n",
    "This problem is a multi-class classification problem since each dart can only be thrown by one of 4 competitors. So classes/labels are mutually exclusive, and therefore we can build a neuron with as many output as competitors and use the `softmax` activation function to achieve a total sum of probabilities of 1 over all competitors.\n",
    "\n",
    "The `Sequential` model and `Dense` layers are already imported for you to use.\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Instantiate a `Sequential` model.\n",
    "-   Add 3 dense layers of 128, 64 and 32 neurons each.\n",
    "-   Add a final dense layer with as many neurons as competitors.\n",
    "-   Compile your model using `categorical_crossentropy` loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a sequential model\n",
    "model = Sequential()\n",
    "  \n",
    "# Add 3 dense layers of 128, 64 and 32 neurons each\n",
    "model.add(Dense(128, input_shape=(2,), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "  \n",
    "# Add a dense layer with as many neurons as competitors\n",
    "model.add(Dense(4, activation='softmax'))  # Assuming there are 4 competitors\n",
    "  \n",
    "# Compile your model using categorical_crossentropy loss\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de816a3",
   "metadata": {},
   "source": [
    "Prepare your dataset\n",
    "====================\n",
    "\n",
    "In the console you can check that your labels, `darts.competitor` are not yet in a format to be understood by your network. They contain the names of the competitors as strings. You will first turn these competitors into unique numbers,then use the `to_categorical()` function from `keras.utils`to turn these numbers into their one-hot encoded representation. \n",
    "\n",
    "This is useful for multi-class classification problems, since there are as many output neurons as classes and for every observation in our dataset we just want one of the neurons to be activated.\n",
    "\n",
    "The dart's dataset is loaded as `darts`. Pandas is imported as `pd`. Let's prepare this dataset!\n",
    "\n",
    "Instructions 1/2\n",
    "----------------\n",
    "\n",
    "-   Use the `Categorical()` method from pandas to transform the `competitor` column.\n",
    "-   Assign a number to each competitor using the `cat.codes` attribute from the competitor column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ab217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform into a categorical variable\n",
    "darts.competitor = pd.Categorical(darts.competitor)\n",
    "\n",
    "# Assign a number to each category (label encoding)\n",
    "darts.competitor = darts.competitor.cat.codes\n",
    "\n",
    "# Print the label encoded competitors\n",
    "print('Label encoded competitors: \\n', darts.competitor.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b9b885",
   "metadata": {},
   "source": [
    "Instructions 2/2\n",
    "----------------\n",
    "\n",
    "-   Import `to_categorical` from `tensorflow.keras.utils`.\n",
    "-   Apply `to_categorical()` to your labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09818ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform into a categorical variable\n",
    "darts.competitor = pd.Categorical(darts.competitor)\n",
    "\n",
    "# Assign a number to each category (label encoding)\n",
    "darts.competitor = darts.competitor.cat.codes \n",
    "\n",
    "# Import to_categorical from keras utils module\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "coordinates = darts.drop(['competitor'], axis=1)\n",
    "# Use to_categorical on your labels\n",
    "competitors = to_categorical(darts.competitor)\n",
    "\n",
    "# Now print the one-hot encoded labels\n",
    "print('One-hot encoded competitors: \\n', competitors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00305a2c",
   "metadata": {},
   "source": [
    "Training on dart throwers\n",
    "=========================\n",
    "\n",
    "Your model is now ready, just as your dataset. It's time to train!\n",
    "\n",
    "The `coordinates` features and `competitors` labels you just transformed have been partitioned into `coord_train`,`coord_test` and `competitors_train`,`competitors_test`.\n",
    "\n",
    "Your `model` is also loaded. Feel free to visualize your training data or `model.summary()` in the console. \n",
    "\n",
    "Let's find out who threw which dart just by looking at the board!\n",
    "\n",
    "Instructions\n",
    "------------\n",
    "\n",
    "-   Train your `model` on the training data for 200 `epochs`.\n",
    "-   Evaluate your `model` accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit your model to the training data for 200 epochs\n",
    "model.fit(coord_train, competitors_train, epochs=200)\n",
    "\n",
    "# Evaluate your model accuracy on the test data\n",
    "accuracy = model.evaluate(coord_test, competitors_test)[1]\n",
    "\n",
    "# Print accuracy\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0dd548",
   "metadata": {},
   "source": [
    "Softmax predictions\n",
    "===================\n",
    "\n",
    "Your recently trained `model` is loaded for you. This model is generalizing well!, that's why you got a high accuracy on the test set. \n",
    "\n",
    "Since you used the `softmax` activation function, for every input of 2 coordinates provided to your model there's an output vector of 4 numbers. Each of these numbers encodes the probability of a given dart being thrown by one of the 4 possible competitors. \n",
    "\n",
    "When computing accuracy with the model's `.evaluate()` method, your model takes the class with the highest probability as the prediction. `np.argmax()` can help you do this since it returns the index with the highest value in an array. \n",
    "\n",
    "Use the collection of test throws stored in `coords_small_test` and `np.argmax()`to check this out!\n",
    "\n",
    "Instructions 1/2\n",
    "----------------\n",
    "\n",
    "-   Predict with your `model` on  `coords_small_test`.\n",
    "-   Print the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b4e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on coords_small_test\n",
    "preds = model.predict(coords_small_test)\n",
    "\n",
    "# Print preds vs true values\n",
    "print(\"{:45} | {}\".format('Raw Model Predictions', 'True labels'))\n",
    "for i, pred in enumerate(preds):\n",
    "    print(\"{} | {}\".format(np.argmax(pred), competitors_small_test[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63dc8be",
   "metadata": {},
   "source": [
    "Instructions 2/2\n",
    "----------------\n",
    "\n",
    "-   Use `np.argmax()`to extract the index of the highest probable competitor from each `pred` vector in `preds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fcc3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on coords_small_test\n",
    "preds = model.predict(coords_small_test)\n",
    "\n",
    "# Print preds vs true values\n",
    "print(\"{:45} | {}\".format('Raw Model Predictions', 'True labels'))\n",
    "for i, pred in enumerate(preds):\n",
    "    print(\"{} | {}\".format(pred, competitors_small_test[i]))\n",
    "\n",
    "# Extract the position of highest probability from each pred vector\n",
    "preds_chosen = [np.argmax(pred) for pred in preds]\n",
    "\n",
    "# Print preds vs true values\n",
    "print(\"{:10} | {}\".format('Rounded Model Predictions', 'True labels'))\n",
    "for i, pred in enumerate(preds_chosen):\n",
    "    print(\"{:25} | {}\".format(pred, competitors_small_test[i]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIAgents4Pharma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
